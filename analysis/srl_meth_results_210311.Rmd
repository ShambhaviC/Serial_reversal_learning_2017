---
title: "Serial reversal learning in nectar-feeding bats"
author: Shambhavi
always_allow_html: yes
output: 
  word_document:
  pdf_document: 
  html_document:
  fig_caption: yes
  bookdown::pdf_document2:
    number_sections: no
    toc: no
    keep_tex: no
bibliography: serial_reversal_learning.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.align = "center")
```

```{r Reading in the packages, echo = FALSE, include=FALSE, results= 'hide'}
# clearing the environment
rm(list = ls())

# creating a vector of the required packages 
packages <- c("rmarkdown", "reshape2", "knitr", "flextable", "scales", "tidyverse", "lubridate", "ggpubr", "gridExtra",  "Hmisc", "brms", "bayesplot")

# installing the required packages if needed
# if (!require(packages)) 
# install.packages(packages)

sapply(packages, library, character.only = TRUE)
```

# Introduction 

# Methods 

## Study site and subjects
The experiment was done in June and July 2017 at La Selva Biological Field Station, Province Heredia, Costa Rica. Male and female individuals of the species *Glossophaga commissarisi*, were captured from the wild for the experiment. The bats were attracted to a particular location in the forest using sugar-water (see **Reward** below) as bait and then caught in mist-nets. The bats were sexed and the selected individuals were were then taken to another location in the rainforest where two flight-cages (4 x 6 m) were set up. The flight-cages had mesh walls and therefore the same climactic conditions as the surrounding environment. A group of four bats at a time were put into a flight cage. All the individuals in a group were the same sex. The bats were weighed and radio frequency identification (RFID) tags that were uniquely assigned to each bat were placed around their necks as collars. The bats were then released into the flight-cages so they could fly within them freely. 

Before the start of the experiment the procedure was tested with four females and refinements were made to the procedure. The data from these individuals were not analyzed. 16 bats participated in the main experiment. At the end of the experiment, the RFID collars were removed and the bats were weighed to make sure they had not lost too much weight. No blinding was done as all the data collection was completely automatized. Two of the bats did not drink sufficient nectar and were released before the end of the experiment and not replaced. The data from these two individuals were not analyzed. Thus, 14 bats in total (7 males and 7 females) completed the experiment and the data from these animals were analyzed. 

Animal experimental procedures were reviewed and permission for animal experimentation and RFID-tagging was granted by Sistema Nacional de Areas de Conservación (SINAC) at the Ministerio de Ambiente y Energía (MINAE), Costa Rica.

## Experimental Setup
### Reward
The reward received by the bats during the experiment was also their main source of food. The reward was a 17% by weight solution of sugar dissolved in water (prepared fresh everyday), hereafter referred to as 'nectar'. The sugar consisted of a 1:1:1 mass-mixture of sucrose, fructose and dextrose. The nectar was thus similar in composition and concentration to the nectar produced by wild chiropterophilous plants [@baker_sugar_1998].

### Flower and pump setup
Each flight cage had a square plastic frame in the center (2x2x1.5m). Eight reward-dispensing devices - hereafter referred to as 'flowers' - were fixed in a radial pattern on this frame, two on each side of the square (see **Figure 1**) with a minimum distance of 40 cm between adjacent flowers. This is a distance the bats can discriminate [@thiele_hierarchical_2005]. Each flower had the following parts: an RFID reader mounted on a plastic cylinder around the head of the flower; an infra-red light-barrier beam; an electronic pinch valve through which a PVC tube was placed and fixed to the head of the flower

A single stepper-motor pump was placed in the center of the plastic frame. The pump contained a 25 mL Hamilton glass syringe (Sigma Aldrich) which was connected to the tubing system of the flowers through 5 pinch valves. These pinch valves controlled the flow of liquid from the pump to the system and from a reservoir of liquid to the pump. This reservoir (500 mL thread bottle, Roth, Germany) was filled with fresh nectar everyday and connected to the syringe through the valves. The nectar was then pushed by the syringe through the valves into the tubes. 

When an RFID-tagged bat approached a flower, the individual RFID number was read by the reader. If the bat then poked its nose into the flower and broke the light barrier, it triggered the release of a reward. The pinch valve opened and the pump moved the correct number of pre-programmed steps to dispense nectar to the head of the flower. The bat could easily hover in front of the flower and lick this up. Only when both events occurred, i.e., the RFID reader detected a bat and the light-barrier was broken, would a reward be triggered.

The flowers and the pump were connected to a Lenovo ThinkPad laptop computer, which ran the experimental programs and the programs used to clean and fill the systems: PhenoSoft Control 16, PhenoSoft GmBH, Berlin, Germany. The raw data were also recorded to this computer as comma-separated values (CSV) files.

```{r, Figure of the setup, fig.cap= "**Figure 1**: a) Schematic of the cage and flower set-up b) Pump from Cage 1 c) Pump from Cage 2"}

include_graphics("images/allthree.png")

```

## Experimental procedure
Every day at around 1000 h the old nectar was emptied from the system. The system was rinsed and filled with plain water until 1500 h , when it was filled again with fresh nectar. Twice a week the system was filled with 70% ethanol for an hour to prevent microbial growth, then repeatedly rinsed with water. 

4 bats were placed in a flight-cage in a group, and all the bats were the same sex. There were 4 such groups in total, and data were collected simultaneously from two groups, one in each flight-cage. Each bat was uniquely assigned 2 adjacent flowers on the same side of the square frame, out of the array of eight. These flowers were programmed to reward only 1 of the 4 bats in the cage. After the system was filled with fresh nectar at approximately 1700 h, the program was left running till the next morning for data-collection. Thus, the bats could begin visiting the flowers to collect a reward whenever they chose, which was at approximately 1800 h every night. 

```{r Calculating the time taken for the pump to fill up, message = FALSE, warning = FALSE, message = FALSE, echo=FALSE, results='hide'}

# reading in the pre-processed data to demonstrate the pump fill time 
raw_data_preproc <- read.csv2("data/raw_data_preproc.csv", sep = ";", header = TRUE)

# creating a vector of the bats to be excluded from the main analysis
bats_incomp <- c("Bat7", "Bat19")

# creating a vector with the beta bats
bats_beta <- c("Bat1", "Bat2", "Bat3", "Bat4")

# creating a vector of the main experimental days
main_days <- c("Day 1", "Day 2", "Day 3")

pump_time <- raw_data_preproc %>% 
  arrange(DateTime) %>% 
  group_by(Cage) %>% 
  filter(MsgValue1 == "start pump" | MsgValue1 == "end pump") %>% 
  mutate(interval = as.integer(difftime(lead(DateTime), DateTime, units = "mins"))) %>% 
  select(DateTime, IdLabel, Condition, Cage, MsgValue1, interval) %>% 
  filter(interval < 20) %>% 
  group_by(Cage) %>% 
  summarise(mean_filltime = round(mean(interval), digits = 2),  
            sd_filltime = round(sd(interval), digits = 2))
pump_fills <- raw_data_preproc %>% 
  arrange(DateTime) %>% 
  group_by(Cage, Condition) %>% 
  mutate(hour = hour(DateTime)) %>% 
  filter(!IdLabel %in% bats_incomp,
         !IdLabel %in% bats_beta,  
         day < 4, 
         hour > 18 | hour < 6, 
         MsgValue1 == "start pump") %>%
  summarise(pump_events = n())

fill_cage1 <- pump_fills %>% 
  filter(Cage == 1) %>% 
  summarise(mean_fills = mean(pump_events), 
            sd_fills = sd(pump_events))
fill_cage2 <- pump_fills %>% 
  filter(Cage == 2) %>% 
  summarise(mean_fills = mean(pump_events), 
            sd_fills = sd(pump_events))
  
```

```{r, Calculating the proportion of wrongly unrewarded visits, message = FALSE, warning = FALSE, message = FALSE, echo=FALSE, results='hide'}
#----------------------------------
# Reading in and preparing the data
#----------------------------------
# loading the prepared CSV file of raw data
raw_data <- read.csv2(file = "data/raw_data.csv", sep = ";", header = TRUE)

# The following terms are used in the analysis of the data:
# 1. Day: a single experimental night during which the data were collected
# 2. block: a group of 50 visits between each reversal where the same flower is rewarding
# 3. bin: a smaller group of visits within a block, the size of which can be set in the code below
# 4. visits: each individual flower visit

# setting binsize and breaks for cutting up the data into block and bin
binsize <- 10
breaks <- seq (0, 3000, binsize)

# placing the visits made by the beta bats in a separate data frame

rev_learning_all_beta <- raw_data %>% 
  filter(IdLabel %in% bats_beta)

# placing the visits made on days 4, 5 and 6 in a separate data frame 

rev_learning_all_lastdays <- raw_data %>% 
  filter(!day %in% main_days)

# preparing a data frame with all the visits, including the proper but unrewarded ones 
rev_learning_all_unrew <- raw_data %>%
  filter(
    # removing the bats that did not complete the experiment
    !IdLabel %in% bats_incomp,
    !IdLabel %in% bats_beta, 
    day %in% main_days, 
    # filtering out the main experimental data
    Condition == "SerialReversalCounter"
  ) %>%
  mutate(
    # marking the difference between the normal visits in a block and the switch points
    MsgValue1 = ifelse(MsgValue1 == "switch", MsgValue1, "block"),  
    # making a column to mark the unrewarded proper visits 
      reinforce1value = replace_na(reinforce1value, 0),
      reinforce1Account = replace_na(reinforce1Account, 0), 
      Unrew = ifelse(reinforce1value != reinforce1Account, 1, 0)
  ) %>%
  rename(Bat = IdLabel) %>%
  arrange(Group, day, Bat, DateTime) %>%
  # grouping the data to count the visits, noting the reversals separately
  group_by(Bat, day) %>%
  mutate(
    # creating a column with the total number of visits made by a bat per day
    count_vis = ifelse(MsgValue1 == "switch", 0, 1), 
    count_vis = cumsum(count_vis)
  ) %>%
  # setting the maximum number of visits a night higher than the programmed max to allow for the 
  # unrewarded visits
  filter(count_vis <= 350) %>%
  ungroup()

# adding the reversal block numbers and marking the reversals for the dataset with the unrewarded visits
rev_learning_all_unrew <- rev_learning_all_unrew %>% 
  # creating a column with the reversal block number, marking the reversals
  mutate(block = ifelse(MsgValue1 == "switch", 1, 0)) %>%
  group_by(day, Bat) %>%
  mutate(block = cumsum(block)) %>%
  ungroup() %>% 
  group_by(day, Bat, block) %>%
  # creating a column with the number of visits within each block
  mutate(block_vis = ifelse(MsgValue1 == "switch", 0, 1), 
         block_vis = cumsum(block_vis), 
         # creating a new column for visits in each block to be binned
         bin = "") %>%
  ungroup() %>%
  group_by(day, Bat, block) %>%
  # cutting the visits inside each block into bin of the size set earlier
  mutate(bin = as.numeric(cut(block_vis, breaks, include.lowest = TRUE)))

# adding a reward status to the table 
rev_learning_all_unrew <- rev_learning_all_unrew %>% 
  mutate(reward_status = ifelse(reinforce1value == 0 | Unrew == 1, 0, 1)) %>% 
  filter(!Bat %in% bats_beta, 
         day %in% main_days)

# what percentage of the bats' visits are wrongly unrewarded? 
mean_unrew <- rev_learning_all_unrew %>% 
  group_by(Bat, Day) %>% 
  filter(MsgValue1 != "switch") %>% 
  summarise(mean_unrew = mean(Unrew)) %>% 
  mutate(mean_unrew = mean_unrew *100)

overall_mean_unrew <- round(as.numeric(mean(mean_unrew$mean_unrew), digits = 2))
overall_sd_unrew <- round(as.numeric(sd(mean_unrew$mean_unrew)), digits = 2)

```

During the course of the night, when the syringe of the pump had been emptied, the pump re-filled automatically. This process took `r as.numeric(pump_time[1, 2])` minutes (SD = ±`r as.numeric(pump_time[1 ,3])`) in Cage 1, occurring on average `r round(as.numeric(fill_cage1$mean_fills), digits = 2)` times (SD = ± `r round(as.numeric(fill_cage1$sd_fills), digits = 2)`); and `r as.numeric(pump_time[2, 2])` minutes (SD = ±`r as.numeric(pump_time[2, 3])`) in Cage 2, occurring on average `r round(as.numeric(fill_cage2$mean_fills), digits = 2)` times (SD ± `r round(as.numeric(fill_cage2$sd_fills), digits = 2)`). About `r overall_mean_unrew` % (SD = ±`r overall_sd_unrew`) of all visits made by the bats over all 3 experimental nights happened during the pump refill events, and the bats did not receive any reward on these visits, even if they were made to the rewarding flower. 

Every night the bats were also given ad-libitum supplemental food: 3.5g of hummingbird food (NektarPlus, Nekton) in 100 mL of water and 3.5g of milk powder (Nido 1+, Nestle) in 100 mL of water. They were also given a small bowl of locally-sourced bee pollen. 

## Experimental design
The experiment proceeded through the following stages. 

### Ad-libitum reward

On the night the naive bats were captured and placed into the flight cages they received ad-libitum reward from all the flowers all night long. To enable the bats to find the flowers a small cotton pad was placed on the flowers, soaked with di-methyl di-sulphide. This is a chemical attractant produced by many bat-pollinated flowers [@von_helversen_sulphur-containing_2000]. A small drop of honey was applied to the inside of the flowers to encourage the bats to place their heads inside, break the light-barrier and trigger a nectar reward. By the end of the night all the bats had found the flowers and learned to trigger rewards quickly. 

### Flower training

After the bats had learned to trigger rewards, the next stage of training involved assigning the bats uniquely to two out of the eight flowers in the array. This stage was similar to the *ad-libitum* stage, except the bats could only trigger a reward at their assigned flowers. 

### Alternation

To ensure that the bats were familiar with both flowers assigned to them they went through one final stage of training: forced alternation between the two assigned flowers all night long. 

### Main Experiment

In this serial reversal learning task the bats had to choose between a flower that gave 40 $\mu$L of nectar and one that gave no reward at all. The location of the rewarding flower was not cued, but through the Alternation phase of training each bat knew the locations of both flowers that were potentially rewarding to it. After a bat had made 50 visits in total to the two flowers a reversal occurred: the previously rewarding flower became the non-rewarding flower and *vice versa*. The batch of 50 visits that occurred between two consecutive reversals (when the locations of the rewarding and unrewarding flowers) was termed a 'reversal block', including the first 50 visits of a night when the bats had not experienced any reversal at all that night. This occurred at regular intervals of 50 visits until the bat either stopped making visits or reached a maximum of 300 visits in a night. After the bat had made 300 rewarded visits it could no longer receive a reward that experimental night. There were five reversals per night. This stage of the experiment was repeated for three nights in a row. The same flower was the first to be rewarding at the start of every night. Thus, because there were five reversals every night (so six blocks of 50 visits), the last flower to be rewarding on a night was non-rewarding at the start of the next night. 

## Statistical analysis 

All the visits made by the bats during a night, up to a maximum of 300 were included in the analyses. There were 3 experimental nights, divided into six blocks of 50 visits each. At the end of the first five blocks a reversal occurred and the end of the last block was the end of data-collection for the night. Each block was further divided into five bins, each consisting of 10 visits, in order to further examine the bats' behaviour within each block. 

We defined a perseverative visit as a visit to the previously-rewarding option just after the occurrence of a reversal, until the first visit to the newly-rewarding option. By definition this could not happen in the first block of a night. A generalized linear mixed-model was used to investigate the effect of experimental night and reversal block on the number of perseverative visits. This model was fit in a Bayesian framework using Hamiltonian Monte Carlo in the R package `brms` [@burkner_brms_2017], which is a front-end for `rstan` (Stan Development Team, 2020). A negative-binomial likelihood function was used for this model. Experimental night, reversal block and their interaction were fixed effects and random slopes and intercepts were used to fit regression lines for each individual animal. 
We also examined the proportion of visits made to the rewarding flower. This was defined as ratio of the number of visits to the rewarding flower divided by the total number of visits in a bin. The model was fit using a binomial likelihood function, with experimental night, block, bin and their interactions as fixed effects; random slopes and intercepts were used to fit regression lines for the individuals. 
After examining the results of the above analyses, further data exploration was done. We defined a sampling visit as a visit made to a non-rewarding flower after the first experience of reward at a rewarding flower in any block. A negative-binomial likelihood function was used to model the number of sampling visits made by the bats, with experimental night, reversal block, bin and their interactions as fixed effects. Random slopes and random intercepts were used to fit regression lines for the individual animals. 
A second model was also fit to the proportion of visits to the rewarding flower to take into account the fact that the first night and the first block of each night were qualitatively different from the others. On the first night the animals had had no prior experience of any reversals, and during the first block of every night they had not experienced any reversals on that night, and this was reflected in the fit of the posterior predictions made from the first model. The second model of these data was identical to the first except for the addition of experimental night and block as factor variables, with the first night and the first block of every night as one level and the other nights and other blocks of each night as the other level. The two models were compared using leave-one-out cross-validation, implemented in `brms` using the package `loo` [@vehtari_practical_2017]. 

Weakly informative priors were used. The random intercepts and slopes were given a Normal distribution with a mean of 0, and a standard deviation drawn from a Cauchy distribution with a mean of 0 and a standard deviation of 1. All the models were estimated using 4 chains with a thinning interval of 3, with 1200 warm-up samples and 1300 post-warm-up samples for the model with the first experimental night and block additionally treated differently; 2000 warm-up samples and 2000 post-warm-up samples for the model of the smapling visits; and 1000 warm-up samples and 1000 post-warm-up samples for the others. 

Visual inspection of the trace plots, the number of effective samples, the Gelman-Rubin convergence diagnostic ($\hat R$) and the calculation of posterior predictions for the same clusters were all used to assess the fit of the models. In all of the models the $\hat R$ was equal to 1 for all the chains. 

The data from all 14 bats that participated in the three experimental nights were included in these models, even though some individuals did not complete all 300 visits on every single night. 

All statistical analyses and creation of plots were done in R. 

## Data availability 
All data and analysis code are available online at ..... 

# Results 

## Confirmatory Analyses

### Explanatory paragraph
**This paragraph is just for our guidance and will be removed later: it is an overall summary of the conclusions we draw from all of the analyses, i.e., the story we are building.**
**Confirmatory analyses**: As bats experience serial reversals they show a more rapid switch to the rewarding option after a reversal, and an overall increase in the proportion of visits made to the rewarding option. This overall increase was smaller with each successive reversal.  
**Exploratory analyses**: The largest proportion of visits to the rewarding option was made every night before the bats had experienced any reversals. In addition, the smaller increase with each reversal seen in the confirmatory analysis was not due to an increase in sampling visits, but explainable through the combination of a faster switch to the rewarding option and an extremely high proportion of visits to the rewarding option: a sort of 'ceiling effect'.

### a) Bats made more than 90% of their visits to the rewarding option
```{r, Reading in and preparing the main data, include = FALSE}
#----------------------------------------
# Preparing data from the main experiment
#----------------------------------------

# making a separate data frame without any unrewarded visits and preparing it further with block and bin numbers
rev_learning_all <- rev_learning_all_unrew %>% 
  filter(Unrew == 0) %>%
  select(-Unrew) %>%
  # grouping the data to count the visits, noting the reversals separately
  group_by(Bat, day) %>%
  mutate(
    # noting whether the bat made a visit to the more or less rewarding flower
    reward_status = ifelse(reinforce1value > 0, 1, 0),
    # creating a column with the total number of visits made by a bat per day
    count_vis = ifelse(MsgValue1 == "switch", 0, 1), 
    # taking the cumulative sum of the visit counts 
    count_vis = cumsum(count_vis)
  ) %>%
  # setting the maximum number of visits a night
  filter(count_vis <= 300) %>%
  ungroup() %>%
  # creating a column with the reversal block number, marking the reversals
  mutate(block = ifelse(MsgValue1 == "switch", 1, 0)) %>%
  group_by(day, Bat) %>%
  mutate(block = cumsum(block)) %>%
  ungroup() %>% 
  group_by(day, Bat, block) %>%
  # creating a column with the number of visits within each block
  mutate(block_vis = ifelse(MsgValue1 == "switch", 0, 1), 
         block_vis = cumsum(block_vis), 
  # creating a new column for visits in each block to be binned
         bin = "") %>%
  ungroup() %>%
  group_by(day, Bat, block) %>%
  # cutting the visits inside each block into bin of the size set earlier
  mutate(bin = as.numeric(cut(block_vis, breaks, include.lowest = TRUE)))

#-----------------------------------------------------------------
# Calculating the raw proportion of visits to the rewarding flower
#-----------------------------------------------------------------
block1 <- rev_learning_all %>% 
  filter(block == 1) %>% 
  summarise(mean_prop = mean(reward_status)*100)

later_bins <- rev_learning_all %>% 
  filter(bin != 1) %>% 
  summarise(mean_prop = mean(reward_status)*100) 

```

At the start of the each night, before they had experienced any reversals, the bats made approximately `r round(as.numeric(mean(block1$mean_prop), digits = 2))`% (±SD `r round(as.numeric(sd(block1$mean_prop), digits = 2))`) of their visits to the rewarding flower; immediately following a reversal, this proportion dropped below 50% (**Figure 2**). The proportion of visits to the rewarding flower for the rest of a block then increased to `r round(as.numeric(mean(later_bins$mean_prop), digits = 2))`% (±SD `r round(as.numeric(sd(later_bins$mean_prop), digits = 2))`) after the first bin of 10 visits following a reversal. 

```{r, Plotting the average behaviour with the sample sizes, message = FALSE, warning = FALSE, echo = FALSE, fig.cap = "**Figure 2**: Average preferences of the bats and the sample size of each block. The first block before the bats experienced any reversals at all is marked with white points, the other blocks with black points. Shaded areas are 95% confidence intervals", fig.width = 9, fig.height = 3}

# averaging the bats' choice behaviour over day, block and bin
rev_learning_avg <- rev_learning_all %>%
  group_by(day, block) %>%
  mutate(n_bats = n_distinct(Bat)) %>% 
  group_by(day, block, n_bats, bin) %>% 
  # calculating the 95% confidence intervals 
  group_modify(~ mean_cl_boot(.x$reward_status, conf.int = 0.95)) %>%
  ungroup() %>%
  group_by(day) %>%
  mutate(
    day_bin = 1:n(),
    day_bin_vis = day_bin * binsize,
    reversal = ifelse(block != lead(block), "switch", "block")
  )

# creating a look-up table so the reversals can be marked 
rev_main_avg <- rev_learning_avg %>%
  filter(
    reversal == "switch",
    day %in% main_days
  ) %>%
  select(day, block, day_bin, day_bin_vis)

# calculating the sample size in each block 
bat_labels <- rev_learning_avg %>% 
  select(day, block, n_bats) %>%
  distinct() %>% 
  group_by(day, block) %>% 
  mutate(day_bin_vis = ifelse(block == 1, 25, 50)) %>%
  ungroup() %>% 
  group_by(day) %>% 
  mutate(day_bin_vis = cumsum(day_bin_vis)) %>% 
  filter(day %in% main_days)

p1 <- rev_learning_avg %>%
  # filtering only the first three main days of the experiment:
  # one group had the experiment extended a further three days
  filter(day %in% main_days) %>%
  mutate(firstpoint = as.factor(ifelse(block == 1 & day == "Day 1", 1, 0))) %>% 
  ggplot(aes(day_bin_vis, y)) +
  geom_point(aes(color = firstpoint, fill = firstpoint), shape = 21) +
  scale_color_manual(values=c("0" = "black", "1" = "black")) + 
  scale_fill_manual(values = c("0" = "black", "1" = "white")) + 
  geom_line() +
  geom_ribbon(aes(ymin = ymin, ymax = ymax), alpha = 0.3) +
  facet_grid(. ~ day) +
  scale_x_continuous(breaks = seq(50, 300, by = 50)) +
  ylim(0, 1.1) +
  geom_hline(yintercept = c(0.25, 0.5, 0.75, 1), linetype = "dotted") +
  geom_vline(aes(xintercept = day_bin_vis), rev_main_avg, linetype = "dashed") +
  theme_classic() +
  geom_text( data = bat_labels, 
             aes(x = day_bin_vis, y = 1.05, label = n_bats, group = n_bats)) + 
  labs(x = "Visits", y = "Proportion of total visits \n made to the rewarding option") + 
  theme(legend.position = "none")

p1
```

### b) Bats switch to the rewarding option faster as they experience more reversals

A visit to a non-rewarding flower after a reversal, before the first experience of a reward at the newly-rewarding option was called a perseverative visit. Our analysis showed that both experimental night and block had a negative effect on the number of perseverative visits made by the bats. As the bats experience more reversals on more nights the number of perseverative visits decreased. The interaction of night and block, however, was positive: the decrease in the number of perseverative visits was smaller as the bats experienced more experimental nights.  

```{r, message = FALSE, warning = FALSE, echo = FALSE, fig.cap = "**Figure 3**: Number of perseverative visits made by the individual bats after a reversal. Red lines are data from the individual bats, black lines are the mean number of visits averaged over bats", fig.width = 6, fig.height = 3}
#---------------------------------------------------
# Plotting the perseverative visits made by the bats
#---------------------------------------------------
pers_visits <- rev_learning_all %>% 
  select(-c(Group, Cage, Condition, Day, IdRFID, SystemMsg)) %>% 
  filter(block_vis != 0) %>% 
  group_by(Bat, day, block) %>% 
  mutate(first_rew = cumsum(reward_status)) %>% 
  filter(block > 1, 
         first_rew == 1, 
         reward_status == 1) %>% 
  ungroup() %>%
  group_by(day, block) %>% 
  mutate(mean_vis = mean(block_vis))

p2 <- pers_visits %>% 
  filter(day %in% main_days) %>% 
  mutate(day = case_when(day == "Day 1" ~ "Night 1", 
                         day == "Day 2" ~ "Night 2", 
                         day == "Day 3" ~ "Night 3")) %>% 
  ggplot(aes(block)) + 
  geom_line(aes(y = block_vis, group = Bat, color = "red"), alpha = 0.5) + 
  geom_line(aes(y = mean_vis), color = "black") + 
  facet_grid(.~day) + 
  ylim(0, 18) + 
  theme_bw() + 
  theme(legend.position = "none") + 
  ylab("Number of visits to the previous rewarding flower \n before the first visit to a new rewarding flower") + 
  xlab("Reversal block")

p2
```

```{r, Modelling the effect of night and block on the perseverative visits and plotting the results, message = FALSE, warning = FALSE, message = FALSE, echo=FALSE, fig.cap = "**Figure 4**: Plot of slope coefficient values of the fixed effects: experimental night and block", fig.width = 5, fig.height = 3}
#---------------
# Model fitting 
#---------------
# preparing the data table for the analysis of the perseverative visits 
analysis_pers <- rev_learning_all %>% 
  ungroup() %>% 
  select(Day, block, Bat, reward_status, block_vis, count_vis) %>%
  filter(block_vis != 0) %>% 
  group_by(Bat, Day, block) %>% 
  mutate(first_rew = cumsum(reward_status)) %>% 
  filter(block > 1, 
         first_rew == 1, 
         reward_status == 1)

# fitting a random slopes and random intercept model to the data, examining the effects of day, block and bin on the number of perseverative visits following a reversal; the response variable is taken to follow a negative-binomial distribution, which assumes that each Poisson count variable has its own rate parameter 

# m_pers <-
#   brm(data = analysis_pers, family = negbinomial,
#       block_vis ~ Day + block + Day:block + (1 + Day + block| Bat),
#       prior = c(prior(normal(0, 10), class = Intercept),
#                 prior(normal(0, 10), class = b),
#                 prior(cauchy(0, 1), class = sd)),
#       iter = 2000, warmup = 1000, chains = 4, cores = 4, thin = 3, 
#       control = list(adapt_delta = 0.999, 
#                      max_treedepth = 12),
#       seed = 12)
# 
# save(m_pers, file = "03_stats_rs_m4_negbinom.rda")
load("data/03_stats_rs_m4_negbinom.rda")
#m_pers <- read.csv2(file = "data/m_pers.csv", sep = ";", header = TRUE)

# renaming the model appropriately
m_pers <- m3.1.1

# removing the model with the misleading name 
rm(m3.1.1)
# setting the colour scheme 
color_scheme_set("darkgray")

#model summary
t1 <- fixef(m_pers) %>% 
  as_tibble() %>% 
  mutate("Fixed effect" = c("Intercept", "Night", "Block", "Night-Block Interaction"), 
         Estimate = round(Estimate, digits = 2), 
         Q2.5 = round(Q2.5, digits = 2), 
         Q97.5 = round(Q97.5, digits = 2), 
         # making a note of those rows where the slope coefficients do not overlap with 0
         bold = case_when(Q2.5 < 0 & Q97.5 < 0 ~ 1, 
                          Q2.5 > 0 & Q97.5 > 0 ~ 1), 
         row_num = 1:n())

# taking out the rows to be made bold as a vector
t1_bold <- t1 %>% filter(bold == 1) 
t1_bold <- as.vector(t1_bold$row_num)

t1 <- t1 %>% 
  # renaming the credibility intervals column
  mutate("95% Credibility intervals" = paste0("(", Q2.5, " , ", Q97.5, ")")) %>%
  # select the required volumes
  select("Fixed effect", "Estimate", "95% Credibility intervals") %>% 
  flextable(cwidth = 1.50) %>% 
  theme_booktabs() %>% 
  set_caption("**Table 1**: Results of the random regression model (brms), testing for the effects of night and block (fixed effects) on the number of perseverative visits (dependent variable)") %>% 
  align(align = "center", part = "all") %>% 
  # making the column names and the 'significant' rows bold 
  bold(part = "header") %>% 
  bold(i = c(t1_bold), bold = TRUE)

t1

# creating a plot of the slope coefficients 
p3 <- mcmc_intervals(m_pers, 
               pars = vars(2:4), 
               point_size = 1.75, 
               prob_outer = 0.95) + 
  geom_vline(xintercept = 0) + 
    scale_y_discrete(
    labels = c("b_Day" = "Experimental night",
               "b_block" = "Reversal block", 
               "b_Day:block" = "Night - block interaction"),
    limits = c("b_Day:block", "b_block", "b_Day")) 
  #theme_bw()

p3

```

**Figure 5** shows the fit of the model to the empirical data through sampling from the posterior distribution. The model clearly captures both the negative effect of night and block, as well as their positive interaction. 

```{r, message = FALSE, warning = FALSE, message = FALSE, echo=FALSE, fig.cap = "**Figure 5**: The posterior predictions of the model of perseverative visits (blue line), compared with the empirical data from the bats (red line)", fig.width = 9.5, fig.height = 3}

# calculating the posterior predictions 
# selecting the required columns from the analysis dataframe 
nd_pers <- analysis_pers %>% 
  select(Bat, Day, block)

# calculating the posterior predictions 
post_fit <-
  fitted(m_pers,
         newdata = nd_pers) %>% 
  as_tibble() %>% 
  mutate(Bat = analysis_pers$Bat, 
         Day = analysis_pers$Day,
         block = analysis_pers$block, 
         count_vis = analysis_pers$block_vis)

# calculating the empirical equivalents of the posterior predictions 
comparison_pers <- analysis_pers %>% 
  group_by(Bat, Day, block) %>% 
  group_modify(~ mean_cl_boot(.x$block_vis, conf.int = 0.95))

# putting the calculated posterior values and the empirical values into the same table
comparison_pers <- left_join(analysis_pers, post_fit, by = c("Bat", "Day", "block"))

# plotting the posterior predicted values and empirical values together 
p3 <- comparison_pers %>% 
  mutate(Day = case_when(Day == 1 ~ "Night 1", 
                         Day == 2 ~ "Night 2", 
                         Day == 3 ~ "Night 3")) %>% 
  ggplot(aes(block)) + 
  #geom_point(aes(y = y), color = "red", size = 0.2) +
  geom_line(aes(y = block_vis), color = "red") + 
  #geom_ribbon(aes(ymin = ymin, ymax = ymax), fill = "red", alpha = 0.3) + 
  geom_point(aes(y = Estimate), color = "blue", size = 0.2) + 
  geom_line(aes(y = Estimate), color = "blue") + 
  geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5), fill = "blue", alpha = 0.3) +
  xlab("Block") + 
  ylab("Perseverative visits after a reversal before \n the first visit to the new rewarding flower after a reversal") + 
  facet_grid(Day ~ Bat) + 
  theme_bw()

p3

```

### c) The bats increase the proportion of visits to the rewarding option as they experience more reversals; this behaviour shows a 'ceiling effect' 

The proportion of visits to the rewarding option was a modeled as an effect of experimental night, block and bin. This analysis showed that night, block and bin all had a positive effect on the proportion of visits to the rewarding option: as the bats experience more reversals on more nights, and the more visits made since the occurrence of a reversal, the proportion of visits made to the rewarding option increased. 
Interestingly the slopes of the interactions of experimental night and block; block and bin within the block; and experimental night and bin within the block were all negative. That is, the increase in proportion of visits to the rewarding flower gets smaller as the bats experience more reversals on more nights; there is a smaller 'improvement' in performance. Though the interactions effects were smaller than the main effects, the 95% credibility intervals of neither the main nor the interaction effects overlapped with 0. 

```{r, Modelling the effect of night, block and bin on the proportion of visits to the rewarding option, message = FALSE, warning = FALSE, message = FALSE, echo=FALSE, fig.cap = "**Figure 6**: Plot of slope coefficient values of the fixed effects: experimental night, block and bin", fig.width = 5, fig.height = 3}
#-----------------------------------------------------------------------
# Fitting the model without accounting for the first day and first block
#-----------------------------------------------------------------------
# creating the dataset for the analysis 
analysis_choices <- rev_learning_all %>% 
  ungroup() %>% 
  select(Day, block, bin, Bat, reward_status, block_vis, count_vis) %>% 
  filter(block_vis != 0)

# fitting the model 
# m_choices <-
#   brm(data = analysis_choices, family = binomial,
#       reward_status | trials(1) ~ Day + block + bin +
#         Day:block +
#         block:bin +
#         Day:bin +
#         (1 + Day + block + bin | Bat), # random slopes 
#       prior = c(prior(normal(0, 10), class = Intercept),
#                 prior(normal(0, 10), class = b),
#                 prior(cauchy(0, 1), class = sd)),
#       iter = 2000, warmup = 1000, chains = 4, cores = 5, thin = 3, 
#       control = list(adapt_delta = 0.9995, max_treedepth = 15),  
#       seed = 12)
# 
# # save the model 
# save(m_choices, file = "03_stats_rs_m1.1.rda")
#here is the model with the results, ready to be loaded. 
load(file = "data/03_stats_rs_m1.1.rda")
# renaming the model appropriately
m_choices <- m1.2.1
# removing the old model with the misleading name
rm(m1.2.1)

color_scheme_set("darkgray")

#model summary
t2 <- fixef(m_choices) %>% 
  as_tibble() %>% 
  mutate("Fixed effect" = c("Intercept", "Night", "Block","Bin", "Night-Block interaction", "Block-Bin interaction", "Night-Bin interaction"), 
         Estimate = round(Estimate, digits = 2), 
         Q2.5 = round(Q2.5, digits = 2), 
         Q97.5 = round(Q97.5, digits = 2), 
         # making a note of those rows where the slope coefficients do not overlap with 0
         bold = case_when(Q2.5 < 0 & Q97.5 < 0 ~ 1, 
                          Q2.5 > 0 & Q97.5 > 0 ~ 1), 
         row_num = 1:n()) 

# taking out the rows to be made bold as a vector
t2_bold <- t2 %>% filter(bold == 1) 
t2_bold <- as.vector(t2_bold$row_num)
         
t2 <- t2 %>% 
  mutate("95% Credibility intervals" = paste0("(", Q2.5, " , ", Q97.5, ")")) %>% 
  select("Fixed effect", "Estimate", "95% Credibility intervals") %>% 
  flextable(cwidth = 2) %>% 
  hline() %>% 
  theme_booktabs() %>% 
  set_caption("**Table 2**: Results of the random regression model (brms), testing for the effects of night, block and bin on the proportion of visits to the rewarding flower (dependent variable)") %>% 
  align(align = "center", part = "all") %>% 
  # making the column names bold
  bold(part = "header") %>% 
  bold(i = c(t2_bold), bold = TRUE)

t2

# creating the plot of slope coefficients
p4 <- mcmc_intervals(m_choices, 
               pars = vars(2:7), 
               point_size = 1.75, 
               prob_outer = 0.95) + 
  geom_vline(xintercept = 0) + 
  scale_y_discrete(
    labels = c("b_Day" = "Experimental night",
               "b_block" = "Reversal block", 
               "b_bin" = "Bin", 
               "b_Day:block" = "Night - block interaction", 
               "b_block:bin" = "Block - bin interaction", 
               "b_Day:bin" = "Night - bin interaction"), 
    limits = c("b_Day:bin", "b_block:bin", "b_Day:block", "b_bin", "b_block", "b_Day")) +
  theme_bw()

print(p4)

```

**Figure 7** shows the fit of the posterior predictions of this model. 

```{r, Modelling the perseverative visits and plotting the results, message = FALSE, warning = FALSE, message = FALSE, echo=FALSE, fig.cap = "**Figure 7**: The posterior predictions of the model of perseverative visits (blue line), compared with the empirical data from the bats (red line)", fig.width = 9.5, fig.height = 6}

# calculating the posterior predictions 
# selecting the required columns from the analysis dataframe 
nd_choices <- analysis_choices %>% 
  select(Bat, Day, block, bin, count_vis)

# calculating the posterior predictions 
post_fit <-
  predict(m_choices) %>% 
  as_tibble() %>% 
  mutate(Bat = nd_choices$Bat, 
         Day = nd_choices$Day,
         block = nd_choices$block, 
         bin = nd_choices$bin, 
         count_vis = nd_choices$count_vis)

# calculating the empirical equivalents of the posterior predictions 
comparison_choices <- analysis_choices %>% 
  group_by(Bat, Day, block, bin) %>% 
  group_modify(~ mean_cl_boot(.x$reward_status, conf.int = 0.95))

# look up table for splitting the data set 
split <- data.frame(
  Bat = c("Bat5", "Bat6", "Bat8", "Bat9", "Bat10", "Bat11", "Bat12", "Bat13", "Bat14", "Bat15", "Bat16", "Bat17", "Bat18", "Bat20"),
  row = as.factor(c(rep(1, 7), rep(2, 7)))) 

# putting the calculated posterior values and the empirical values into the same table
comparison_choices <- left_join(comparison_choices, post_fit, by = c("Bat", "Day", "block", "bin"))
comparison_choices <- left_join(comparison_choices, split, by = "Bat") %>% 
  mutate(Day = case_when(Day == 1 ~ "Night 1", 
                         Day == 2 ~ "Night 2", 
                         Day == 3 ~ "Night 3"))

# plotting the posterior predicted values and empirical values together 
p5 <- comparison_choices %>% 
  filter(row == 1) %>% 
  ggplot(aes(count_vis)) + 
  #geom_point(aes(y = y), color = "red", size = 0.2) +
  geom_line(aes(y = y), color = "red") + 
  geom_ribbon(aes(ymin = ymin, ymax = ymax), fill = "red", alpha = 0.3) + 
  #geom_point(aes(y = Estimate), color = "blue", size = 0.2) + 
  geom_line(aes(y = Estimate), color = "blue", alpha = 0.5) + 
  #geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5), fill = "blue", alpha = 0.3) + 
  geom_vline(xintercept = c(50, 100, 150, 200, 250), linetype = "dashed", size = 0.2) + 
  xlab("Visit count") + 
  ylab("Proportion of visits to the rewarding flower") + 
  scale_y_continuous(breaks = c(0, 0.5, 1)) + 
  facet_grid(Day ~ Bat) + 
  theme_classic()

p6 <- comparison_choices %>% 
  filter(row == 2) %>% 
  ggplot(aes(count_vis)) + 
  #geom_point(aes(y = y), color = "red", size = 0.2) +
  geom_line(aes(y = y), color = "red") + 
  geom_ribbon(aes(ymin = ymin, ymax = ymax), fill = "red", alpha = 0.3) + 
  #geom_point(aes(y = Estimate), color = "blue", size = 0.2) + 
  geom_line(aes(y = Estimate), color = "blue", alpha = 0.5) + 
  #geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5), fill = "blue", alpha = 0.3) + 
  geom_vline(xintercept = c(50, 100, 150, 200, 250), linetype = "dashed", size = 0.2) + 
  xlab("Visit count") + 
  ylab("Proportion of visits to the rewarding flower") + 
  scale_y_continuous(breaks = c(0, 0.5, 1)) + 
  facet_grid(Day ~ Bat) + 
  theme_classic()

ggarrange(p5, p6, nrow = 2, ncol = 1)
```

## Further exploratory analyses

### a) The effect of the first experimental night and the first block of each night

The first block of an experimental night was qualitatively different from the other blocks, as this was the only part of the night when the bats had not yet experienced a reversal. A similar argument can be made about the first experimental night: on this night the bats experience reversals for the first time. As it seemed the posterior predictions of our model with the effects of experimental night, block and bin did not completely capture the behaviour of the bats we did an exploratory analysis to specifically explore the effect of the first block and the first night. 

The results of the model that accounts for the first night and block are presented in **Figure 8**. The main effects of night, block and bin, and their interactions were similar to the previous model. Additionally, the variable 'block type', (i.e., whether a block was the first reversal block of the night or not), had a positive slope. The bats made more visits to the rewarding flower before they had experienced any reversal at all. While the 'night type' did not seem to affect the proportion of visits to the rewarding flower, block type and night type had an interaction effect with a positive slope coefficient: the first block of the first night, before any reversals had ever been experienced even once, had the highest proportion of visits to the rewarding flower compared to any other block on any other night. 

```{r, Plotting the results of the model of the proportion of visits to the rewarding flower, message = FALSE, warning = FALSE, message = FALSE, echo=FALSE, fig.cap = "**Figure 8**: The effect of night, block, bin, night type and block type on the proportion of visits to the rewarding option. Plot of intercept and slope coefficient values of the fixed effects", fig.width = 5, fig.height = 3}
#---------------------------------------------------------------
# Fitting the model accounting for the first day and first block
#---------------------------------------------------------------
analysis_choices2 <- analysis_choices %>% 
  mutate(day_type = as.factor(ifelse(Day == 1, 1, 0)), 
         block_type = as.factor(ifelse(block == 1, 1, 0)))
  
# m_choices2 <-
#   brm(data = analysis_choices2, family = binomial,
#       reward_status | trials(1) ~ 
#         Day + block + 
#         day_type + block_type + bin + 
#         Day:block + block:bin + Day:bin + 
#         day_type:block_type + block_type:bin + day_type:bin +
#         (1 + Day + block + day_type + block_type + bin | Bat), # random slopes 
#       prior = c(prior(normal(0, 10), class = Intercept),
#                 prior(normal(0, 10), class = b),
#                 prior(cauchy(0, 1), class = sd)),
#       # longer chains were needed for this more complex model to converge 
#       iter = 2500, warmup = 1200, chains = 4, cores = 5, thin = 3,
#       control = list(adapt_delta = 0.9995, max_treedepth = 15),  
#       seed = 12)

# save the model 
#save(m_choices2, file = "03_stats_rs_m6.rda")
#here is the model with the results, ready to be loaded. 
load(file = "data/03_stats_rs_m6.rda")
m_choices2 <- m6
# removing the old model with the misleading name
rm(m6)

# setting the colour scheme 
color_scheme_set("darkgray")

#model summary
t3 <- fixef(m_choices2) %>% 
  as_tibble() %>% 
  mutate("Fixed effect" = c("Intercept", "Night", "Block", "Night Type 1", "Block Type 1", "Bin", "Night-Block interaction", "Block-Bin interaction", "Night-Bin interaction", "Night Type 1-Block Type 1 interaction", "Block Type 1-Bin interaction", "Night Type 1-Bin interaction"), 
         Estimate = round(Estimate, digits = 2), 
         Q2.5 = round(Q2.5, digits = 2), 
         Q97.5 = round(Q97.5, digits = 2), 
         # making a note of those rows where the slope coefficients do not overlap with 0
         bold = case_when(Q2.5 < 0 & Q97.5 < 0 ~ 1, 
                          Q2.5 > 0 & Q97.5 > 0 ~ 1), 
         row_num = 1:n()) 

# taking out the rows to be made bold as a vector
t3_bold <- t3 %>% filter(bold == 1) 
t3_bold <- as.vector(t3_bold$row_num)
         
t3 <- t3 %>% 
  mutate("95% Credibility intervals" = paste0("(", Q2.5, " , ", Q97.5, ")")) %>% 
  select("Fixed effect", "Estimate", "95% Credibility intervals") %>% 
  flextable(cwidth = 2) %>% 
  hline() %>% 
  theme_booktabs() %>% 
  set_caption("**Table 3**: Results of the random regression model (brms), testing for the effects of night, block, bin, night type and block type on the proportion of visits to the rewarding flower (dependent variable)") %>% 
  align(align = "center", part = "all") %>% 
  # making the column names bold
  bold(part = "header") %>% 
  bold(i = c(t3_bold), bold = TRUE)

t3

# creating the plot of slope coefficients
p7 <- mcmc_intervals(m_choices2, 
               pars = vars(2:12), 
               point_size = 1.75, 
               prob_outer = 0.95) + 
  geom_vline(xintercept = 0) + 
    scale_y_discrete(
    labels = c("b_Day" = "Experimental night",
               "b_block" = "Reversal block", 
               "b_day_type1" = "First experimental night",
               "b_block_type1" = "First block of a night",
               "b_bin" = "Bin", 
               "b_Day:block" = "Night - block interaction", 
               "b_block:bin" = "Block - bin interaction", 
               "b_Day:bin" = "Day - bin interaction", 
               "b_day_type1:block_type1" = "First night - first block interaction", 
               "b_block_type1:bin" = "First block - bin interaction", 
               "b_day_type1:bin" = "First night - bin interaction"), 
    limits = c("b_day_type1:bin", "b_block_type1:bin", "b_day_type1:block_type1", "b_Day:bin",
               "b_block:bin", "b_Day:block", "b_bin", "b_block_type1", "b_day_type1",
               "b_block", "b_Day"))+ 
  theme_bw()

print(p7)
```

```{r, Calculating and plotting the posterior predictions, message = FALSE, warning = FALSE, message = FALSE, echo=FALSE, fig.cap = "**Figure 9**: The posterior predictions of the model (blue line), compared with the empirical data from the bats (red line). Reversals are marked as the dotted line", fig.width = 9.5, fig.height = 6}

# calculating the posterior predictions 
# selecting the required columns from the analysis dataframe 
nd_choices2 <- analysis_choices2 %>% 
  select(Bat, Day, block, bin, count_vis)

# calculating the posterior predictions 
post_fit <-
  predict(m_choices2) %>% 
  as_tibble() %>% 
  mutate(Bat = nd_choices2$Bat, 
         Day = nd_choices2$Day,
         block = nd_choices2$block, 
         bin = nd_choices2$bin, 
         count_vis = nd_choices2$count_vis)

# calculating the empirical equivalents of the posterior predictions 
comparison_choices2 <- analysis_choices2 %>% 
  group_by(Bat, Day, block, bin) %>% 
  group_modify(~ mean_cl_boot(.x$reward_status, conf.int = 0.95))

# look up table for splitting the data set 
split <- data.frame(
  Bat = c("Bat5", "Bat6", "Bat8", "Bat9", "Bat10", "Bat11", "Bat12", "Bat13", "Bat14", "Bat15", "Bat16", "Bat17", "Bat18", "Bat20"),
  row = as.factor(c(rep(1, 7), rep(2, 7)))) 

# putting the calculated posterior values and the empirical values into the same table
comparison_choices2 <- left_join(comparison_choices2, post_fit, by = c("Bat", "Day", "block", "bin"))
comparison_choices2 <- left_join(comparison_choices2, split, by = "Bat") %>% 
  mutate(Day = case_when(Day == 1 ~ "Night 1", 
                         Day == 2 ~ "Night 2", 
                         Day == 3 ~ "Night 3"))

# plotting the posterior predicted values and empirical values together 
p8 <- comparison_choices2 %>% 
  filter(row == 1) %>% 
  ggplot(aes(count_vis)) + 
  #geom_point(aes(y = y), color = "red", size = 0.2) +
  geom_line(aes(y = y), color = "red") + 
  geom_ribbon(aes(ymin = ymin, ymax = ymax), fill = "red", alpha = 0.3) + 
  #geom_point(aes(y = Estimate), color = "blue", size = 0.2) + 
  geom_line(aes(y = Estimate), color = "blue", alpha = 0.5) + 
  #geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5), fill = "blue", alpha = 0.3) + 
  geom_vline(xintercept = c(50, 100, 150, 200, 250), linetype = "dashed", size = 0.2) + 
  xlab("Visit count") + 
  ylab("Proportion of visits to the rewarding flower") + 
  scale_y_continuous(breaks = c(0, 0.5, 1)) + 
  facet_grid(Day ~ Bat) + 
  theme_classic()

p9 <- comparison_choices2 %>% 
  filter(row == 2) %>% 
  ggplot(aes(count_vis)) + 
  #geom_point(aes(y = y), color = "red", size = 0.2) +
  geom_line(aes(y = y), color = "red") + 
  geom_ribbon(aes(ymin = ymin, ymax = ymax), fill = "red", alpha = 0.3) + 
  #geom_point(aes(y = Estimate), color = "blue", size = 0.2) + 
  geom_line(aes(y = Estimate), color = "blue", alpha = 0.5) + 
  #geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5), fill = "blue", alpha = 0.3) + 
  geom_vline(xintercept = c(50, 100, 150, 200, 250), linetype = "dashed", size = 0.2) + 
  xlab("Visit count") + 
  ylab("Proportion of visits to the rewarding flower") + 
  scale_y_continuous(breaks = c(0, 0.5, 1)) + 
  facet_grid(Day ~ Bat) + 
  theme_classic()

ggarrange(p8, p9, nrow = 2, ncol = 1)

```

We compared the predictive accuracy of the model that included night type and block type to the model that did not include these, using leave-one-out cross-validation. The LOO criterion was lower for the former than the latter, indicating better predictive accuracy (**Table 4**). 

```{r, Comparing the two models, message = FALSE, warning = FALSE, echo=FALSE}

# reading in the table with the model comparison 
loo_comparison <- read.csv2(file = "data/loo_comparison.csv", sep = ";", header = TRUE)
loo_comparison <- loo_comparison %>% 
  mutate(elpd_diff = round(as.numeric(elpd_diff), digits = 2), 
         se_diff = round(as.numeric(se_diff), digits = 2)) %>% 
  rename("Difference in LOO estimates" = elpd_diff, 
         "Standard error" = se_diff) 

loo_comparison <- flextable(loo_comparison, cwidth = 1.5) %>% 
  hline() %>% 
  theme_booktabs() %>% 
  set_caption("**Table 4**: Comparison of the two models of the proportion of visits to the rewarding option") %>% 
  align(align = "center", part = "all") %>% 
  # making the column names bold
  bold(part = "header") %>% 
  bold(j = 1, bold = TRUE)

loo_comparison

```

## b) Sampling visits

As the previous analyses have shown, the proportion of visits made to the rewarding option increased overall as the bats experienced more reversals, but this 'improvement' in performance decreases. We inferred that this could be for one of the following reasons. It is possible the bats' behaviour showed a 'ceiling effect': as the proportion of visits to the rewarding option is very close to 1, and the number of perseverative visits decreases, the proportion of visits to the rewarding option cannot increase much further. Another possibility is a change in the number of sampling visits. We define a sampling visit as a visit to the non-rewarding flower after the first visit to a rewarding flower in a particular block. If there is an increase in the number of sampling visits as the bats experience more reversals, this too could cause the negative interaction effect of night and block, and block and bin on the proportion of visits to the rewarding option. 

Modeling the number of sampling visits made by the bats as an effect of the night, block and bin showed that this was not, in fact, the case. The number of sampling visits does not appear to change as an effect of the increasing number of reversals: the 95% credibility intervals of the slope intercepts overlap with 0, both for the main as well as the interaction terms (**Figure 10**). In other words, the increase in the proportion of visits to the rewarding option (the 'improvement' in performance) does not appear to be affected by sampling visits.  

```{r, Model to look at the effect of night and block on the sampling visits, message = FALSE, warning = FALSE, echo=FALSE, fig.cap = "**Figure 10**: The effect of night, block and bin on the number of sampling visits. Plot of intercept and slope coefficient values of the fixed effects", fig.height= 3, fig.width=5}
#---------------------------------------------------------------------------------------------
# Setting up the model to look at the effect of night, block and bin on the number of sampling visits
#---------------------------------------------------------------------------------------------
analysis4 <- rev_learning_all %>% 
  select(-c(Group, Cage, Condition, IdRFID, SystemMsg, eventDuration, reinforce1value, reinforce1Account)) %>% 
  filter(block_vis != 0) %>% 
  ungroup() %>%
  group_by(Bat, Day, block) %>% 
  mutate(first_rew = cumsum(reward_status)) %>% 
  # removing the first block when there is no distinction between perseverative and sampling errors
  filter(block > 1, 
         # filtering the visits after the first rewarded one
         first_rew > 0,   
         #filtering the unrewarded visits
         reward_status == 0) %>%
  ungroup() %>%
  group_by(Day, Bat, block, bin) %>% 
  #counting the visits to the unrewarded flower
  summarise(sampling = n())

# m7 <-
#   brm(data = analysis4, family = negbinomial,
#       sampling ~ Day + block + bin + Day:block + block:bin + (1 + Day + block + bin | Bat),
#       prior = c(prior(normal(0, 10), class = Intercept),
#                 prior(normal(0, 10), class = b),
#                 prior(cauchy(0, 1), class = sd)),
#       iter = 4000, warmup = 2000, chains = 4, cores = 4, thin = 3, 
#       control = list(adapt_delta = 0.999, 
#                      max_treedepth = 12),
#       seed = 12)

color_scheme_set("darkgray")
load(file = "data/03_stats_rs_samp.rda")

# renaming the model appopriately
m_samp <- m7
# removing the model with the wrong name
rm(m7)

p9 <- m_samp %>% 
  mcmc_intervals(
               pars = vars(2:6), 
               point_size = 1.75, 
               prob_outer = 0.95) + 
  geom_vline(xintercept = 0) + 
      scale_y_discrete(
    labels = c("b_Day" = "Experimental night",
               "b_block" = "Reversal block", 
               "b_bin" = "Bin", 
               "b_Day:block" = "Night - block interaction", 
               "b_block:bin" = "Block - bin interaction"), 
    limits = c("b_block:bin", "b_Day:block", "b_bin", "b_block", "b_Day")) + 
  theme_bw()

p9

```

# Discussion 

# References 
