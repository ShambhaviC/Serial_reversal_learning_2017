---
title: "Nectar-feeding bats learn the rule behind serial reversals"
header-includes:
   - \usepackage{lineno}
   - \linenumbers
   - \usepackage{float} \floatplacement{figure}{H}
   - \newcommand{\beginsupplement}{\setcounter{table}{0}  \renewcommand{\thetable}{S\arabic{table}} \setcounter{figure}{0} \renewcommand{\thefigure}{S\arabic{figure}}}
always_allow_html: yes
output:
   bookdown::html_document2:
      fig_caption: yes
      number_sections: no
   bookdown::word_document2:
      fig_caption: yes
      number_sections: no
   #    fig_caption: yes
   #    number_sections: no
  # bookdown::pdf_document2:
  #   number_sections: no
  #   toc: no
  #   number_sections: no
  #   toc: no
bibliography: srl.bib
# csl: animal-cognition.csl
---

```{css style settings, echo = FALSE}
blockquote {
    margin: 0 0 20px;
    font-size: 14px;
}
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE, 
  message = FALSE, 
  warning = FALSE, 
  fig.align = "center", 
  fig.pos = "H")
```

```{r Reading-in-the-packages}
# clearing the environment
 rm(list = ls())

# installing the required packages if needed and loading them
if (!require(rmarkdown)) {
  install.packages("rmarkdown")
}
if (!require(reshape2)) {
  install.packages("reshape2")
}
if (!require(tufte)) {
  install.packages("tufte")
}
if (!require(rticles)) {
  install.packages("rticles")
}
if (!require(knitr)) {
  install.packages("knitr")
}
if (!require(shiny)) {
  install.packages("shiny")
}
if (!require(scales)) {
  install.packages("scales")
}
if (!require(tidyverse)) {
  install.packages("tidyverse")
}
if (!require(gluedown)) {
  install.packages("gluedown")
}
if (!require(glue)) {
  install.packages("glue")
}
if (!require(ggthemes)) {
  install.packages("ggthemes")
}
if (!require(lubridate)) {
  install.packages("lubridate")
}
if (!require(ggpubr)) {
  install.packages("ggpubr")
}
if (!require(gridExtra)) {
  install.packages("gridExtra")
}
if (!require(Hmisc)) {
  install.packages("Hmisc")
}
if (!require(brms)) {
  install.packages("brms")
}
if (!require(bayesplot)) {
  install.packages("bayesplot")
}
if (!require(bayestestR)) {
  install.packages("bayestestR")
}
```

```{r Themes-and-CI-functions}

# creating two themes for all the plots

theme_srl <- function() {
  theme_pubr() +
    theme(
      axis.text = element_text(size = 8, family = "Times"),
      axis.title = element_text(size = 10, family = "Times"),
      strip.text.x = element_text(size = 10, family = "Times"),
      strip.text.y = element_text(size = 10, family = "Times"),
      legend.text = element_text(size = 10, family = "Times"),
      legend.title = element_text(size = 12, face = "bold", family = "Times")
    )
}

theme_srl2 <- function() {
  theme_bw() +
    theme(
      axis.text = element_text(size = 8, family = "Times"),
      axis.title = element_text(size = 10, family = "Times"),
      strip.text.x = element_text(size = 10, family = "Times"),
      strip.text.y = element_text(size = 10, family = "Times"),
      legend.text = element_text(size = 10, family = "Times"),
      legend.title = element_text(size = 12, face = "bold", family = "Times")
    )
}
 # writing a function to automate the reporting of an estimate and error bars
report_m_ci_perc <- function(tbl, par = "_r_", brackets = "round") {
  open_bracket <- case_when(
    brackets == "round" ~ "(",
    brackets == "square" ~ "[",
    brackets == "squiggly" ~ "{",
    brackets == "none" ~ "",
    TRUE ~ str_sub(brackets, 1, 1)
  )
  
  close_bracket <- case_when(
    brackets == "round" ~ ")",
    brackets == "square" ~ "]",
    brackets == "squiggly" ~ "}",
    brackets == "none" ~ "",
    TRUE ~ str_sub(brackets, 2, 2)
  )
  
  tbl <- tbl %>% 
    mutate(CI = paste0(open_bracket, "95% CI ", ymin, ", ", ymax, close_bracket))
  
    return(glue("{tbl$y}% {tbl$CI}"))
}

# writing a function to make a table to get estimates and error bars as a model output

model_outputs <- function(model, fixed_effects) {
  
# creating a table with the required values for the forest plot
t1 <- fixef(model, 
            probs = c(0.055, 0.945)) %>%
  as_tibble() %>%
  mutate(
    `Fixed effect` = fixed_effects,
    Estimate = round(Estimate, digits = 2),
    Q5.5 = round(Q5.5, digits = 2),
    Q94.5 = round(Q94.5, digits = 2)
  ) %>%
  # renaming the credibility intervals column
  mutate("89% Credibility intervals" = paste0("[", Q5.5, ", ", Q94.5, "]")) %>%
  #filter(`Fixed effect` != "Intercept") %>%
  rename(labels = `Fixed effect`) %>%
  select(labels, Estimate, `89% Credibility intervals`) %>%
  mutate(All = paste0(Estimate, " ", `89% Credibility intervals`)) %>%
  select(labels, All)
}

# setting the maximum value on the x axis to locate the labels
max_xvalue_output <- function(model, fixed_effects) {
  
max_xvalue <- fixef(model, 
                    probs = c(0.055, 0.945))%>%
  as_tibble() %>%
  mutate(
    `Fixed effect` = fixed_effects,
    Estimate = round(Estimate, digits = 2),
    Q5.5 = round(Q5.5, digits = 2),
    Q94.5 = round(Q94.5, digits = 2)
  ) %>%
  #filter(`Fixed effect` != "Intercept") %>%
  select(Q94.5) %>%
  filter(Q94.5 == max(Q94.5)) %>%
  as.numeric()

}

```

```{r Pump-filltime-events}
#----------------------------------
# Reading in and preparing the data
#----------------------------------
# reading in the pre-processed data to demonstrate the pump fill time
alldata_pumps <- read.csv2("/Users/shambhavi/Google Drive/Experiments & Data/SRL_2017/analysis/data/processed_data/raw_data_all.csv", sep = ";", header = TRUE)

# creating a vector of the bats to be excluded from the main analysis
bats_incomp <- c("Bat 7", "Bat 19")

# creating a vector with the beta bats
bats_beta <- c("Bat 1", "Bat 2", "Bat 3", "Bat 4")

# creating a vector of the main experimental days
main_days <- c("Day 1", "Day 2", "Day 3")

#--------------------------
# Analysing the pump events
#--------------------------

# calculating the time for each refill event
pump_time <- alldata_pumps %>%
  filter(Day %in% main_days) %>% 
  group_by(Cage) %>%
  arrange(DateTime) %>%
  filter(MsgValue1 == "start pump" | MsgValue1 == "end pump") %>%
  mutate(interval = ifelse(MsgValue1 == "start pump", as.numeric(difftime(lead(DateTime), DateTime, units = "secs")), "non-fill time")) %>%
  select(DateTime, IdLabel, Condition, Cage, MsgValue1, interval) %>%
  arrange(DateTime) %>%
  filter(
    Condition == "SerialReversalCounter",
    interval != "non-fill time",
    interval < 300
  ) %>%
  mutate(interval = as.integer(interval) / 60) %>%
  summarise(
    mean_filltime = round(mean(interval), digits = 1),
    sd_filltime = round(sd(interval), digits = 2)
  )

# counting the number of fill events per night: there is exactly one so the R code is not cited in the main text
pump_fills <- alldata_pumps %>%
  filter(Condition == "SerialReversalCounter") %>%
  arrange(DateTime) %>%
  group_by(Group, Day) %>%
  mutate(hour = hour(DateTime)) %>%
  filter(
    !IdLabel %in% bats_incomp,
    !IdLabel %in% bats_beta,
    Day %in% main_days,
    hour > 18 | hour < 6,
    MsgValue1 == "start pump"
  ) %>%
  summarise(pump_events = n()) %>%
  ungroup() %>%
  summarise(fill_events = mean(pump_events))
```

```{r, Wrongly-unrewarded-visits}
#----------------------------------
# Reading in and preparing the data
#----------------------------------
# loading the prepared CSV file of raw data
rev_learning_all <- read.csv2(file = "/Users/shambhavi/Google Drive/Experiments & Data/SRL_2017/analysis/data/processed_data/raw_data_bats.csv", sep = ";", header = TRUE)

# creating a vector of the bats to be excluded from the main analysis
bats_incomp <- c("Bat 7", "Bat 19")

# creating a vector with the beta bats
bats_beta <- c("Bat 1", "Bat 2", "Bat 3", "Bat 4")

# creating a vector of the main experimental days
main_days <- c("Day 1", "Day 2", "Day 3")

# preparing a data frame with all the visits, including the proper but unrewarded ones
rev_learning_all <- rev_learning_all %>%
  filter(
    # filtering only the bats
    str_detect(IdLabel, "Bat"), 
    # removing the bats that did not complete the experiment
    !IdLabel %in% bats_incomp,
    !IdLabel %in% bats_beta,
    # taking only the three main experimental days 
    Day %in% main_days,
    # filtering out the main experimental data
    Condition == "SerialReversalCounter", 
  ) %>%
  mutate(
    # marking the difference between the normal visits in a block and the switch points
    MsgValue1 = ifelse(MsgValue1 == "switch", "switch", "block"),
    # making a column to mark the unrewarded proper visits
    reinforce1value = replace_na(reinforce1value, 0),
    reinforce1Account = replace_na(reinforce1Account, 0),
    Unrew = ifelse(reinforce1value != reinforce1Account, 1, 0)
  ) %>%
  rename(Bat = IdLabel) %>%
  #arrange(Group, Day, Bat, DateTime) %>%
  # grouping the data to count the visits, noting the reversals separately
  group_by(Bat, Day) %>%
  mutate(
    # creating a column with the total number of visits made by a bat per day
    count_vis = ifelse(MsgValue1 == "switch", 0, 1),
    count_vis = cumsum(count_vis)
  ) %>%
  # setting the maximum number of visits a night higher than the programmed max to allow for the unrewarded visits
  filter(count_vis <= 350)

#----------------------------------
# Calculating the unrewarded visits
#----------------------------------

# calculating the percentage of the bats' visits are wrongly unrewarded
mean_unrew <- rev_learning_all %>%
  group_by(Bat, Day) %>%
  filter(MsgValue1 != "switch") %>%
  summarise(mean_unrew = mean(Unrew)) %>%
  mutate(mean_unrew = mean_unrew * 100)

overall_mean_unrew <- round(as.numeric(mean(mean_unrew$mean_unrew), digits = 2))
overall_sd_unrew <- round(as.numeric(sd(mean_unrew$mean_unrew)), digits = 2)
```

# Abstract

Animals that show flexibility in their behavioural responses to environmental change have a strong advantage in foraging for food. We aimed to explore this ability in Commissaris’s long-tongued bat through a spatial serial reversal learning task. Wild bats were trained to obtain rewards from two artificial flowers. At any given time only one of the flowers provided a reward. After the bats had experienced the rewarding properties of the flowers for some time, a reversal happened: the rewarding flower became non-rewarding and *vice versa*. These reversals of rewarding properties occurred repeatedly.

We found that the bats detected and responded to the reversals of reward properties: when a food location suddenly dried up the bats abandoned visiting it and switched to the alternative, showing a near-exclusive preference for the rewarding option. The bats switched to the rewarding flower more swiftly with each successive experience of a reversal. The number of visits to the rewarding flower increased overall, driven by the increase in the number of rewarded visits immediately after each reversal. Our results are consistent with the occurrence of second-order learning, demonstrated in nectar-feeding bats for the first time.

# Introduction

Many animals live and forage in environments that change frequently and often unpredictably. The foraging environment of nectar-feeding animals mainly consists of flowering plants and the food resource they provide: nectar. Though flowers – and their nectar contents – are stationary, they bloom seasonally and single flowers on plants themselves wither and die every day or every few days, altering their efficacy with time as food resources. Thus, nectar-feeding animals face the challenge of exploiting resources that continually change with time but are relatively predictable in space. These animals need to detect the changing reward contingencies in their environment and adjust their behaviour accordingly.

Behavioural flexibility is an ability to cope with such changes. The word ‘flexibility’ has been used to mean many different things in the animal behaviour literature (often inconsistently – @audet_whats_2017), and one interpretation of the word is similar to the concept of elasticity: behavioural patterns that can be repeatedly and readily reversed [@bond_serial_2007]. An experimental protocol that has been widely used to test for and demonstrate this sort of flexibility is reversal learning [@izquierdo_neural_2017]. 

In a reversal learning task an animal must first learn about multiple stimulus-response associations, such as two spatial locations that can be approached to obtain a potential reward. The animal must then discriminate between these associations in its behaviour, according to the strength of that association. This is first-order learning [@balsters_cerebellar_2011]. When only one of the two options is rewarding, this is the only one the animal should respond to. When reinforcement at this location stops the animal should abolish its current behaviour. It is this ability to abruptly terminate a repeated behaviour and switch to another behaviour that the animal needs to have for efficient exploitation of the available resources. The information contained in the absence of an expected reward becomes a stimulus in itself. A successful animal associates this non-reward stimulus with the appropriate response, which is the inhibition of its previous behaviour and reorientation to the available alternative. In a serial reversal learning procedure the reward contingencies of the two options reverse repeatedly: one option is rewarding and the other is not; then the rewarding option stops yielding reward and the previously non-rewarding option becomes rewarding. The question then is: can an animal detect the rule of the environment that dictates change in reward contingencies, learn which cue indicates that change, and respond to this “cue of change”? When an animal responds to a stimulus that indicates environmental change through a corresponding change in its behaviour, second-order learning is said to have occurred, operating on first-order learning [@shettleworth_cognition_2010]. In a serial reversal paradigm the theoretical most successful animal (which collects the maximum possible reward) makes exactly one error per reversal. 

We carried out a serial reversal learning task with Commissaris’s long-tongued bat, (*Glossophaga commissarisi*), which primarily feeds on flower nectar. Flower visitors like these bats may often experience reversal situations in their natural environment. A flower full of nectar may remain rewarding for multiple visits before it is empty. The flower visitor should then seek another flower. However, at a later time point, when ongoing secretion has replenished nectar, a previously visited flower is rewarding again. In our experiment the bats were given two potentially rewarding options to choose between. The options were separated in space and their spatial location was the cue to indicate their reward properties at any moment. *G. commissarisi* is known to have excellent spatial memory [@thiele_hierarchical_2005] so no other cue was necessary. At the start of the night, only one of the options was rewarding, the ‘S+’ option and the other was not rewarding, the ‘S-’ option. After a certain number of visits had been made by the bats, the reward contingencies reversed without any signal or cue to the bats: the previously rewarding option was now unrewarding and the previously unrewarding option was rewarding, and this reversal happened five times in a night. The experiment was done for three consecutive nights. 

It is well known that bats alter their preference between reward sources according to their transient rewarding properties and thus show first-order learning for spatial locations (@winter_foraging_2005, @tolch_psychometric_2007, @nachev_psychophysics_2012, @nachev_cognition-mediated_2017). Thus the aim of our experiment was as follows. We tested if bats can learn to respond to stimuli that indicate that their environment has changed by then changing their own behaviour, i.e., show second-order learning. Faced with the occurrence of successive reversals, would the bats change their behavioural allocation between the two potentially rewarding options with increasing speed? Further, we were interested to see if this speed of switching from one option to another increased enough to result in one error (unrewarded visit) per reversal. 

We focused on the first experimental night when the bats experienced the reversals for the first time and showed large behavioural changes. The very first group of 50 visits, when the bats had not yet experienced any change in reward contingencies were removed from the analysis. Thus we examined the effect of reversal experience on how swiftly the bats switched to the newly rewarding option after a reversal, and how their overall behavioural allocation to the rewarding option changed. 

# Methods

## Study site and subjects

The experiment took place at La Selva Biological Field Station, Province Heredia, Costa Rica in June-July 2017. Bats of the species *Glossophaga commissarisi* were captured from the wild and retained in a flight cage through the experiment. The bats were attracted to a particular location in the forest using chicken-feeders filled with sugar-water (see **Reward**) as bait. The feeders had cotton swabs soaked in dimethyl disulphide on them, a chemical attractant produced by many bat-pollinated flowers [@von_helversen_sulphur-containing_2000] and then caught in mist-nets. The bats were sexed on capture and housed in two outdoor, meshed flight-cages (4 x 6 m) under ambient light conditions. All individuals were weighed and marked with radio frequency identification (RFID) tags placed as collars around their necks.

A total of 16 bats participated in the main experiment and the first stage of the experiment began on the same night the bats entered the cages. A group of four experimental bats of the same sex were placed in a flight cage together. Two such groups were run in parallel, one in each flight-cage so the data were collected simultaneously. At the end of the experiment, the RFID collars were removed and the bats were released back into the wild. All the data collection was completely automatized. Two of the bats did not drink a sufficient amount of sugar-water to meet minimum energy requirements. These two bats were released before the end of the experiment and not replaced, and the data from these two individuals were not analyzed. Thus, 14 bats (7 males and 7 females) completed the experiment. Permission for this research was granted by Sistema Nacional de Areas de Conservación (SINAC) at the Ministerio de Ambiente y Energía (MINAE), Costa Rica.

## Experimental Setup

### Reward

The reward received by the bats during the experiment was also their main source of food. The reward was a 17% by weight solution of sugar dissolved in water, hereafter referred to as ‘nectar’. The sugar consisted of a 1:1:1 mass-mixture of sucrose, fructose and glucose. The nectar was thus similar in composition and concentration to the nectar produced by wild chiropterophilous plants [@baker_sugar_1998]. Every night, the bats were also given *ad-libitum* access to 10 mL of supplemental food: 3.5 g of hummingbird food (NektarPlus, Nekton, Germany) and 3.5 g of milk powder (Nido 1+, Nestle, Switzerland) in 10 mL of water. The bats in each cage were also given a small bowl of locally-sourced bee pollen.

### Flower and pump setup

Each flight cage had a square plastic frame in the center (2 × 2 × 1.5 m). Eight reward-dispensing devices - hereafter referred to as ‘flowers’ - were fixed in a radial pattern on this frame, two on each side of the square (figure \@(fig:Schematic)) with a distance of 40 cm between adjacent flowers. At this distance, bats can easily discriminate neighbouring flowers [@thiele_hierarchical_2005]. Each flower had the following parts: an RFID reader mounted on a plastic cylinder around the head of the flower; an infra-red photo gate; and an electronic pinch valve through which a silicon tube was placed and fixed to the head of the flower.

A stepper-motor pump was placed in the center of the plastic frame in each cage. The pumps contained a 25 mL Hamilton glass syringe (Sigma Aldrich, Germany). The step volume of the two pumps differed slightly: the pump in Cage 1 delivered `r round(40/19, digits = 2)` $\mu$L per step of the stepper-motor, and the pump in Cage 2, `r round(40/12, digits = 2)` $\mu$L per step. The glass syringe was connected to the tubing system of the flowers through five pinch valves [@nachev_psychophysics_2012]. The pinch valves controlled the flow of liquid from the pump to the system and from a reservoir of liquid to the pump. The reservoir (500 mL thread bottle, Roth, Germany) was filled with fresh nectar every day and was connected to the syringe through the valves.

Every day at around 1000 h, the old nectar was emptied from the system, which was rinsed and filled with plain water until 1500 h, when it was filled again with fresh nectar. Twice a week, the system was filled with 70% ethanol for an hour to prevent microbial growth, then repeatedly rinsed with water.

When a tagged bat approached a flower, the individual RFID number was read. If the bat then poked its nose into the flower and interrupted the light beam, this could trigger the release of a reward. The pinch valve opened and the pump moved the correct number of pre-programmed steps to dispense nectar to the head of the flower. The bat could easily hover in front of the flower and lick up the nectar. A reward was given only when both events occurred, i.e., the RFID reader identified a bat and the photo gate was triggered. The flowers and the pump were connected to a Windows PC, which ran the experimental programs and the program used to automatically flush, clean and fill the pump and tubing system (PhenoSoft Control, PhenoSys, Germany).

(ref:Schematic) Schematic of the cage and flower set-up (not drawn to scale)

```{r, Schematic, fig.cap= "(ref:Schematic)"}

include_graphics("/Users/shambhavi/Google Drive/Experiments & Data/SRL_2017/analysis/images/cage_schematic.png")
```

## Experimental procedure

Out of the array of eight flowers, each bat was uniquely assigned two adjacent flowers on the same side of the square frame, programmed to reward only one of the four bats in the cage. After the system was filled with fresh nectar at approximately 1700 h, the program was left running for data-collection till the next morning. Thus, the bats could begin visiting the flowers to collect a reward whenever they chose, which was at nightfall at approximately 1800 h every night. During the main experiment, the bats could make a maximum of 300 visits a night.

During the course of the night, when the syringe of the pump had been emptied, the pump re-filled automatically. This event happened only once every night. On the main experimental days this process took `r as.numeric(pump_time[1, 2])` minutes (SD = ±`r as.numeric(pump_time[1 ,3])`) for the horizontal pump, and `r as.numeric(pump_time[2, 2])` minutes (SD = ±`r as.numeric(pump_time[2, 3])`) for the vertical pump.

About `r overall_mean_unrew` % (SD = ±`r overall_sd_unrew`) of all visits made by the bats over all three experimental nights were wrongly unrewarded: the bats did not receive a reward during these visits even when the visits were made to a flower assigned to them that was rewarding at the time. This happened either during the pump refill times or when the pump was moving to reward a visit made by another bat that happened almost at the same time. Such events did not count towards the total of 300.

## Experimental design

The experiment proceeded through the following stages.

### Training

On the night the naïve bats were captured and placed into the flight cages, they could receive a reward from any of the flowers whenever they visited them throughout the night. To enable the bats to find the flowers, a small cotton pad soaked in dimethyl disulphide was placed on each flower. A small drop of honey was applied to the inside of the flowers to encourage the bats to place their heads inside, interrupt the photo gate, and trigger a nectar reward. By the end of the night, all the bats had found the flowers and learned to trigger rewards.

The next stage of training involved assigning the bats uniquely to two out of the eight flowers in the array. For an individual animal, only the two flowers assigned to it would elicit rewards from this stage of training until the end of the experiment. This stage was similar to the previous one, except the bats could only trigger a reward at their assigned flowers, and the chemical attractant and honey were not used.

To ensure that the bats were familiar with both flowers assigned to them, the bats went through one final stage of training: forced alternation. The bats received a reward at one of the two flowers for one trial, and then could only receive reward at the other flower for the next trial. In this way the bats had to alternate between the two flowers every single trial.  

### Serial Reversal Learning Task

In the serial reversal learning task, the bats had continuous access to two flowers: one that gave a 40 $\mu$L nectar reward, and one that remained empty. The location of the rewarding flower was not cued; however, after completing the alternation training phase, each bat knew the locations of both flowers that were potentially rewarding to it. After a bat had made 50 visits in total to the two flowers (regardless of relative allocation), a reversal occurred: the previously rewarding flower became the non-rewarding flower and *vice versa*. Importantly, only visits to the two flowers assigned to a bat counted towards the visit tally. Each set of 50 visits to the assigned two flowers, either at the start of each night or between reversals, was termed a ‘block’. There were six blocks and five reversals per night, unless the bat ceased visiting earlier. This was repeated for three consecutive nights. The same flower started the sequence every night. Consequently, the last flower to be rewarding one night was non-rewarding at the start of the next .

## Data analysis

The raw data collected during this study were the computer-logged events of feeder visits. Each event included the time stamp, animal ID, photo gate interruption duration and the volume of nectar dispensed. The bats made some visits and approaches to the flowers that were not assigned to them; however, these were in the minority, and were not considered for the analysis (see **Supplementary Material** for details). Each of the three experimental nights had five reversals, one at the end of each of the first five blocks; the end of the last block was the end of data-collection for the night. Each block was further divided into five bins of ten visits, in order to examine the bats’ behaviour within each block. R was used for all statistical analyses and creation of plots.

All the statistical models were fitted in a Bayesian framework using Hamiltonian Monte Carlo in the R package `brms` [@burkner_brms_2017] which is a front-end for `rstan` [@carpenter_stan_2017]. Generalized linear mixed models were used for the analyses (see **Supplementary Information** for the technical details of the model fitting). We report here the mean as a measure of central tendency and the 89% quantile-based credible intervals for the intercept and slope coeffients (89% boundaries are the default for reporting credible intervals – @mcelreath_statistical_2020). To aid in the interpretation of the model parameters we also present plots of the conditional effects of some of the predictor variables. 

Our analyses were focused on the first experimental night, when the bats experienced reversals for the first time and the effect of the reversals on the bats' behaviour was strongest. In order to quantify second-order learning, the first 25 visits in each block of the first night were considered. Our aim was to quantify how swiftly the bats switched from the previously-rewarding option to the newly-rewarding one, and this switch happened in this portion of the block. The area under the curve of these data points was calculated by the composite trapezoid rule: connecting all the points by a direct line using the R package `bayestestR` [@makowski_bayestestr_2019]. We then investigated the effect of reversal number on the areas under the curves by fitting a generalized linear mixed-model to the data. By definition, the very first block of the night was excluded as no reversal had been experienced at the start of this block. We then investigated the effect of block, bin and their interaction on the proportion of visits to the rewarding flower. The proportion of visits to the rewarding flower was calculated as the number of visits to the S+ divided by total number of visits to both the S+ and S-, and we denoted this as the Prop~rew~. A separate but similar model was fit to the data from the second and third nights, calculating the effect of experimental night, block and bin on the Prop~rew~. 

A few of the results report 95% confidence intervals, as opposed to credible intervals, and these are noted specifically. The confidence intervals were calculated by non-parametric bootstrapping without assuming a normal distribution of the data, using the `Hmisc` package **(Harrell 2021)**. 

## Data availability

All data and analysis code are available online at .....


# Results 

## A consistently high proportion of the bats' visits go to the rewarding option

```{r, Preparing-main-data}
#----------------------------------------
# Preparing data from the main experiment
#----------------------------------------
# The following terms are used in the analysis of the data:
# 1. Day: a single experimental night during which the data were collected
# 2. block: a group of 50 visits between each reversal where the same flower is rewarding
# 3. bin: a smaller group of visits within a block, the size of which can be set in the code below
# 4. visits: each individual flower visit

# setting binsize and breaks for cutting up the data into block and bin
binsize <- 10
breaks <- seq(0, 3000, binsize)

# making a separate data frame without any unrewarded visits and preparing it further with block and bin numbers
rev_learning <- rev_learning_all %>%
  arrange(Bat, DateTime) %>% 
  filter(Unrew == 0) %>%
  select(-Unrew) %>%
  # grouping the data to count the visits, noting the reversals separately
  group_by(Bat, Day) %>%
  mutate(count_vis = 1:n()) %>% 
  mutate(
    # noting whether the bat made a visit to the more or less rewarding flower
    reward_status = ifelse(reinforce1value > 0, 1, 0),
    # creating a column with the total number of visits made by a bat per day
    count_vis = ifelse(MsgValue1 == "switch", 0, 1)) %>% 
  # removing the visits that are numbered as 0
  #filter(count_vis > 0) %>% 
    # taking the cumulative sum of the visit counts
  mutate(count_vis = cumsum(count_vis)) %>%
  # setting the maximum number of visits a night
  filter(count_vis <= 300) %>%
  ungroup() %>%
  # creating a column with the block number, marking the reversals
  mutate(block = ifelse(MsgValue1 == "switch", 1, 0)) %>%
  group_by(Day, Bat) %>%
  mutate(block = cumsum(block)) %>%
  ungroup() %>%
  group_by(Day, Bat, block) %>%
  # creating a column with the number of visits within each block
  mutate(
    block_vis = ifelse(MsgValue1 == "switch", 0, 1),
    block_vis = cumsum(block_vis), 
  # cutting the visits inside each block into bin of the size set earlier
    bin = as.numeric(cut(block_vis, breaks, include.lowest = TRUE)))

#----------------------------------------------------------------------------
# Calculating the proportion of visits to the rewarding option averaged over all the bats
#----------------------------------------------------------------------------
# averaging the bats' choice behaviour over day, block and bin
rev_learning_avg <- rev_learning %>%
  ungroup() %>% 
  group_by(Day, block) %>%
  mutate(n_bats = n_distinct(Bat)) %>%
  group_by(Day, block, n_bats, bin) %>%
  # calculating the 95% confidence intervals
  group_modify(~ mean_cl_boot(.x$reward_status, conf.int = 0.95)) %>%
  ungroup() %>%
  group_by(Day) %>%
  mutate(
    day_bin = 1:n(),
    day_bin_vis = day_bin * binsize,
    reversal = ifelse(block != lead(block), "switch", "block")
  )

# creating a look-up table so the reversals can be marked
rev_main_avg <- rev_learning_avg %>%
  filter(
    reversal == "switch",
    Day %in% main_days
  ) %>%
  select(Day, block, day_bin, day_bin_vis) %>%
  mutate(Day = case_when(
    Day == "Day 1" ~ "Night 1",
    Day == "Day 2" ~ "Night 2",
    Day == "Day 3" ~ "Night 3"
  ), 
  day_bin_vis = day_bin_vis)

# calculating the sample size in each block
bat_labels <- rev_learning_avg %>%
  select(Day, block, n_bats) %>%
  distinct() %>%
  group_by(Day, block) %>%
  mutate(day_bin_vis = ifelse(block == 1, 25, 50)) %>%
  ungroup() %>%
  group_by(Day) %>%
  mutate(day_bin_vis = cumsum(day_bin_vis)) %>%
  filter(Day %in% main_days) %>%
  mutate(Day = case_when(
    Day == "Day 1" ~ "Night 1",
    Day == "Day 2" ~ "Night 2",
    Day == "Day 3" ~ "Night 3"
  ))

rev_learning_block_avg <- rev_learning %>%
  ungroup() %>% 
  group_by(Day, block) %>%
  mutate(n_bats = n_distinct(Bat)) %>%
  group_by(Day, block, n_bats) %>%
  # calculating the 95% confidence intervals
  group_modify(~ mean_cl_boot(.x$reward_status, conf.int = 0.95)) %>%
  ungroup() %>%
  group_by(Day) %>%
  mutate(
    day_bin = 1:n(),
    day_bin_vis = day_bin * binsize,
    reversal = ifelse(block != lead(block), "switch", "block")
  )
```

``` {r, S+-some-bins}
#-------------------------------------------------------------
# Calculating values for visits to the S+ for some of the bins
#-------------------------------------------------------------

# calculating and saving the values for the proportion of visits to the rewarding option in some of the bins
day1bin1 <- rev_learning %>%
  ungroup() %>%
  filter(
    Day == "Day 1",
    block == 1,
    bin == 1
  ) %>%
  mutate(reward_status = reward_status * 100) %>%
  group_modify(~ mean_cl_boot(.x$reward_status, conf.int = 0.95)) %>%
  mutate(
    y = round(y, digits = 1),
    ymin = round(ymin, digits = 1),
    ymax = round(ymax, digits = 1)
  )

day1bin2 <- rev_learning %>%
  ungroup() %>%
  filter(
    Day == "Day 1",
    block == 1,
    bin == 2
  ) %>%
  mutate(reward_status = reward_status * 100) %>%
  group_modify(~ mean_cl_boot(.x$reward_status, conf.int = 0.95)) %>%
  mutate(
    y = round(y, digits = 1),
    ymin = round(ymin, digits = 1),
    ymax = round(ymax, digits = 1)
  )

day1bin5 <- rev_learning %>%
  ungroup() %>%
  filter(
    Day == "Day 1",
    block == 1,
    bin == 5
  ) %>%
  mutate(reward_status = reward_status * 100) %>%
  group_modify(~ mean_cl_boot(.x$reward_status, conf.int = 0.95)) %>%
  mutate(
    y = round(y, digits = 1),
    ymin = round(ymin, digits = 1),
    ymax = round(ymax, digits = 1)
  )

day1bin6 <- rev_learning %>%
  ungroup() %>%
  filter(
    Day == "Day 1",
    block == 2,
    bin == 1
  ) %>%
  mutate(reward_status = reward_status * 100) %>%
  group_modify(~ mean_cl_boot(.x$reward_status, conf.int = 0.95)) %>%
  mutate(
    y = round(y, digits = 1),
    ymin = round(ymin, digits = 1),
    ymax = round(ymax, digits = 1)
  )

day1bin10 <- rev_learning %>%
  ungroup() %>%
  filter(
    Day == "Day 1",
    block == 2,
    bin == 5
  ) %>%
  mutate(reward_status = reward_status * 100) %>%
  group_modify(~ mean_cl_boot(.x$reward_status, conf.int = 0.95)) %>%
  mutate(
    y = round(y, digits = 1),
    ymin = round(ymin, digits = 1),
    ymax = round(ymax, digits = 1)
  )

day1last3bins <- rev_learning %>%
  ungroup() %>%
  filter(
    Day == "Day 1",
    block > 1,
    bin > 2
  ) %>%
  mutate(reward_status = reward_status * 100) %>%
  group_modify(~ mean_cl_boot(.x$reward_status, conf.int = 0.95)) %>%
  mutate(
    y = round(y, digits = 1),
    ymin = round(ymin, digits = 1),
    ymax = round(ymax, digits = 1)
  )
```

The bats made a very high number of visits to the rewarding option. When a reversal occurred the bats abandoned the option that had been rewarding until then and switched to making most of their visits to the newly-rewarding option (figure \@ref(fig:overall-summary)a)). A consistent pattern emerged over all three nights: a sharp decrease in the proportion of visits to the previously-rewarding option immediately following a reversal, then a rapid increase in visits to the newly-rewarding option. 

At the start of the first night, in the very first bin of ten visits when the bats did not yet have any information about the available options and had never experienced a reversal, the Prop~rew~ (the proportion of visits to the rewarding option) averaged across individuals was at chance level: `r report_m_ci_perc(day1bin1, par = "y", brackets = "square")`, about 5 out of the 10 visits. Within the next ten visits however, Prop~rew~ increased to `r report_m_ci_perc(day1bin2, par = "y", brackets = "square")` and by the last bin of this first block was `r report_m_ci_perc(day1bin5, par = "y", brackets = "square")`. Immediately after the first experience of a reversal, the Prop~rew~ dropped down to `r report_m_ci_perc(day1bin6, par = "y", brackets = "square")` in the first ten visits, but came back up to `r report_m_ci_perc(day1bin10, par = "y", brackets = "square")` by the last bin of this block of fifty visits.

(ref:overall-summary) a) Visits to the rewarding of two options across the three experimental nights. Data are average proportions for bins of ten visits averaged over all 14 individuals. Data are indicated by white points in the first block on the first night before the bats had experienced any reversals; the bin averages of the other blocks are indicated by black points. b) Average propotion of visits to the rewarding of two options per block. The data-point indicated by a white point in the first block of the first night was before the bats had experienced any reversals; the averages of the other blocks are indicated by black points. Numbers indicate the bats that participated in a block. Shading shows 95% confidence intervals. Dashed lines show reversals  

```{r, overall-summary, fig.cap = "(ref:overall-summary)", fig.width = 9, fig.height = 6}

p1 <- rev_learning_avg %>%
  # filtering only the first three main Days of the experiment:
  # one group had the experiment extended a further three Days
  filter(Day == "Day 1") %>%
  mutate(
    Day = case_when(
      Day == "Day 1" ~ "Night 1"
    ),
    firstpoint = as.factor(ifelse(block == 1 & Day == "Night 1", 1, 0)), 
    day_bin_vis = day_bin_vis - 5
  ) %>%
  ggplot(aes(day_bin_vis, y)) +
  geom_point(aes(color = firstpoint, fill = firstpoint), shape = 21) +
  scale_color_manual(values = c("0" = "black", "1" = "black")) +
  scale_fill_manual(values = c("0" = "black", "1" = "white")) +
  geom_line() +
  geom_ribbon(aes(ymin = ymin, ymax = ymax), alpha = 0.3) +
  facet_grid(. ~ Day) +
  scale_x_continuous(breaks = seq(50, 300, by = 50)) +
  scale_y_continuous(breaks = seq(0, 1.1, by = 0.25)) +
  geom_vline(aes(xintercept = day_bin_vis), data = rev_main_avg %>% filter(Day == "Night 1"), linetype = "dashed") +
  geom_hline(yintercept = c(0.25, 0.5, 0.75, 1), linetype = "dotted") +
  theme_srl2() +
  geom_text(
    data = bat_labels  %>% filter(Day == "Night 1"),
    aes(x = day_bin_vis, y = 1.05, label = n_bats, group = n_bats), family = "Times"
  ) +
  labs(x = "Visits", y = "Visits to the rewarding option") +
  theme(legend.position = "none")

# p1.5 <- rev_learning_block_avg %>%
#   # filtering only the first three main Days of the experiment:
#   # one group had the experiment extended a further three Days
#   filter(Day %in% main_days) %>%
#   mutate(
#     Day = case_when(
#       Day == "Day 1" ~ "Night 1",
#       Day == "Day 2" ~ "Night 2",
#       Day == "Day 3" ~ "Night 3"
#     ),
#     firstpoint = as.factor(ifelse(block == 1 & Day == "Night 1", 1, 0)), 
#     day_bin_vis = day_bin_vis - 5
#   ) %>%
#   ggplot(aes(block, y)) +
#   geom_point(aes(color = firstpoint, fill = firstpoint), shape = 21) +
#   scale_color_manual(values = c("0" = "black", "1" = "black")) +
#   scale_fill_manual(values = c("0" = "black", "1" = "white")) +
#   geom_line() +
#   geom_ribbon(aes(ymin = ymin, ymax = ymax), alpha = 0.3) +
#   facet_grid(. ~ Day) +
#   scale_x_continuous(breaks = seq(1, 6, by = 1)) +
#   scale_y_continuous(breaks = seq(0, 1.1, by = 0.25)) +
#   #geom_vline(aes(xintercept = c(1, 2), linetype = "dashed")) +
#   geom_hline(yintercept = c(0.25, 0.5, 0.75, 1), linetype = "dotted") +
#   theme_srl2() +
#   geom_text(
#     data = bat_labels,
#     aes(x = block, y = 1.05, label = n_bats, group = n_bats), family = "Times"
#   ) +
#   labs(x = "Block", y = "Visits to the rewarding option") +
#   theme(legend.position = "none")

p1
```

## Bats switch to the rewarding option faster as they experience more reversals

On the first experimental night the area under the curve formed by the proportion of the bats' visits to the rewarding option in the first 25 visits of a block increased with the each reversal the bats experienced (figure \@ref(fig:areas-under-the-curves) and \@ref(fig:area-under-the-curve-all-reversals)). This is the part of each block where perseverative visits occur, i.e., visits to the previously rewarding option after a reversal has occurred. 

(ref:areas-under-the-curves) Areas under the curves formed by the proportion of visits to the rewarding option out of the first 25 visits after each reversal on the first night. Thin coloured lines are data from the individual bats; the thick red line is the average area under the curve of all the bats. 

```{r areas-under-the-curves, fig.cap = "(ref:areas-under-the-curves)", fig.width = 6, fig.height = 4}

# setting a different binsize to group the data
binsize_five <- 5
breaks_five <- seq(0, 3000, binsize_five)

# creating a separate dataframe with the data from the first night
rev_learning_first_night <- rev_learning %>% 
  # filtering out the first night
  filter(Day == "Day 1") %>%
  # binning the data
  mutate(bin_five = as.numeric(cut(block_vis, breaks_five, include.lowest = TRUE))) %>% 
  ungroup() %>% 
  select(Bat, block, bin, reward_status, block_vis, bin_five) %>% 
  # grouping by block
  group_by(Bat, block) %>% 
  # calculating the average proportion of visits to rewarding flower for each bat and each block
  mutate(block_average = mean(reward_status)) %>% 
  ungroup() %>% 
  group_by(Bat, block, block_average, bin_five) %>%
  # calculating the average proportion of visits to the rewading flower for each bat, block and bin
  summarise(bin_five_average = mean(reward_status)) %>%
  ungroup() %>% 
  group_by(Bat) %>% 
  # calculating the total number of visits per animal over the whole night
  mutate(total_vis = 1:n())

areas_under_curves <- rev_learning_first_night %>% 
  ungroup() %>% 
  group_by(Bat, block) %>% 
  mutate(
    # creating a column to note which blocks have 25 visits or more as this will be the parts of the blocks that are analyzed
         keep_2 = max(bin_five)/2
         ) %>% 
  # filtering the blocks after the first reversal had been 
  # experienced, and the blocks that had the first half complete
  filter(
         block > 1, 
         bin_five <= 5, 
         keep_2 == 5
         ) %>% 
  ungroup() %>%
  # selecting the required columns
  select(Bat, block, total_vis, bin_five, bin_five_average) %>% 
  group_by(Bat, block) %>%
  # calculating the area under the curve
  summarise(auc = area_under_curve(total_vis, bin_five_average), 
            auc = round(auc, digits = 2))

# plotting out the areas under the curves 
p4 <- areas_under_curves %>% 
  mutate(block = block - 1) %>% 
  ungroup() %>% 
  group_by(block) %>% 
  mutate(block_mean = mean(auc)) %>% 
  ggplot() + 
  #geom_point() + 
  geom_line(aes(block, auc, group = Bat, colour = Bat)) +
  geom_line(aes(block, block_mean), colour = "red", size = 2) + 
  xlab("Reversal number on the first night") + 
  ylab("Area under the curve") + 
  #scale_y_continuous(breaks = seq(0, 4, by = 0.5)) + 
  theme_srl2()
  
p4
```

(ref:area-under-the-curve-all-reversals) a) Forest plot of the regression coeffients from the model of the effect of reversal on the area under the curve of the bats' choice data. Circles represent the means of the posterior distributions of the slope coefficients, thick horizontal lines represent 50% credible intervals, and thin horizontal lines 89% credible intervals. The numbers in bold are the means of the posterior distributions and 89% credible intervals b) Conditional effects plot from the model of the effect of reversal on the area under the curve of the bats' choice data, sampling from the posterior distribution.

```{r area-under-the-curve-all-reversals, fig.cap = "(ref:area-under-the-curve-all-reversals)", fig.width = 12, fig.height = 3}

# displaying the priors for the model 
# get_prior(data = areas_under_curves, family = gaussian,
#       auc ~ block + (1 + block|Bat))

# fitting the model
# m.areas.under.curves <-
#   brm(data = areas_under_curves, family = gaussian,
#       # allowing the slopes and intercepts to vary by bat
#       auc ~ block + (1 + block|Bat),
#       iter = 3000, warmup = 1500, chains = 4, cores = 4, thin = 3,
#       control = list(adapt_delta = 0.999, max_treedepth = 15),
#       seed = 12)

# saving the model
# save(m.areas.under.curves, file = "data/processed_data/m.areas.under.curves.rda")

# loading the model
load("data/processed_data/m.areas.under.curves.rda")

# setting the colour scheme
color_scheme_set("darkgray")

# setting the names of the fixed effects
fixed_effects = c("Intercept", "Reversal")

# putting the model's estimates into a table
t1_estimates <- model_outputs(m.areas.under.curves, fixed_effects)

# finding the maximum x value in the fixed effects of the model
max_xvalue <- max_xvalue_output(m.areas.under.curves, fixed_effects)

# creating a plot of the slope coefficients
p5 <- mcmc_intervals(m.areas.under.curves,
  point_size = 1.1,
  pars = vars(1:4),
  prob_outer = 0.89
) +
  xlim(-0.5, max_xvalue + 0.6) +
  geom_vline(xintercept = 0) +
  scale_y_discrete(
    labels = c(
      "b_Intercept" = "Intercept",
      "b_block" = "Reversal number"
    ),
    limits = c("b_block", "b_Intercept")
  ) +
  geom_text(
    data = t1_estimates,
    aes(x = max_xvalue + 0.1, y = c(2, 1), label = All, fontface = "bold", family = "Times"), size = 3, hjust = 0
  ) +
  theme_srl2()

# setting the conditions for the conditional effects plots 
int_conditions <- list(block = c(2,3,4,5,6))

# calculating the conditional effects
m_areas_under_curves <- conditional_effects(m.areas.under.curves, int_conditions = int_conditions, prob = 0.89, nsamples = 150)

#plotting out the conditional effects 
p6 <- plot(m_areas_under_curves, plot = FALSE, line_args = c(alpha = 1/5)) [[1]] +
  xlab("Experimental night") +
  ylab("Perseverative \n visits") +
  scale_x_continuous(breaks = seq(1,5,by = 1)) +
  #scale_y_continuous(breaks = seq(1.5, 2.5, by = 0.5)) +
  #ylim(1.5, 4) + 
  xlab("Reversal number on the first night") + 
  ylab("Posterior estimate of \n the area under the curve") + 
  theme_srl2()

# plotting it out
ggarrange(p5, p6, ncol = 2, labels = c("a)","b)"), font.label = list(face = "plain", family = "Times New Roman", size = 8))
```

The average proportions of visits to the rewarding option in each block of 50 visits plotted in figure (\@ref(fig:overall-summary)b)) show that on all three nights, the highest number of visits to the rewarding option occurred in the first block. On the first night, there was a decrease in the second block followed by an increase in the succeeding blocks. The second block, just after the first reversal of the first night is unique, as it is the very first time the bats experience a reversal in the main experiment. The effect of reversal on the area under the curve persists even when the data in the second block are removed from the analysis (figure \@ref(fig:area-under-the-curve-all-but-first-reversal)b)). 

(ref:area-under-the-curve-all-but-first-reversal) a) Forest plot of the regression coeffients from the model of the effect of reversal on the area under the curve of the bats' choice data, excluding the very first reversal (the second block). Circles represent the means of the posterior distributions of the slope coefficients, thick horizontal lines represent 50% credible intervals, and thin horizontal lines 89% credible intervals. The numbers in bold are the means of the posterior distributions and 89% credible intervals b) Conditional effects plot from the model of the effect of reversal - excluding the first reversal - on the area under the curve of the bats' choice data, sampling from the posterior distribution.

```{r area-under-the-curve-all-but-first-reversal, fig.cap = "(ref:area-under-the-curve-all-but-first-reversal)", fig.width = 12, fig.height = 3}

# creating a dataset with all the reversals but leaving out the first one
areas_under_curves_lastblocks <- areas_under_curves %>%
  filter(block > 2)

# fitting a similar model of the areas under the curves but leaving out the first reversal
# m.areas.under.curves.lastblocks <-
#   brm(data = areas_under_curves_lastblocks, family = gaussian,
#       auc ~ block + (1 + block|Bat),
#       iter = 3000, warmup = 1500, chains = 4, cores = 4, thin = 3,
#       control = list(adapt_delta = 0.999, max_treedepth = 15),
#       seed = 12)

# saving the model
# save(m.areas.under.curves.lastblocks, file = "data/processed_data/m.areas.under.curves.lastblocks.rda")

# loading the model
load("data/processed_data/m.areas.under.curves.lastblocks.rda")

# setting the colour scheme
color_scheme_set("darkgray")

# setting the names off the fixed effects
fixed_effects = c("Intercept", "Reversal")

# putting the model's estimates into a table
t1_estimates <- model_outputs(m.areas.under.curves.lastblocks, fixed_effects)

# finding the maximum x value in the fixed effects of the model
max_xvalue <- max_xvalue_output(m.areas.under.curves.lastblocks, fixed_effects)

# creating a plot of the slope coefficients
p7 <- mcmc_intervals(m.areas.under.curves.lastblocks,
  point_size = 1.1,
  pars = vars(1:4),
  prob_outer = 0.89
) +
  xlim(-0.5, max_xvalue + 0.6) +
  geom_vline(xintercept = 0) +
  scale_y_discrete(
    labels = c(
      "b_Intercept" = "Intercept",
      "b_block" = "Reversal number"
    ),
    limits = c("b_block", "b_Intercept")
  ) +
  geom_text(
    data = t1_estimates,
    aes(x = max_xvalue + 0.1, y = c(2, 1), label = All, fontface = "bold", family = "Times"), size = 3, hjust = 0
  ) +
  theme_srl2()

# setting the conditions for the conditional effects plots 
int_conditions <- list(block = c(3,4,5,6))

# calculating the conditional effects
m_areas_under_curves_lastblocks <- conditional_effects(m.areas.under.curves.lastblocks, int_conditions = int_conditions, prob = 0.89, nsamples = 150)

#plotting out the conditional effects 
p8 <- plot(m_areas_under_curves_lastblocks, plot = FALSE, line_args = c(alpha = 1/5)) [[1]] +
  xlab("Experimental night") +
  ylab("Perseverative \n visits") +
  scale_x_continuous(breaks = seq(1,5,by = 1)) +
  #scale_y_continuous(breaks = seq(1.5, 2.5, by = 0.5)) +
  ylim(1.5, 4) + 
  xlab("Reversal number on the first night") + 
  ylab("Posterior estimate of \n the area under the curve") +
  theme_srl2()

# plotting it out
ggarrange(p7, p8, ncol = 2, labels = c("a)","b)"), font.label = list(face = "plain", family = "Times New Roman", size = 8))
```

## Bats make more visits to the rewarding flower as they experience more reversals 

On the first night, apart from the increasingly faster switch to the rewarding option after a reversal, the Prop~rew~ increased as the bats experienced more reversals in two ways: over the entire night as an effect of reversal; and within each reversal block as an effect of 10-visit bins. The interaction effect of the reversal and bin showed that the increase in the visits to the rewarding option was driven by the effect of the first bin of 10 visits in each block. (figure \@ref(fig:first-night-first-block-removed)); in the last two bins of every block there was a consistently high number of rewarded visits. These effects of bin and reversal persisted even when the second block, following the first reversal, was removed from the analysis (figure \@ref(fig:first-night-first-two-blocks-removed)). 

```{r area-under-curve-all-visits}

areas_under_curves_allvisits <- rev_learning_first_night %>% 
  ungroup() %>% 
  group_by(Bat, block) %>% 
  mutate(
    # creating a column to note which blocks have 25 visits or more as this will be the parts of the blocks that are analyzed
         keep_2 = max(bin_five)
         ) %>% 
  # filtering the blocks after the first reversal had been 
  # experienced, and the blocks that had the first half complete
  filter(
         block > 1, 
         #bin_five <= 5, 
         keep_2 == 10
         ) %>% 
  ungroup() %>%
  # selecting the required columns
  select(Bat, block, total_vis, bin_five, bin_five_average) %>% 
  group_by(Bat, block) %>%
  # calculating the area under the curve
  summarise(auc = area_under_curve(total_vis, bin_five_average), 
            auc = round(auc, digits = 2))

#fitting the model
# m.areas.under.curves.all.visits <-
#   brm(data = areas_under_curves_allvisits, family = gaussian,
#       # allowing the slopes and intercepts to vary by bat
#       auc ~ block + (1 + block|Bat),
#       iter = 3000, warmup = 1500, chains = 4, cores = 4, thin = 3,
#       control = list(adapt_delta = 0.999, max_treedepth = 15),
#       seed = 12)
# 
# # saving the model
# save(m.areas.under.curves.all.visits, file = "data/processed_data/m.areas.under.curves.all.visits.rda")

# loading the model
load("data/processed_data/m.areas.under.curves.all.visits.rda")

# setting the names off the fixed effects
fixed_effects = c("Intercept", "Reversal")

# putting the model's estimates into a table
t1_estimates <- model_outputs(m.areas.under.curves.all.visits, fixed_effects)
```

This was consistent with the result that reversal number also had an effect on the area under the curve of the entire reversal block, and not just the first 25 visits in a block (Mean and 89% credible intervals: intercept - `r t1_estimates[1,2]`; slope coefficient -`r t1_estimates[2,2]`). The bats made more visits to the rewarding option with each experience of a reversal, primarily because they switched to the rewarding option faster with each reversal. 

(ref:first-night-first-block-removed) a) Forest plot of the regression coeffients from the model of the effect of reversal and 10-visit bin on the visits to the rewarding flower. Circles represent the means of the posterior distributions of the slope coefficients, thick horizontal lines represent 50% credible intervals, and thin horizontal lines 89% credible intervals. The numbers in bold are the means of the posterior distributions and 89% credible intervals b) Conditional effects plot from the model of the effect of reversal and 10-visit bin on the visits to the rewarding flower showing the two-way interaction between reversal and bin, sampling from the posterior distribution.

```{r first-night-first-block-removed, fig.cap = "(ref:first-night-first-block-removed)", fig.width = 18, fig.height = 5}

# creating a table of the data from the first night with the first block removed
analysis_choices_firstnight_nofirstblock <- rev_learning %>% 
  ungroup() %>% 
  select(Day, block, bin, Bat, reward_status, block_vis, count_vis) %>% 
  filter(block_vis != 0) %>% 
  # removing the space temporarily and changing the Day back to numbers as this is how it was done in the model 
  mutate(Bat = str_remove_all(Bat, " "),
         Day = case_when(Day == "Day 1" ~ 1, 
                         Day == "Day 2" ~ 2, 
                         Day == "Day 3" ~ 3), 
         Day = as.integer(Day),
         block = as.integer(block),
         bin = as.integer(bin),
         reward_status = as.integer(reward_status),
         block_vis = as.integer(block_vis),
         count_vis = as.integer(count_vis)) %>% 
  filter(Day == 1,  
         block != 1)

# fitting the model
# m.firstnight.blockbin.nofirstblock <-
#   brm(data = analysis_choices_firstnight_nofirstblock, family = bernoulli,
#       reward_status ~ block + bin + block:bin + 
#         (1 + block:bin|Bat), # random slopes and intercepts
#       prior = c(prior(normal(0, 2.5), class = Intercept),
#                 prior(normal(0, 2.5), class = b), 
#                 prior(cauchy(0, 1), class = sd)
#                 ),
#       iter = 2000, warmup = 1000, chains = 4, cores = 5, thin = 3,
#       control = list(adapt_delta = 0.99, max_treedepth = 15),
#       seed = 12)

# saving the model
# save(m.firstnight.blockbin.nofirstblock, file = "data/processed_data/m.firstnight.blockbin.nofirstblock.rda")

# loading the model
load("data/processed_data/m.firstnight.blockbin.nofirstblock.rda")

# setting the colour scheme
color_scheme_set("darkgray")

# setting the names of the fixed effects 
fixed_effects = c("Intercept", "block", "bin", "block:bin")

# putting the model's estimates into a table
t1_estimates <- model_outputs(m.firstnight.blockbin.nofirstblock, fixed_effects)

# finding the maximum x value in the fixed effects of the model
max_xvalue <- max_xvalue_output(m.firstnight.blockbin.nofirstblock, fixed_effects)

# creating a plot of the slope coefficients
p9 <- mcmc_intervals(m.firstnight.blockbin.nofirstblock,
  point_size = 1.1,
  pars = vars(1:4),
  prob_outer = 0.89
) +
  xlim(-5, max_xvalue + 0.8) +
  geom_vline(xintercept = 0) +
  scale_y_discrete(
    labels = c(
      "b_Intercept" = "Intercept",
      "b_block" = "Reversal",
      "b_bin" = "Bin",
      "b_block:bin" = "Reversal-bin \n interaction"
    ),
    limits = c("b_block:bin", "b_bin", "b_block", "b_Intercept")
  ) +
  geom_text(
    data = t1_estimates,
    aes(x = max_xvalue + 0.1, y = c(4, 3, 2, 1), label = All, fontface = "bold", family = "Times"), size = 3, hjust = 0
  ) +
  theme_srl2()

# setting the conditions for the conditional effects plots 
int_conditions <- list(block = c(2,3,4,5,6), bin = c(1,2,3,4,5))

# calculating the conditional effects
m_firstnight_blockbin_nofirstblock <- conditional_effects(m.firstnight.blockbin.nofirstblock, int_conditions = int_conditions, prob = 0.89, nsamples = 150)

# plotting out the conditional effects
p10 <- plot(m_firstnight_blockbin_nofirstblock, plot = FALSE, line_args = c(alpha = 1/5)) [[3]] +
  scale_x_continuous(breaks = seq(1,5,by = 1)) +
  ylim(0,1) + 
  xlab("Reversal") + 
  ylab("Visits to the rewarding option") +
  theme_srl2()

# plotting it out
ggarrange(p9, p10, ncol = 2, labels = c("a)","b)"), font.label = list(face = "plain", family = "Times New Roman", size = 8))
```

(ref:first-night-first-two-blocks-removed) a) Forest plot of the regression coeffients from the model of the effect of reversal and 10-visit bin on the visits to the rewarding flower, excluding the first reversal. Circles represent the means of the posterior distributions of the slope coefficients, thick horizontal lines represent 50% credible intervals, and thin horizontal lines 89% credible intervals. The numbers in bold are the means of the posterior distributions and 89% credible intervals b) Conditional effects plot from the model of the effect of reversal and 10-visit bin on the visits to the rewarding flower - excluding the first reversal - showing the two-way interaction between reversal and bin, sampling from the posterior distribution.

```{r first-night-first-two-blocks-removed, fig.cap = "(ref:first-night-first-two-blocks-removed)", fig.width = 18, fig.height = 5}
# creating a table of the data from the first night with the first two blocks removed
analysis_choices_firstnight_lastthreeblocks <- analysis_choices_firstnight_nofirstblock %>% 
  filter(block > 2)

# fitting the model
# m.firstnight.blockbin.lastthreeblocks <-
#   brm(data = analysis_choices_firstnight_lastthreeblocks, family = bernoulli,
#       reward_status ~ block + bin + block:bin + 
#         (1 + block:bin|Bat), # random slopes and intercepts
#       prior = c(prior(normal(0, 2.5), class = Intercept),
#                 prior(normal(0, 2.5), class = b), 
#                 prior(cauchy(0, 1), class = sd)
#                 ),
#       iter = 2000, warmup = 1000, chains = 4, cores = 5, thin = 3,
#       control = list(adapt_delta = 0.99, max_treedepth = 15),
#       seed = 12)

# saving the model
# save(m.firstnight.blockbin.lastthreeblocks, file = "data/processed_data/m.firstnight.blockbin.lastthreeblocks.rda")

# loading the model
load("data/processed_data/m.firstnight.blockbin.lastthreeblocks.rda")

# setting the names of the fixed effects
fixed_effects = c("Intercept", "block", "bin", "block:bin")

# putting the model's estimates into a table
t1_estimates <- model_outputs(m.firstnight.blockbin.lastthreeblocks, fixed_effects)

# finding the maximum x value in the fixed effects of the model
max_xvalue <- max_xvalue_output(m.firstnight.blockbin.lastthreeblocks, fixed_effects)

# creating a plot of the slope coefficients
p11 <- mcmc_intervals(m.firstnight.blockbin.lastthreeblocks,
  point_size = 1.1,
  pars = vars(1:4),
  prob_outer = 0.89
) +
  xlim(-5, max_xvalue + 0.8) +
  geom_vline(xintercept = 0) +
  scale_y_discrete(
    labels = c(
      "b_Intercept" = "Intercept",
      "b_block" = "Reversal",
      "b_bin" = "Bin",
      "b_block:bin" = "Reversal-bin \n interaction"
    ),
    limits = c("b_block:bin", "b_bin", "b_block", "b_Intercept")
  ) +
  geom_text(
    data = t1_estimates,
    aes(x = max_xvalue + 0.1, y = c(4, 3, 2, 1), label = All, fontface = "bold", family = "Times"), size = 3, hjust = 0
  ) +
  theme_srl2()

# setting the conditions for the conditional effects plots 
int_conditions <- list(block = c(3,4,5,6), bin = c(1,2,3,4,5))

# calculating the conditional effects
m_firstnight_blockbin_nofirstblock <- conditional_effects(m.firstnight.blockbin.nofirstblock, int_conditions = int_conditions, prob = 0.89, nsamples = 150)

# creating the plots of the conditional effects
p12 <- plot(m_firstnight_blockbin_nofirstblock, plot = FALSE, line_args = c(alpha = 1/5)) [[3]] +
  scale_x_continuous(breaks = seq(3,6,by = 1)) +
  ylim(0,1) + 
  xlab("Reversal") + 
  ylab("Visits to the rewarding option") +
  theme_srl2()

# plotting it out
ggarrange(p11, p12, ncol = 2, labels = c("a)","b)"), font.label = list(face = "plain", family = "Times New Roman", size = 8))
```

## The proportion of rewarded visits does not increase due to reversal experience in the later stages of the experiment

On the second and third experimental nights the highest Prop~rew~ was in the first block of the night, before any reversals had been experienced: `r report_m_ci_perc(day2and3bin1, par = "y", brackets = "square")`. Excluding this first block, there was no effect of reversal on the Prop~rew~, although there was a strong effect of 10-visit bin within each block. That is, the proportion of visits to the rewarded flower only increased within each block as the block progressed (figure \@ref(fig:second-and-third-nights-analysis)).  

(ref:second-and-third-nights-analysis) a) Forest plot of the regression coeffients from the model of the effect of experimental night, reversal and 10-visit bin on the visits to the rewarding flower, excluding the first night. Circles represent the means of the posterior distributions of the slope coefficients, thick horizontal lines represent 50% credible intervals, and thin horizontal lines 89% credible intervals. The numbers in bold are the means of the posterior distributions and 89% credible intervals b) Conditional effects plot from the model of the effect of experimental night, reversal and 10-visit bin on the visits to the rewarding flower - excluding the first night - showing the two-way interaction between reversal and bin, sampling from the posterior distribution.

```{r second-and-third-nights-analysis, fig.cap = "(ref:second-and-third-nights-analysis)", fig.width = 18, fig.height = 5}

# creating a data table with the data from the second and third nights
analysis_choices_laternights <- rev_learning %>% 
  ungroup() %>% 
  select(Day, block, bin, Bat, reward_status, block_vis, count_vis) %>% 
  filter(block_vis != 0) %>% 
  # removing the space temporarily and changing the Day back to numbers as this is how it was done in the model 
  mutate(Bat = str_remove_all(Bat, " "),
         Day = case_when(Day == "Day 1" ~ 1, 
                         Day == "Day 2" ~ 2, 
                         Day == "Day 3" ~ 3), 
         Day = as.integer(Day),
         block = as.integer(block),
         bin = as.integer(bin),
         reward_status = as.integer(reward_status),
         block_vis = as.integer(block_vis),
         count_vis = as.integer(count_vis)) %>% 
  filter(Day > 1, 
         block > 1)

# fitting the model
# m.dayblockbin.laternights <-
  # brm(data = analysis_choices_laternights, family = bernoulli,
  #     reward_status ~ Day + block + bin + block:bin + Day:block + 
  #       (1 + block:bin + Day:block|Bat), # random slopes and intercepts
  #     prior = c(prior(normal(0, 2.5), class = Intercept),
  #               prior(normal(0, 2.5), class = b), 
  #               prior(cauchy(0, 1), class = sd)
  #               ),
  #     iter = 2000, warmup = 1000, chains = 4, cores = 5, thin = 3,
  #     control = list(adapt_delta = 0.99, max_treedepth = 15),
  #     seed = 12)

# saving the model
# save(m.dayblockbin.laternights, file = "data/processed_data/m.dayblockbin.laternights.rda")

# loading the model
load("data/processed_data/m.dayblockbin.laternights.rda")

# setting the names of the fixed effects
fixed_effects = c("Intercept", "Day", "block", "bin", "block:bin", "Day:block")

# putting the model's estimates into a table
t1_estimates <- model_outputs(m.dayblockbin.laternights, fixed_effects)

# finding the maximum x value in the fixed effects of the model
max_xvalue <- max_xvalue_output(m.dayblockbin.laternights, fixed_effects)

# creating a plot of the slope coefficients
p13 <- mcmc_intervals(m.dayblockbin.laternights,
  point_size = 1.1,
  pars = vars(1:6),
  prob_outer = 0.89
) +
  xlim(-3, max_xvalue + 0.8) +
  geom_vline(xintercept = 0) +
  scale_y_discrete(
    labels = c(
      "b_Intercept" = "Intercept",
      "b_Day" = "Experimental \n night", 
      "b_block" = "Block",
      "b_bin" = "Bin",
      "b_block:bin" = "Block-bin \n interaction", 
      "b_Day:block" = "Night-block \n interaction"
    ),
    limits = c("b_Day:block", "b_block:bin", "b_bin", "b_block", "b_Day", "b_Intercept")
  ) +
  geom_text(
    data = t1_estimates,
    aes(x = max_xvalue + 0.1, y = c(6, 5, 4, 3, 2, 1), label = All, fontface = "bold", family = "Times"), size = 3, hjust = 0
  ) +
  theme_srl2()

# setting the conditions for the conditional effects plots 
int_conditions <- list(Day = c(1, 2, 3), block = c(2,3,4,5,6), bin = c(1,2,3,4,5))

# calculating the conditional effects
m_dayblockbin_laternights <- conditional_effects(m.dayblockbin.laternights, int_conditions = int_conditions, prob = 0.89, nsamples = 150)

# creating the plots of the conditional effects
p14 <- plot(m_dayblockbin_laternights, plot = FALSE, line_args = c(alpha = 1/5)) [[4]] +
  ylim(0,1) + 
  xlab("Block") + 
  ylab("Visits to the rewarding option") + 
  theme_srl2() + 
  theme(legend.position = "right")

# plotting it out
ggarrange(p13, p14, ncol = 2, labels = c("a)","b)"), font.label = list(face = "plain", family = "Times New Roman", size = 8))
```

# Discussion 

In our experiment wild nectar-feeding bats participated in a spatial serial reversal learning task with two potentially rewarding options that repeatedly alternated their rewarding properties. With this study we examined whether nectar-feeding bats were capable of second-order learning, an ability that would enhance their behavioural flexibility in a dynamically changing foraging environment. We found that the bats switched to the newly-rewarding option from a previously-rewarding one with increasing swiftness with each successive experience of a reversal: strong evidence of second-order learning. This 'speed of switching' increased on the first night of the experiment with five experiences of a reversal until it reached a plateau, and no further increase was seen as an effect of reversals.  

On the first night of our three-night experiment there were significant changes in the bats' decision-making behaviour. In order to quantify the swiftness of the change of the bats' choices from one option to another we analyzed the area under the curve marked by the choice data from the first 25 visits out of 50 visits of each block. The area under the curve following each of the five reversals increased significantly. The first reversal on this night was also the very first experience of a reversal in the main experiment, experienced after a long series of trials with fixed reward contingencies (the bats experienced an alternation of reward contingencies during the training phase of the experiment, but this occurred with every single rewarded visit they made). Thus, in the first ten visits after the first reversal, the proportion of visits to the rewarding flower dropped to the lowest value observed in the entire experiment (figure \@ref(fig:overall-summary)a). Even when this block with its especially low number of rewarded visits was excluded from the analysis however, the area under the curve increased as an effect of the third, fourth and fifth reversals on the first night (figure \@ref(fig:area-under-the-curve-all-but-first-reversal)). In other words, the effect of reversal on the area under the curve of the first 25 visits of a block was not driven solely by the very first experience of a reversal.

The overall proportion of visits to the rewarding option increased with each block, excluding the very first block when reversals had not been experienced. In order to ascertain whether the increase in the area under the curve was during to an overall increase in the proportion of rewarded visits, and not swifter choice reversal, we analyzed how the proportion of rewarded visits changed both across blocks and within each block. To do this we calculated the effect of block, bins of 10 visits within each block, and their interaction on the proportion of rewarded visits (figure \@ref(fig:first-night-first-block-removed)). This analysis revealed that the proportion of rewarded visits in the last 30 visits of each block did not change as an effect of block; rather, the increase in the proportion of rewarded visits with each block was driven by the first 20 visits in the block. This was true even when the second block, which occurred after the first reversal, was excluded from the analysis, although the effect of block was somewhat weaker (figure \@ref(fig:first-night-first-two-blocks-removed)). This is consistent with the interpretation that the bats alter their choice behaviour faster immediately after a reversal of reward contingencies. 

An important methodological point that affects the interpretation of our results is that the bats in this experiment received a rather large magnitude of reward each trial: 40 $\mu$L. As the experiment went on, and the bats received hundreds of these large rewards, it is possible that they both became physically satiated, and learned that the environment was a rich one where food was easily obtained. One might expect therefore that motivation to find food decreased over the course of each night due to these reasons, with the animals relatively hungry at the beginning of their nightly foraging bout. On the first experimental night there was an increase in the number of rewarded visits made, but a potential decrease in motivation to find food may have contributed to the choice behaviour seen on the second and third nights. On these later nights the successive experiences of reversals did not increase the proportion of rewarded visits; rather, there was a small increase in the variation of the proportion of rewarded visits. 

During the first 50 visits of each night, the bats had no experience of a reversal of reward contingencies that night. This is when the proportion of rewarded visits was the highest every night. After the bats experienced no reward at an option that had been rewarding until then, the proportion of rewarded visits decreased, and never again became as high as it was in the first block. Bats are known to adjust their choice behaviour between different available options according to their history of reinforcement at those options [@tolch_psychometric_2007, @nachev_psychophysics_2012]. If it is solely reinforcement history that dictates choice behaviour, then as the experience of reinforcement accumulates at both flowers over the course of the night, it is more difficult to discriminate which flower has a richer history. One would then expect that the bats' behaviour approaches random choice as a night goes on, i.e., the Prop~rew~ would approach 0.5. Even if the animals do not rely on their entire history of reinforcement at an option for their decision-making but merely a part of it, one would expect to see a slower switch to the rewarding option following each reversal, and then a steady increase in rewarded visits. This is the exact opposite of what was seen on the first experimental night: the bats switched to the rewarding option *faster*. On the second and third nights, while the switch to the rewarding option did not become faster, the bats also did not show a steady increase in rewarded visits, even after experiencing a few reversals. Instead, a consistent pattern was seen: the proportion of rewarded visits dropped to about 0.5 immediately after the reversal, and then came back up to approximately 0.9, steadily maintained until the next reversal. The immediate post-reversal drop in rewarded visits was never as low as it was at the start of the first night, but was consistently approximately 0.5, which was the proportion of rewarded visits immediately after the reversals at the end of the first night. 

While it is clear, therefore, that the bats' choice behaviour was not dictated by the reinforcement history at the two options, it is also evident that the swifter switch to the rewarding option ceases by the end of the first night. The bats' choice behaviour was consistent with second-order learning, but though the optimum behaviour of one error per reversal is approached, it is never reached. 

The performance on the serial reversal task of animals that share similarities with bats in their foraging ecology is illuminating. In an experiment similar to ours with a large trial number bumblebees showed a reduction in their perseverative errors and an increase in the errors made in the last trials, though there was an overall decrease in the errors [@strang_serial_2014]. The authors of this paper interpreted these findings as indicative of proactive interference, which occurs when previously-learned information interferes with the learning or remembering new information [@tello-ramos_spatial_2019]. 
Several animals that rely strongly on spatial memory have also been studied in reversal learning tasks, specifically birds that cache food at various locations that they must remember and return to. Birds that are known to have better or more long-lasting spatial memory such as black-capped chickadees [@hampton_proactive_1998], Clark’s nutcrackers [@lewis_interference_2006] and high elevation mountain chickadees [@croston_predictably_2017] were worse at adapting to the new contingency after a reversal than the initial learning (reviewed in @tello-ramos_spatial_2019). These data are consistent with the idea that there is a trade-off between acquiring new memories and retaining old ones, i.e., that proactive interference may be occurring in spatial reversal tasks, just like in bumblebees. It is known that Glossophagine bats have excellent spatial memory, potentially lasting up to several weeks [@rose_learning_2016], but there no evidence of proactive intereference in the bats' performance on the serial reversal task. At best there is a little increased variation in the choice behaviour after many reversals have been experienced, for which there may be other explanations such as physical satiety.  

Our results are consistent with previous work of the same species of bat under natural conditions in the same environment (La Selva Biological Field Station, Costa Rica) [@thiele_nahrungssuchstrategien_2006]. This study, using the serial reversal task, evaluated the behavioural flexibility of nectar-feeding bats to fluctuations in food resource availability. Free-flying, ID-tagged wild bats interacted with 50 ID-sensor equipped artificial flowers placed over a 100 x 100 m area in the open forest that varied in their rate of nectar production. The allocation of flower types to spatial locations changed with the same pattern every night. During each night, bats adapted to the changes in resource availability. However, the bats needed four nights before they had adapted to the underlying recurring, predictable pattern of resource variability. 

In most cases under natural foraging conditions, flowers are emptied in a single visit. There are however certain plants such as species of *Agave* or *Vriesea*, that hold large amounts of nectar, which if undetected for a long time may require multiple hovering visits to deplete – “jackpot” rewards in other words [@ohashi_efficient_2005]. Thus the ability to swiftly inhibit visiting a flower that had been rewarding for multiple visits is likely part of the bats' natural foraging ecology as nectar-feeding animals. 

What performance on the serial reversal task says about the cognitive mechanisms at work is not completely settled. Cognitive flexibility describes the processes in the brain that underlie adaptive change in behaviour in response to changes in the internal or external environment, whereas behavioural flexibility is the modifiability of learned behaviour [@dhawan_more_2019]. Cognitive flexibility cannot be directly observed; it is inferred to have occurred through behavioural flexibility [@tait_assessment_2018], and the reversal learning task is a test of behavioural flexibility, not cognitive flexibility [@dhawan_more_2019]. Our study with nectar-feeding bats yielded strong evidence of second-order learning, indicative of a high capacity for behavioural flexibility evolved in the bats through a foraging ecology dominated by the search for nectar-rich flowers. 

# Electronic Supplementary Material {-}

\beginsupplement

## Visits and approaches to the unassigned flowers

```{r Preparing-data-and-checking-distribution-to-nonassigned-flowers}

#------------------------------------------------
# Preparing the table with the information needed
#------------------------------------------------

# setting binsize and breaks for cutting up the data into block and bin
binsize <- 10
breaks <- seq(0, 3000, binsize)

# creating a data-table with the visits to the unassigned flowers 
samp_all_nonrw <- alldata_pumps %>%
  arrange(DateTime) %>%
  filter(
    Condition == "SerialReversalCounter",
    Day %in% main_days,
    !IdLabel %in% bats_beta,
    !IdLabel %in% bats_incomp,
    # selecting the required information in the proper columns
    str_detect(MsgValue1, "start pump") | str_detect(MsgValue1, "end pump") | str_detect(MsgValue1, "switch") | str_detect(unitLabel, "CondMod | Reader") | str_detect(IdLabel, "Bat")
  ) %>%
  mutate(
    Day = case_when(
      Day == "Day 1" ~ "Night 1",
      Day == "Day 2" ~ "Night 2",
      Day == "Day 3" ~ "Night 3"
    ),
    Loc = as.integer(str_extract(unitLabel, "[0-9]+"))
  ) %>%
  rename(Bat = IdLabel) %>%
  ungroup() %>%
  group_by(Day, Bat) %>%
  # creating a column with the block number, marking the reversals
  mutate(block = ifelse(MsgValue1 == "switch", 1, 0)) %>%
  group_by(Day, Bat) %>%
  mutate(block = cumsum(block)) %>%
  ungroup() %>%
  group_by(Day, Bat, block) %>%
  # creating a column with the number of visits within each block
  mutate(
    block_vis = ifelse(MsgValue1 == "switch", 0, 1),
    block_vis = cumsum(block_vis),
    # creating a new column for visits in each block to be binned
    bin = ""
  ) %>%
  ungroup() %>%
  group_by(Day, Bat, block) %>%
  # cutting the visits inside each block into bin of the size set earlier
  mutate(bin = as.numeric(cut(block_vis, breaks, include.lowest = TRUE))) %>%
  filter(Bat != " Test")

# making a look-up table to mark the assigned flowers
rewarding <- samp_all_nonrw %>%
  # marking the assigned flowers
  filter(outLabel == "positive") %>%
  # pulling out the CondMod events
  mutate(assigned = ifelse(str_detect(unitLabel, "CondMod"), 1, 0)) %>%
  arrange(Bat) %>%
  ungroup() %>%
  select(Day, Bat, unitLabel, assigned) %>%
  distinct() %>%
  # making a column with the flower numbers
  mutate(Loc = as.integer(str_extract(unitLabel, "[0-9]+"))) %>%
  select(-unitLabel)

# making the table with the flower numbers marked
assignment <- samp_all_nonrw %>%
  ungroup() %>%
  select(Day, Bat, unitLabel) %>%
  distinct() %>%
  mutate(Loc = as.integer(str_extract(unitLabel, "[0-9]+")))

# joining the tables to create the assignment look-up table
assignment <- left_join(assignment, rewarding, by = c("Day", "Bat", "Loc")) %>%
  mutate(assigned = replace_na(assigned, 0)) %>%
  select(-unitLabel)

# removing the now unnecessary look-up table
rm(rewarding)

# marking the visits in the data set from the bats as assigned or not assigned
samp_all_nonrw <- left_join(samp_all_nonrw, assignment, by = c("Day", "Bat", "Loc"))

# labels to extract
labels <- paste(c("CondMod", "Reader"), collapse = "|")

# making a look-up table to find the last visit of the experiment
last_visit <- samp_all_nonrw %>%
  # selecting the visits to the assigned flowers and the CondMods
  filter(
    assigned == 1,
    outLabel == "positive"
  ) %>%
  group_by(Day, Bat) %>%
  # counting these visits
  mutate(count_vis = 1:n()) %>%
  # filter the last one of these visits
  filter(count_vis == max(count_vis)) %>%
  # selecting the required columns
  select(DateTime, Day, Bat) %>%
  distinct() %>%
  # noting the last experimental visit
  mutate(final_vis = 1)

# adding the information about the last visit to the main table
samp_all_nonrw <- left_join(samp_all_nonrw, last_visit, by = c("DateTime", "Day", "Bat"))

samp_all_nonrw <- samp_all_nonrw %>%
  mutate(
    final_vis = replace_na(final_vis, 0),
    # flipping the 1s and 0s for the assigned so that the visits to the unassigned flowers can be calculated for the Y axis
    assigned = ifelse(assigned == 0, 1, 0)
  )

# taking only the experimental times
samp_exp_nonrw <- samp_all_nonrw %>%
  ungroup() %>%
  group_by(Day, Bat) %>%
  mutate(
    final_vis = cumsum(final_vis),
    final_vis = cumsum(final_vis)
  ) %>%
  filter(final_vis <= 1) %>%
  group_by(Day, Bat)

# making a look-up table with the reversals
reversals <- samp_exp_nonrw %>%
  ungroup() %>%
  group_by(Bat, Day) %>%
  mutate(day_bin = ifelse(bin == lag(bin), 0, 1)) %>%
  filter(!is.na(day_bin)) %>%
  mutate(
    day_bin = cumsum(day_bin),
    day_bin = day_bin + 1,
    day_bin_vis = day_bin * 10
  ) %>%
  ungroup() %>%
  mutate(day_bin_vis = ifelse(MsgValue1 == "start pump" | MsgValue1 == "end pump", lag(day_bin_vis), day_bin_vis)) %>%
  filter(MsgValue1 == "switch")

#----------------------------------------------
# Counting the events at the unassigned flowers
#----------------------------------------------

# calculating the visits to the unassigned flowers over the night
samp_avg_nonrw <- samp_exp_nonrw %>%
  # grouping the data to see what happened before and after the experiment
  group_by(Day, Bat, block, bin) %>%
  group_modify(~ mean_cl_boot(.x$assigned, conf.int = 0.89)) %>%
  ungroup() %>%
  group_by(Bat, Day) %>%
  mutate(
    day_bin = 1:n(),
    day_bin_vis = day_bin * 10,
    ymin = replace_na(ymin, 0),
    ymax = replace_na(ymax, 0)
  ) %>%
  filter(str_detect(Bat, "Bat"))

# plotting the proportion of visits to the unassigned flowers
# samp_avg_nonrw %>%
#   # filtering only the first three main days of the experiment:
#   # one group had the experiment extended a further three days
#   ggplot(aes(day_bin_vis, y)) +
#   geom_point(size = 0.3) +
#   geom_line() +
#   geom_ribbon(aes(ymin = ymin, ymax = ymax), alpha = 0.3) +
#   facet_grid(Bat ~ Day) +
#   #scale_x_continuous(breaks = seq(50, 300, by = 50)) +
#   ylim(0, 1.1) +
#   geom_hline(yintercept = c(0.25, 0.5, 0.75, 1), linetype = "dotted") +
#   geom_vline(data = reversals, aes(xintercept = day_bin_vis), color = "blue") +
#   theme_classic() +
#   labs(x = "Visits", y = "Proportion of visits to the non-assigned flowers") +
#   theme(legend.position = "none")


# creating a table with the individual counts of visits to the different flowers

samp_bar_nonrw <- samp_exp_nonrw %>%
  # removing the NAs
  filter(
    !is.na(Bat),
    !is.na(Loc)
  ) %>%
  ungroup() %>%
  group_by(Day, Cage, Bat, unitLabel, assigned, Loc) %>%
  summarise(visits = n()) %>%
  arrange(Loc) %>%
  mutate(
    Type = str_extract(unitLabel, labels),
    # marking the CondMod and Reader events
    Type = as.factor(ifelse(Type == "CondMod", "Nose-poke", "Fly-by")),
    Loc = as.character(Loc),
    assigned = ifelse(assigned == 0, " ", "(non-assigned)")
  ) %>%
  ungroup() %>%
  group_by(Day, Bat, Loc, Type) %>%
  mutate(
    max = sum(visits),
    Event = paste(Type, assigned, sep = " ")
  ) %>%
  # taking only the bat visits 
  filter(unitLabel != "exp")

# calculating the proportion of events at the unassigned flowers
samp_prop_nonrw <- samp_exp_nonrw %>%
  group_by(Day, Bat, assigned) %>%
  summarise(sum = n()) %>%
  pivot_wider(names_from = assigned, values_from = sum) %>%
  rename(
    non_assigned = `1`,
    assigned = `0`
  ) %>%
  filter(!is.na(assigned)) %>%
  mutate(
    non_assigned = replace_na(non_assigned, 0),
    prop_assigned = non_assigned / (assigned + non_assigned)
  )

# calculating the mean and 95% CIs
samp_prop_mean <- samp_prop_nonrw %>%
  ungroup() %>%
  group_by(Day) %>%
  group_modify(~ mean_cl_boot(.x$prop_assigned, conf.int = 0.89))
```

Only two out of the array of eight flowers were assigned uniquely to each bat but all the flowers were accessible to all the animals. The number of approaches to and attempts to get a reward from all the flowers, both assigned and not assigned, is shown in figure \@ref(fig:unassigned-flowers).

(ref:unassigned-flowers) Visits made by the bats to all the flowers, including the ones that were not assigned to them. Yellow bars are nose-pokes at the assigned flowers, where the bats attempted to get a reward by breaking the light-barrier. Purple bars are 'fly-by' events near the assigned flowers where the bat flew near the flower but did not attempt to get a reward. Orange bars are nose-pokes at the non-assigned flowers and black bars are fly-bys at the non-assigned flowers.

```{r, unassigned-flowers, fig.cap="(ref:unassigned-flowers)", fig.width = 10, fig.height = 7}

p15 <- samp_bar_nonrw %>%
  # adding a row for the fly-by visits to an assigned flower for Bat 20 so the bars in the following plot are of even width
  ungroup() %>% 
  add_row(Day = "Night 1", Cage = 1, Bat = "Bat 20", unitLabel = "Reader7", assigned = " ", Loc = as.character(7), visits = 0, Type = "Fly-by", max = 0, Event = "Fly-by") %>% 
  filter(Cage == 1) %>%
  ggplot(aes(x = Loc, y = visits, fill = Event)) +
  geom_col(position = "dodge", color = "black") +
  # geom_text(aes(x = Loc, y = max + 15, label = assigned), size = 2) +
  facet_grid(Day ~ Bat) +
  xlab("Flower number") +
  ylab("Number of approaches/visits \n to non-assigned flowers") +
  theme_srl() +
  scale_fill_viridis_d(option = "inferno") 

p16 <- samp_bar_nonrw %>%
  filter(Cage == 2) %>%
  ggplot(aes(x = Loc, y = visits, fill = Event)) +
  geom_col(position = "dodge", color = "black") +
  # geom_text(aes(x = Loc, y = max + 15, label = assigned), size = 2) +
  facet_grid(Day ~ Bat) +
  xlab("Flower number") +
  ylab("Number of approaches/visits \n to non-assigned flowers") +
  scale_fill_viridis_d(option = "inferno") +
  theme_srl() +
  theme(legend.positio = "bottom")

ggarrange(p15, p16, nrow = 2, ncol = 1, common.legend = TRUE)
```

The number of approaches or attempts to get a reward at the non-assigned flowers was a small proportion of the overall number of approaches and reward-attempts at the flowers, less than 10% every night on average as Figure \@ref(fig:proportion-unassigned) shows.

(ref:proportion-unassigned) Proportion of visits or approaches to the un-assigned flowers out of the total number of visits or approaches to flowers. Coloured points are data from individual bats. Black points are the mean proportion per night and the error bars are 89% CIs. 

```{r, proportion-unassigned, fig.cap = "(ref:proportion-unassigned)", fig.width=5, fig.height= 4}

dodge <- position_dodge(width = 0.1)

p17 <- samp_prop_nonrw %>%
  mutate(Day = as.factor(Day)) %>%
  ggplot() +
  geom_jitter(aes(Day, prop_assigned, color = Bat)) +
  geom_point(data = samp_prop_mean, aes(Day, y), alpha = 0.7) +
  geom_errorbar(data = samp_prop_mean, aes(x = Day, ymax = ymax, ymin = ymin), alpha = 0.7, position = dodge, width = 0.1) +
  ylim(0, 1) +
  xlab("Night") +
  ylab("Proportion of approaches or visits \n to the unassigned flowers") +
  geom_hline(yintercept = 0.5, linetype = 2) +
  theme_srl() +
  scale_color_viridis_d(option = "inferno") +
  theme(legend.position = "bottom", legend.box = "vertical", legend.margin = margin())

p17
```


## Curves of individual bats' visits to the rewarding flower on the first night

(ref:first-night-rew-visits-individual-bats) Visits to the rewarding flower for each individual bat: average proportion per five-visit bin. Vertical dashed lines indicate the occurrence of a reversal. The area under the curve marked by data from the reversal up to 25th visit of the block, marked by the vertical dotted line, were analysed. 

```{r, first-night-rew-visits-individual-bats, fig.cap = "(ref:first-night-rew-visits-individual-bats)"}

# plotting it out   
p18 <- rev_learning_first_night %>% 
  ggplot() + 
  geom_line(aes(total_vis, bin_five_average, group = Bat, colour = Bat)) +
  facet_wrap(~Bat) + 
  ylim(0,1) + 
  geom_vline(xintercept = c(10.5, 20.5, 30.5, 40.5, 50.5), linetype = "dashed") +
  geom_vline(xintercept = c(5.5, 15.5, 25.5, 35.5, 45.5), linetype = "dotted") + 
  xlab("Bins of 5 visits") + 
  ylab("Proportion of visits to the rew flower") + 
  theme_srl2()

p18
```


## Details of the statistical analyses

Weakly informative priors were used for the generalized linear mixed-models in `brms`.
All the models were estimated using 4 chains with a thinning interval of 3, with 1500 warm-up samples and 3000 post-warm-up samples for all the models except the one fitted to the data from the second and third nights, which had 1000 warm-up samples and 3000 post-warm-up samples. 

For the models of the area under the curve a normal likelihood function was used, with reversal number as a fixed effect. The intercepts and slopes were allowed to vary for each animal. For the models of the proportion of visits to the rewarding option a bernoulli likelihood function was used. For the model of the first night, the reversal number, 10-visit bin within each block, and their interaction were the fixed effects. Slopes and intercepts were allowed to vary for each animal.  

Visual inspection of the trace plots, the effective sample size, the Gelman-Rubin convergence diagnostic ($\hat R$) and the calculation of posterior predictions for the same clusters were all used to assess the fit of the models. In all the models the $\hat R$ was equal to 1 for all the chains.


# References
