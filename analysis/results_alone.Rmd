---
title: "Nectar-feeding bats learn the rule behind serial reversals"
header-includes:
   - \usepackage{lineno}
   - \linenumbers
   - \usepackage{float} \floatplacement{figure}{H}
   - \newcommand{\beginsupplement}{\setcounter{table}{0}  \renewcommand{\thetable}{S\arabic{table}} \setcounter{figure}{0} \renewcommand{\thefigure}{S\arabic{figure}}}
always_allow_html: yes
output:
   bookdown::html_document2:
      fig_caption: yes
      number_sections: no
   bookdown::word_document2:
      fig_caption: yes
      number_sections: no
   bookdown::pdf_document2:
  #   number_sections: no
  #   toc: no
  #   number_sections: no
  #   toc: no
bibliography: srl.bib
# csl: animal-cognition.csl
---

```{css style settings, echo = FALSE}
blockquote {
    margin: 0 0 20px;
    font-size: 14px;
}
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE, 
  message = FALSE, 
  warning = FALSE, 
  fig.align = "center", 
  fig.pos = "H")
```

```{r Reading-in-the-packages}
# clearing the environment
 rm(list = ls())

# installing the required packages if needed and loading them
if (!require(rmarkdown)) {
  install.packages("rmarkdown")
}
if (!require(reshape2)) {
  install.packages("reshape2")
}
if (!require(tufte)) {
  install.packages("tufte")
}
if (!require(rticles)) {
  install.packages("rticles")
}
if (!require(knitr)) {
  install.packages("knitr")
}
if (!require(shiny)) {
  install.packages("shiny")
}
if (!require(scales)) {
  install.packages("scales")
}
if (!require(tidyverse)) {
  install.packages("tidyverse")
}
if (!require(gluedown)) {
  install.packages("gluedown")
}
if (!require(glue)) {
  install.packages("glue")
}
if (!require(ggthemes)) {
  install.packages("ggthemes")
}
if (!require(lubridate)) {
  install.packages("lubridate")
}
if (!require(ggpubr)) {
  install.packages("ggpubr")
}
if (!require(gridExtra)) {
  install.packages("gridExtra")
}
if (!require(Hmisc)) {
  install.packages("Hmisc")
}
if (!require(brms)) {
  install.packages("brms")
}
if (!require(bayesplot)) {
  install.packages("bayesplot")
}
if (!require(bayestestR)) {
  install.packages("bayestestR")
}
```

```{r Themes-and-CI-functions}

# creating two themes for all the plots

theme_srl <- function() {
  theme_pubr() +
    theme(
      axis.text = element_text(size = 12, family = "Times"),
      axis.title = element_text(size = 14, family = "Times"),
      strip.text.x = element_text(size = 14, family = "Times"),
      strip.text.y = element_text(size = 14, family = "Times"),
      legend.text = element_text(size = 12, family = "Times"),
      legend.title = element_text(size = 14, face = "bold", family = "Times")
    )
}

theme_srl2 <- function() {
  theme_bw() +
    theme(
      axis.text = element_text(size = 12, family = "Times"),
      axis.title = element_text(size = 14, family = "Times"),
      strip.text.x = element_text(size = 14, family = "Times"),
      strip.text.y = element_text(size = 14, family = "Times"),
      legend.text = element_text(size = 12, family = "Times"),
      legend.title = element_text(size = 14, face = "bold", family = "Times")
    )
}
 # writing a function to automate the reporting of an estimate and error bars
report_m_ci_perc <- function(tbl, par = "_r_", brackets = "round") {
  open_bracket <- case_when(
    brackets == "round" ~ "(",
    brackets == "square" ~ "[",
    brackets == "squiggly" ~ "{",
    brackets == "none" ~ "",
    TRUE ~ str_sub(brackets, 1, 1)
  )
  
  close_bracket <- case_when(
    brackets == "round" ~ ")",
    brackets == "square" ~ "]",
    brackets == "squiggly" ~ "}",
    brackets == "none" ~ "",
    TRUE ~ str_sub(brackets, 2, 2)
  )
  
  tbl <- tbl %>% 
    mutate(CI = paste0(open_bracket, "95% CI ", ymin, ", ", ymax, close_bracket))
  
    return(glue("{tbl$y}% {tbl$CI}"))
}

# writing a function to make a table to get estimates and error bars as a model output

model_outputs <- function(model, fixed_effects) {
  
# creating a table with the required values for the forest plot
t1 <- fixef(model, 
            probs = c(0.055, 0.945)) %>%
  as_tibble() %>%
  mutate(
    `Fixed effect` = fixed_effects,
    Estimate = round(Estimate, digits = 2),
    Q5.5 = round(Q5.5, digits = 2),
    Q94.5 = round(Q94.5, digits = 2)
  ) %>%
  # renaming the credibility intervals column
  mutate("89% Credibility intervals" = paste0("[", Q5.5, ", ", Q94.5, "]")) %>%
  #filter(`Fixed effect` != "Intercept") %>%
  rename(labels = `Fixed effect`) %>%
  select(labels, Estimate, `89% Credibility intervals`) %>%
  mutate(All = paste0(Estimate, " ", `89% Credibility intervals`)) %>%
  select(labels, All)
}

# setting the maximum value on the x axis to locate the labels
max_xvalue_output <- function(model, fixed_effects) {
  
max_xvalue <- fixef(model, 
                    probs = c(0.055, 0.945))%>%
  as_tibble() %>%
  mutate(
    `Fixed effect` = fixed_effects,
    Estimate = round(Estimate, digits = 2),
    Q5.5 = round(Q5.5, digits = 2),
    Q94.5 = round(Q94.5, digits = 2)
  ) %>%
  #filter(`Fixed effect` != "Intercept") %>%
  select(Q94.5) %>%
  filter(Q94.5 == max(Q94.5)) %>%
  as.numeric()

}

```

```{r Pump-filltime-events}
#----------------------------------
# Reading in and preparing the data
#----------------------------------
# reading in the pre-processed data to demonstrate the pump fill time
alldata_pumps <- read.csv2("/Users/shambhavi/Google Drive/Experiments & Data/SRL_2017/analysis/data/processed_data/raw_data_all.csv", sep = ";", header = TRUE)

# creating a vector of the bats to be excluded from the main analysis
bats_incomp <- c("Bat 7", "Bat 19")

# creating a vector with the beta bats
bats_beta <- c("Bat 1", "Bat 2", "Bat 3", "Bat 4")

# creating a vector of the main experimental days
main_days <- c("Day 1", "Day 2", "Day 3")

#--------------------------
# Analysing the pump events
#--------------------------

# calculating the time for each refill event
pump_time <- alldata_pumps %>%
  filter(Day %in% main_days) %>% 
  group_by(Cage) %>%
  arrange(DateTime) %>%
  filter(MsgValue1 == "start pump" | MsgValue1 == "end pump") %>%
  mutate(interval = ifelse(MsgValue1 == "start pump", as.numeric(difftime(lead(DateTime), DateTime, units = "secs")), "non-fill time")) %>%
  select(DateTime, IdLabel, Condition, Cage, MsgValue1, interval) %>%
  arrange(DateTime) %>%
  filter(
    Condition == "SerialReversalCounter",
    interval != "non-fill time",
    interval < 300
  ) %>%
  mutate(interval = as.integer(interval) / 60) %>%
  summarise(
    mean_filltime = round(mean(interval), digits = 1),
    sd_filltime = round(sd(interval), digits = 2)
  )

# counting the number of fill events per night: there is exactly one so the R code is not cited in the main text
pump_fills <- alldata_pumps %>%
  filter(Condition == "SerialReversalCounter") %>%
  arrange(DateTime) %>%
  group_by(Group, Day) %>%
  mutate(hour = hour(DateTime)) %>%
  filter(
    !IdLabel %in% bats_incomp,
    !IdLabel %in% bats_beta,
    Day %in% main_days,
    hour > 18 | hour < 6,
    MsgValue1 == "start pump"
  ) %>%
  summarise(pump_events = n()) %>%
  ungroup() %>%
  summarise(fill_events = mean(pump_events))
```

```{r, Wrongly-unrewarded-visits}
#----------------------------------
# Reading in and preparing the data
#----------------------------------
# loading the prepared CSV file of raw data

rev_learning_all <- read.csv2(file = "/Users/shambhavi/Google Drive/Experiments & Data/SRL_2017/analysis/data/processed_data/raw_data_bats.csv", sep = ";", header = TRUE)

# creating a vector of the bats to be excluded from the main analysis
bats_incomp <- c("Bat 7", "Bat 19")

# creating a vector with the beta bats
bats_beta <- c("Bat 1", "Bat 2", "Bat 3", "Bat 4")

# creating a vector of the main experimental days
main_days <- c("Day 1", "Day 2", "Day 3")

# preparing a data frame with all the visits, including the proper but unrewarded ones
rev_learning_all <- rev_learning_all %>%
  filter(
    # filtering only the bats
    str_detect(IdLabel, "Bat"), 
    # removing the bats that did not complete the experiment
    !IdLabel %in% bats_incomp,
    !IdLabel %in% bats_beta,
    # taking only the three main experimental days 
    Day %in% main_days,
    # filtering out the main experimental data
    Condition == "SerialReversalCounter", 
  ) %>%
  mutate(
    # marking the difference between the normal visits in a block and the switch points
    MsgValue1 = ifelse(MsgValue1 == "switch", "switch", "block"),
    # making a column to mark the unrewarded proper visits
    reinforce1value = replace_na(reinforce1value, 0),
    reinforce1Account = replace_na(reinforce1Account, 0),
    Unrew = ifelse(reinforce1value != reinforce1Account, 1, 0)
  ) %>%
  rename(Bat = IdLabel) %>%
  #arrange(Group, Day, Bat, DateTime) %>%
  # grouping the data to count the visits, noting the reversals separately
  group_by(Bat, Day) %>%
  mutate(
    # creating a column with the total number of visits made by a bat per day
    count_vis = ifelse(MsgValue1 == "switch", 0, 1),
    count_vis = cumsum(count_vis)
  ) %>%
  # setting the maximum number of visits a night higher than the programmed max to allow for the unrewarded visits
  filter(count_vis <= 350)

#----------------------------------
# Calculating the unrewarded visits
#----------------------------------

# calculating the percentage of the bats' visits are wrongly unrewarded
mean_unrew <- rev_learning_all %>%
  group_by(Bat, Day) %>%
  filter(MsgValue1 != "switch") %>%
  summarise(mean_unrew = mean(Unrew)) %>%
  mutate(mean_unrew = mean_unrew * 100)

overall_mean_unrew <- round(as.numeric(mean(mean_unrew$mean_unrew), digits = 2))
overall_sd_unrew <- round(as.numeric(sd(mean_unrew$mean_unrew)), digits = 2)
```

# Abstract

Animals that show flexibility in their behavioural responses to environmental change have a strong advantage in foraging for food. We aimed to explore this ability in Commissaris’s long-tongued bat through a spatial serial reversal learning task. Wild bats were trained to obtain rewards from two artificial flowers. At any given time only one of the flowers provided a reward. After the bats had experienced the rewarding properties of the flowers for some time, a reversal happened: the rewarding flower became non-rewarding and *vice versa*. These reversals of rewarding properties occurred repeatedly.

We found that the bats detected and responded to the reversals of reward properties: when a food location suddenly dried up the bats abandoned visiting it and switched to the alternative, showing a near-exclusive preference for the rewarding option. The bats switched to the rewarding flower more swiftly with each successive experience of a reversal. The number of visits to the rewarding flower increased overall, driven by the increase in the number of rewarded visits immediately after each reversal. Our results are consistent with the occurrence of second-order learning, demonstrated in nectar-feeding bats for the first time.

# Introduction

Many animals live and forage in environments that change frequently and often unpredictably. The foraging environment of nectar-feeding animals mainly consists of flowering plants and the food resource they provide: nectar. Though flowers – and their nectar contents – are stationary, they bloom seasonally and single flowers on plants themselves wither and die every day or every few days, altering their efficacy with time as food resources. Thus, nectar-feeding animals face the challenge of exploiting resources that continually change with time but are relatively predictable in space. These animals need to detect the changing reward contingencies in their environment and adjust their behaviour accordingly.

Behavioural flexibility is an ability to cope with such changes. The word ‘flexibility’ has been used to mean many different things in the animal behaviour literature (often inconsistently – @audet_whats_2017), and one interpretation of the word is similar to the concept of elasticity: behavioural patterns that can be repeatedly and readily reversed [@bond_serial_2007]. An experimental protocol that has been widely used to test for and demonstrate this sort of flexibility is reversal learning [@izquierdo_neural_2017]. 

In a reversal learning task an animal must first learn about multiple stimulus-response associations, such as two spatial locations that can be approached to obtain a potential reward. The animal must then discriminate between these associations in its behaviour, according to the strength of that association. This is first-order learning [@balsters_cerebellar_2011]. When only one of the two options is rewarding, this is the only one the animal should respond to. When reinforcement at this location stops the animal should abolish its current behaviour. It is this ability to abruptly terminate a repeated behaviour and switch to another behaviour that the animal needs to have for efficient exploitation of the available resources. The information contained in the absence of an expected reward becomes a stimulus in itself. A successful animal associates this non-reward stimulus with the appropriate response, which is the inhibition of its previous behaviour and reorientation to the available alternative. In a serial reversal learning procedure the reward contingencies of the two options reverse repeatedly: one option is rewarding and the other is not; then the rewarding option stops yielding reward and the previously non-rewarding option becomes rewarding. The question then is: can an animal detect the rule of the environment that dictates change in reward contingencies, learn which cue indicates that change, and respond to this “cue of change”? When an animal responds to a stimulus that indicates environmental change through a corresponding change in its behaviour, second-order learning is said to have occurred, operating on first-order learning [@shettleworth_cognition_2010]. In a serial reversal paradigm the theoretical most successful animal (which collects the maximum possible reward) makes exactly one error per reversal. 

We carried out a serial reversal learning task with Commissaris’s long-tongued bat, (*Glossophaga commissarisi*), which primarily feeds on flower nectar. Flower visitors like these bats may often experience reversal situations in their natural environment. A flower full of nectar may remain rewarding for multiple visits before it is empty. The flower visitor should then seek another flower. However, at a later time point, when ongoing secretion has replenished nectar, a previously visited flower is rewarding again. In our experiment the bats were given two potentially rewarding options to choose between. The options were separated in space and their spatial location was the cue to indicate their reward properties at any moment. *G. commissarisi* is known to have excellent spatial memory [@thiele_hierarchical_2005] so no other cue was necessary. At the start of the night, only one of the options was rewarding, the ‘S+’ option and the other was not rewarding, the ‘S-’ option. After a certain number of visits had been made by the bats, the reward contingencies reversed without any signal or cue to the bats: the previously rewarding option was now unrewarding and the previously unrewarding option was rewarding, and this reversal happened five times in a night. The experiment was done for three consecutive nights. 

It is well known that bats alter their preference between reward sources according to their transient rewarding properties and thus show first-order learning for spatial locations (@winter_foraging_2005, @tolch_psychometric_2007, @nachev_psychophysics_2012, @nachev_cognition-mediated_2017). Thus the aim of our experiment was as follows. We tested if bats can learn to respond to stimuli that indicate that their environment has changed by then changing their own behaviour, i.e., show second-order learning. Faced with the occurrence of successive reversals, would the bats change their behavioural allocation between the two potentially rewarding options with increasing speed? Further, we were interested to see if this speed of switching from one option to another increased enough to result in one error (unrewarded visit) per reversal. 

We focused on the first experimental night when the bats experienced the reversals for the first time and showed large behavioural changes. The very first group of 50 visits, when the bats had not yet experienced any change in reward contingencies were removed from the analysis. Thus we examined the effect of reversal experience on how swiftly the bats switched to the newly rewarding option after a reversal, and how their overall behavioural allocation to the rewarding option changed. 

# Methods

## Study site and subjects

The experiment took place at La Selva Biological Field Station, Province Heredia, Costa Rica in June-July 2017. Bats of the species *Glossophaga commissarisi* were captured from the wild and retained in a flight cage through the experiment. The bats were attracted to a particular location in the forest using chicken-feeders filled with sugar-water (see **Reward**) as bait. The feeders had cotton swabs soaked in dimethyl disulphide on them, a chemical attractant produced by many bat-pollinated flowers [@von_helversen_sulphur-containing_2000] and then caught in mist-nets. The bats were sexed on capture and housed in two outdoor, meshed flight-cages (4 x 6 m) under ambient light conditions. All individuals were weighed and marked with radio frequency identification (RFID) tags placed as collars around their necks.

A total of 16 bats participated in the main experiment and the first stage of the experiment began on the same night the bats entered the cages. A group of four experimental bats of the same sex were placed in a flight cage together. Two such groups were run in parallel, one in each flight-cage so the data were collected simultaneously. At the end of the experiment, the RFID collars were removed and the bats were released back into the wild. All the data collection was completely automatized. Two of the bats did not drink a sufficient amount of sugar-water to meet minimum energy requirements. These two bats were released before the end of the experiment and not replaced, and the data from these two individuals were not analyzed. Thus, 14 bats (7 males and 7 females) completed the experiment. Permission for this research was granted by Sistema Nacional de Areas de Conservación (SINAC) at the Ministerio de Ambiente y Energía (MINAE), Costa Rica.

## Experimental Setup

### Reward

The reward received by the bats during the experiment was also their main source of food. The reward was a 17% by weight solution of sugar dissolved in water, hereafter referred to as ‘nectar’. The sugar consisted of a 1:1:1 mass-mixture of sucrose, fructose and glucose. The nectar was thus similar in composition and concentration to the nectar produced by wild chiropterophilous plants [@baker_sugar_1998]. Every night, the bats were also given *ad-libitum* access to 10 mL of supplemental food: 3.5 g of hummingbird food (NektarPlus, Nekton, Germany) and 3.5 g of milk powder (Nido 1+, Nestle, Switzerland) in 10 mL of water. The bats in each cage were also given a small bowl of locally-sourced bee pollen.

### Flower and pump setup

Each flight cage had a square plastic frame in the center (2 × 2 × 1.5 m). Eight reward-dispensing devices - hereafter referred to as ‘flowers’ - were fixed in a radial pattern on this frame, two on each side of the square (figure \@(fig:Schematic)) with a distance of 40 cm between adjacent flowers. At this distance, bats can easily discriminate neighbouring flowers [@thiele_hierarchical_2005]. Each flower had the following parts: an RFID reader mounted on a plastic cylinder around the head of the flower; an infra-red photo gate; and an electronic pinch valve through which a silicon tube was placed and fixed to the head of the flower.

A stepper-motor pump was placed in the center of the plastic frame in each cage. The pumps contained a 25 mL Hamilton glass syringe (Sigma Aldrich, Germany). The step volume of the two pumps differed slightly: the pump in Cage 1 delivered `r round(40/19, digits = 2)` $\mu$L per step of the stepper-motor, and the pump in Cage 2, `r round(40/12, digits = 2)` $\mu$L per step. The glass syringe was connected to the tubing system of the flowers through five pinch valves [@nachev_psychophysics_2012]. The pinch valves controlled the flow of liquid from the pump to the system and from a reservoir of liquid to the pump. The reservoir (500 mL thread bottle, Roth, Germany) was filled with fresh nectar every day and was connected to the syringe through the valves.

Every day at around 1000 h, the old nectar was emptied from the system, which was rinsed and filled with plain water until 1500 h, when it was filled again with fresh nectar. Twice a week, the system was filled with 70% ethanol for an hour to prevent microbial growth, then repeatedly rinsed with water.

When a tagged bat approached a flower, the individual RFID number was read. If the bat then poked its nose into the flower and interrupted the light beam, this could trigger the release of a reward. The pinch valve opened and the pump moved the correct number of pre-programmed steps to dispense nectar to the head of the flower. The bat could easily hover in front of the flower and lick up the nectar. A reward was given only when both events occurred, i.e., the RFID reader identified a bat and the photo gate was triggered. The flowers and the pump were connected to a Windows PC, which ran the experimental programs and the program used to automatically flush, clean and fill the pump and tubing system (PhenoSoft Control, PhenoSys, Germany).

(ref:Schematic) Schematic of the cage and flower set-up (not drawn to scale)

```{r, Schematic, fig.cap= "(ref:Schematic)"}

include_graphics("/Users/shambhavi/Google Drive/Experiments & Data/SRL_2017/analysis/images/cage_schematic.png")
```

## Experimental procedure

Out of the array of eight flowers, each bat was uniquely assigned two adjacent flowers on the same side of the square frame, programmed to reward only one of the four bats in the cage. After the system was filled with fresh nectar at approximately 1700 h, the program was left running for data-collection till the next morning. Thus, the bats could begin visiting the flowers to collect a reward whenever they chose, which was at nightfall at approximately 1800 h every night. During the main experiment, the bats could make a maximum of 300 visits a night.

During the course of the night, when the syringe of the pump had been emptied, the pump re-filled automatically. This event happened only once every night. On the main experimental days this process took `r as.numeric(pump_time[1, 2])` minutes (SD = ±`r as.numeric(pump_time[1 ,3])`) for the horizontal pump, and `r as.numeric(pump_time[2, 2])` minutes (SD = ±`r as.numeric(pump_time[2, 3])`) for the vertical pump.

About `r overall_mean_unrew` % (SD = ±`r overall_sd_unrew`) of all visits made by the bats over all three experimental nights were wrongly unrewarded: the bats did not receive a reward during these visits even when the visits were made to a flower assigned to them that was rewarding at the time. This happened either during the pump refill times or when the pump was moving to reward a visit made by another bat that happened almost at the same time. Such events did not count towards the total of 300.

## Experimental design

The experiment proceeded through the following stages.

### Training

On the night the naïve bats were captured and placed into the flight cages, they could receive a reward from any of the flowers whenever they visited them throughout the night. To enable the bats to find the flowers, a small cotton pad soaked in dimethyl disulphide was placed on each flower. A small drop of honey was applied to the inside of the flowers to encourage the bats to place their heads inside, interrupt the photo gate, and trigger a nectar reward. By the end of the night, all the bats had found the flowers and learned to trigger rewards.

The next stage of training involved assigning the bats uniquely to two out of the eight flowers in the array. For an individual animal, only the two flowers assigned to it would elicit rewards from this stage of training until the end of the experiment. This stage was similar to the previous one, except the bats could only trigger a reward at their assigned flowers, and the chemical attractant and honey were not used.

To ensure that the bats were familiar with both flowers assigned to them, the bats went through one final stage of training: forced alternation. The bats received a reward at one of the two flowers for one trial, and then could only receive reward at the other flower for the next trial. In this way the bats had to alternate between the two flowers every single trial.  

### Serial Reversal Learning Task

In the serial reversal learning task, the bats had continuous access to two flowers: one that gave a 40 $\mu$L nectar reward, and one that remained empty. The location of the rewarding flower was not cued; however, after completing the alternation training phase, each bat knew the locations of both flowers that were potentially rewarding to it. After a bat had made 50 visits in total to the two flowers (regardless of relative allocation), a reversal occurred: the previously rewarding flower became the non-rewarding flower and *vice versa*. Importantly, only visits to the two flowers assigned to a bat counted towards the visit tally. Each set of 50 visits to the assigned two flowers, either at the start of each night or between reversals, was termed a ‘block’. There were six blocks and five reversals per night, unless the bat ceased visiting earlier. This was repeated for three consecutive nights. The same flower started the sequence every night. Consequently, the last flower to be rewarding one night was non-rewarding at the start of the next .

## Data analysis

The raw data collected during this study were the computer-logged events of feeder visits. Each event included the time stamp, animal ID, photo gate interruption duration and the volume of nectar dispensed. The bats made some visits and approaches to the flowers that were not assigned to them; however, these were in the minority, and were not considered for the analysis (see **Supplementary Material** for details). Each of the three experimental nights had five reversals, one at the end of each of the first five blocks; the end of the last block was the end of data-collection for the night. Each block was further divided into five bins of ten visits, in order to examine the bats’ behaviour within each block. R was used for all statistical analyses and creation of plots.

All the statistical models were fitted in a Bayesian framework using Hamiltonian Monte Carlo in the R package `brms` [@burkner_brms_2017] which is a front-end for `rstan` [@carpenter_stan_2017]. Generalized linear mixed models were used for the analyses (see **Supplementary Information** for the technical details of the model fitting). We report here the mean as a measure of central tendency and the 89% quantile-based credible intervals for the intercept and slope coeffients (89% boundaries are the default for reporting credible intervals – @mcelreath_statistical_2020). To aid in the interpretation of the model parameters we also present plots of the conditional effects of some of the predictor variables. 

Our analyses were focused on the first experimental night, when the bats experienced reversals for the first time and the effect of the reversals on the bats' behaviour was strongest. In order to quantify second-order learning, the first 25 visits in each block of the first night were considered. Our aim was to quantify how swiftly the bats switched from the previously-rewarding option to the newly-rewarding one, and this switch happened in this portion of the block. The area under the curve of these data points was calculated by the composite trapezoid rule: connecting all the points by a direct line using the R package `bayestestR` [@makowski_bayestestr_2019]. We then investigated the effect of reversal number on the areas under the curves by fitting a generalized linear mixed-model to the data. By definition, the very first block of the night was excluded as no reversal had been experienced at the start of this block. We then investigated the effect of block, bin and their interaction on the proportion of visits to the rewarding flower. The proportion of visits to the rewarding flower was calculated as the number of visits to the S+ divided by total number of visits to both the S+ and S-, and we denoted this as the Prop~rew~. A separate but similar model was fit to the data from the second and third nights, calculating the effect of experimental night, block and bin on the Prop~rew~. 

A few of the results report 95% confidence intervals, as opposed to credible intervals, and these are noted specifically. The confidence intervals were calculated by non-parametric bootstrapping without assuming a normal distribution of the data, using the `Hmisc` package **(Harrell 2021)**. 

## Data availability

All data and analysis code are available online at .....


# Results 

## A consistently high proportion of the bats' visits went to the rewarding option

```{r, Preparing-main-data}
#----------------------------------------
# Preparing data from the main experiment
#----------------------------------------
# The following terms are used in the analysis of the data:
# 1. Day: a single experimental night during which the data were collected
# 2. block: a group of 50 visits between each reversal where the same flower is rewarding
# 3. bin: a smaller group of visits within a block, the size of which can be set in the code below
# 4. visits: each individual flower visit

# setting binsize and breaks for cutting up the data into block and bin
binsize <- 10
breaks <- seq(0, 3000, binsize)

# making a separate data frame without any unrewarded visits and preparing it further with block and bin numbers
rev_learning <- rev_learning_all %>%
  arrange(Bat, DateTime) %>% 
  filter(Unrew == 0) %>%
  select(-Unrew) %>%
  # grouping the data to count the visits, noting the reversals separately
  group_by(Bat, Day) %>%
  mutate(count_vis = 1:n()) %>% 
  mutate(
    # noting whether the bat made a visit to the more or less rewarding flower
    reward_status = ifelse(reinforce1value > 0, 1, 0),
    # creating a column with the total number of visits made by a bat per day
    count_vis = ifelse(MsgValue1 == "switch", 0, 1)) %>% 
  # removing the visits that are numbered as 0
  #filter(count_vis > 0) %>% 
    # taking the cumulative sum of the visit counts
  mutate(count_vis = cumsum(count_vis)) %>%
  # setting the maximum number of visits a night
  filter(count_vis <= 300) %>%
  ungroup() %>%
  # creating a column with the block number, marking the reversals
  mutate(block = ifelse(MsgValue1 == "switch", 1, 0)) %>%
  group_by(Day, Bat) %>%
  mutate(block = cumsum(block)) %>%
  ungroup() %>%
  group_by(Day, Bat, block) %>%
  # creating a column with the number of visits within each block
  mutate(
    block_vis = ifelse(MsgValue1 == "switch", 0, 1),
    block_vis = cumsum(block_vis), 
  # cutting the visits inside each block into bin of the size set earlier
    bin = as.numeric(cut(block_vis, breaks, include.lowest = TRUE)))

#----------------------------------------------------------------------------
# Calculating the proportion of visits to the rewarding option averaged over all the bats
#----------------------------------------------------------------------------
# averaging the bats' choice behaviour over day, block and bin
rev_learning_avg <- rev_learning %>%
  ungroup() %>% 
  group_by(Day, block) %>%
  mutate(n_bats = n_distinct(Bat)) %>%
  group_by(Day, block, n_bats, bin) %>%
  # calculating the 95% confidence intervals
  group_modify(~ mean_cl_boot(.x$reward_status, conf.int = 0.95)) %>%
  ungroup() %>%
  group_by(Day) %>%
  mutate(
    day_bin = 1:n(),
    day_bin_vis = day_bin * binsize,
    reversal = ifelse(block != lead(block), "switch", "block")
  )

# creating a look-up table so the reversals can be marked
rev_main_avg <- rev_learning_avg %>%
  filter(
    reversal == "switch",
    Day %in% main_days
  ) %>%
  select(Day, block, day_bin, day_bin_vis) %>%
  mutate(Day = case_when(
    Day == "Day 1" ~ "Night 1",
    Day == "Day 2" ~ "Night 2",
    Day == "Day 3" ~ "Night 3"
  ), 
  day_bin_vis = day_bin_vis)

# calculating the sample size in each block
bat_labels <- rev_learning_avg %>%
  select(Day, block, n_bats) %>%
  distinct() %>%
  group_by(Day, block) %>%
  mutate(day_bin_vis = ifelse(block == 1, 25, 50)) %>%
  ungroup() %>%
  group_by(Day) %>%
  mutate(day_bin_vis = cumsum(day_bin_vis)) %>%
  filter(Day %in% main_days) %>%
  mutate(Day = case_when(
    Day == "Day 1" ~ "Night 1",
    Day == "Day 2" ~ "Night 2",
    Day == "Day 3" ~ "Night 3"
  ))

rev_learning_block_avg <- rev_learning %>%
  ungroup() %>% 
  group_by(Day, block) %>%
  mutate(n_bats = n_distinct(Bat)) %>%
  group_by(Day, block, n_bats) %>%
  # calculating the 95% confidence intervals
  group_modify(~ mean_cl_boot(.x$reward_status, conf.int = 0.95)) %>%
  ungroup() %>%
  group_by(Day) %>%
  mutate(
    day_bin = 1:n(),
    day_bin_vis = day_bin * binsize,
    reversal = ifelse(block != lead(block), "switch", "block")
  )
```

``` {r, S+-some-bins}
#-------------------------------------------------------------
# Calculating values for visits to the S+ for some of the bins
#-------------------------------------------------------------

# calculating and saving the values for the proportion of visits to the rewarding option in some of the bins
day1bin1 <- rev_learning %>%
  ungroup() %>%
  filter(
    Day == "Day 1",
    block == 1,
    bin == 1
  ) %>%
  mutate(reward_status = reward_status * 100) %>%
  group_modify(~ mean_cl_boot(.x$reward_status, conf.int = 0.95)) %>%
  mutate(
    y = round(y, digits = 1),
    ymin = round(ymin, digits = 1),
    ymax = round(ymax, digits = 1)
  )

day1bin2 <- rev_learning %>%
  ungroup() %>%
  filter(
    Day == "Day 1",
    block == 1,
    bin == 2
  ) %>%
  mutate(reward_status = reward_status * 100) %>%
  group_modify(~ mean_cl_boot(.x$reward_status, conf.int = 0.95)) %>%
  mutate(
    y = round(y, digits = 1),
    ymin = round(ymin, digits = 1),
    ymax = round(ymax, digits = 1)
  )

day1bin5 <- rev_learning %>%
  ungroup() %>%
  filter(
    Day == "Day 1",
    block == 1,
    bin == 5
  ) %>%
  mutate(reward_status = reward_status * 100) %>%
  group_modify(~ mean_cl_boot(.x$reward_status, conf.int = 0.95)) %>%
  mutate(
    y = round(y, digits = 1),
    ymin = round(ymin, digits = 1),
    ymax = round(ymax, digits = 1)
  )

day1bin6 <- rev_learning %>%
  ungroup() %>%
  filter(
    Day == "Day 1",
    block == 2,
    bin == 1
  ) %>%
  mutate(reward_status = reward_status * 100) %>%
  group_modify(~ mean_cl_boot(.x$reward_status, conf.int = 0.95)) %>%
  mutate(
    y = round(y, digits = 1),
    ymin = round(ymin, digits = 1),
    ymax = round(ymax, digits = 1)
  )

day1bin10 <- rev_learning %>%
  ungroup() %>%
  filter(
    Day == "Day 1",
    block == 2,
    bin == 5
  ) %>%
  mutate(reward_status = reward_status * 100) %>%
  group_modify(~ mean_cl_boot(.x$reward_status, conf.int = 0.95)) %>%
  mutate(
    y = round(y, digits = 1),
    ymin = round(ymin, digits = 1),
    ymax = round(ymax, digits = 1)
  )

day1last3bins <- rev_learning %>%
  ungroup() %>%
  filter(
    Day == "Day 1",
    block > 1,
    bin > 2
  ) %>%
  mutate(reward_status = reward_status * 100) %>%
  group_modify(~ mean_cl_boot(.x$reward_status, conf.int = 0.95)) %>%
  mutate(
    y = round(y, digits = 1),
    ymin = round(ymin, digits = 1),
    ymax = round(ymax, digits = 1)
  )

day2and3block1 <- rev_learning %>%
  ungroup() %>%
  filter(
    Day != "Day 1",
    block == 1
  ) %>%
  mutate(reward_status = reward_status * 100) %>%
  group_modify(~ mean_cl_boot(.x$reward_status, conf.int = 0.95)) %>%
  mutate(
    y = round(y, digits = 1),
    ymin = round(ymin, digits = 1),
    ymax = round(ymax, digits = 1)
  )
```

The bats made a very high number of visits to the rewarding option, `r report_m_ci_perc(overall, par = "y", brackets = "square")`. When a reversal occurred the bats abandoned the option that had been rewarding until then and switched to making most of their visits to the newly-rewarding option (figure \@ref(fig:overall-summary)). A consistent pattern emerged over all three nights: a sharp decrease in the proportion of visits to the previously-rewarding option immediately following a reversal, then a rapid increase in visits to the newly-rewarding option. 

At the start of the first night, in the very first bin of ten visits when the bats did not yet have any information about the available options and had never experienced a reversal, the Prop~rew~ (the proportion of visits to the rewarding option) averaged across individuals was at chance level: `r report_m_ci_perc(day1bin1, par = "y", brackets = "square")`, about 5 out of the 10 visits. Within the next ten visits however, Prop~rew~ increased to `r report_m_ci_perc(day1bin2, par = "y", brackets = "square")` and by the last bin of this first block was `r report_m_ci_perc(day1bin5, par = "y", brackets = "square")`. Immediately after the first experience of a reversal, the Prop~rew~ dropped down to `r report_m_ci_perc(day1bin6, par = "y", brackets = "square")` in the first ten visits, but came back up to `r report_m_ci_perc(day1bin10, par = "y", brackets = "square")` by the last bin of this block of fifty visits.

(ref:overall-summary) Visits to the rewarding one of two options over the first experimental night. Data are average proportions for bins of ten visits averaged over all the individuals that made visits in each bin. Data are indicated by white points in the first block before the bats had experienced any reversals; the bin averages of the other blocks are indicated by black points. Numbers indicate the bats that participated in a block. Shading shows 95% confidence intervals. Dashed lines show reversals

```{r, overall-summary, fig.cap = "(ref:overall-summary)", fig.width = 3, fig.height = 3}

p1 <- rev_learning_avg %>%
  # filtering only the first three main Days of the experiment:
  # one group had the experiment extended a further three Days
  filter(Day == "Day 1") %>%
  mutate(
    Day = case_when(
      Day == "Day 1" ~ "Night 1"
    ),
    firstpoint = as.factor(ifelse(block == 1 & Day == "Night 1", 1, 0)), 
    day_bin_vis = day_bin_vis - 5
  ) %>%
  ggplot(aes(day_bin_vis, y)) +
  geom_line() +
  geom_hline(yintercept = c(0.25, 0.5, 0.75, 1), linetype = "dotted") +
  geom_ribbon(aes(ymin = ymin, ymax = ymax), alpha = 0.3) +
  geom_point(aes(color = firstpoint, fill = firstpoint), shape = 21, size = 2) +
  scale_color_manual(values = c("0" = "black", "1" = "black")) +
  scale_fill_manual(values = c("0" = "black", "1" = "white")) +
  #facet_grid(. ~ Day) +
  scale_x_continuous(breaks = seq(50, 300, by = 50)) +
  scale_y_continuous(breaks = seq(0, 1.1, by = 0.25)) +
  geom_vline(aes(xintercept = day_bin_vis), data = rev_main_avg %>% filter(Day == "Night 1"), linetype = "dashed") +
  ylim(0,1.05) + 
  theme_srl2() +
  geom_text(
    data = bat_labels  %>% filter(Day == "Night 1"),
    aes(x = day_bin_vis, y = 1.05, label = n_bats, group = n_bats), size = 5, family = "Times"
  ) +
  labs(x = "Visits", y = "Visits to the rewarding option") +
  # theme(axis.title = element_text(size = 14)) + 
  # theme(axis.text = element_text(size = 12)) +  
  theme(legend.position = "none")

# p1.5 <- rev_learning_block_avg %>%
#   # filtering only the first three main Days of the experiment:
#   # one group had the experiment extended a further three Days
#   filter(Day %in% main_days) %>%
#   mutate(
#     Day = case_when(
#       Day == "Day 1" ~ "Night 1",
#       Day == "Day 2" ~ "Night 2",
#       Day == "Day 3" ~ "Night 3"
#     ),
#     firstpoint = as.factor(ifelse(block == 1 & Day == "Night 1", 1, 0)), 
#     day_bin_vis = day_bin_vis - 5
#   ) %>%
#   ggplot(aes(block, y)) +
#   geom_point(aes(color = firstpoint, fill = firstpoint), shape = 21) +
#   scale_color_manual(values = c("0" = "black", "1" = "black")) +
#   scale_fill_manual(values = c("0" = "black", "1" = "white")) +
#   geom_line() +
#   geom_ribbon(aes(ymin = ymin, ymax = ymax), alpha = 0.3) +
#   facet_grid(. ~ Day) +
#   scale_x_continuous(breaks = seq(1, 6, by = 1)) +
#   scale_y_continuous(breaks = seq(0, 1.1, by = 0.25)) +
#   #geom_vline(aes(xintercept = c(1, 2), linetype = "dashed")) +
#   geom_hline(yintercept = c(0.25, 0.5, 0.75, 1), linetype = "dotted") +
#   theme_srl2() +
#   geom_text(
#     data = bat_labels,
#     aes(x = block, y = 1.05, label = n_bats, group = n_bats), family = "Times"
#   ) +
#   labs(x = "Block", y = "Visits to the rewarding option") +
#   theme(legend.position = "none")

p1

first_10_last_10 <- rev_learning %>% 
  filter(bin == 1 | bin == 5, 
         block > 1, 
         Day == "Day 1") %>% 
  mutate(`Visit bin` = ifelse(bin < 3, "First 10 visits", "Last 10 visits")) %>% 
  ungroup() %>% 
  group_by(block, `Visit bin`) %>% 
  group_modify(~ mean_cl_boot(.x$reward_status, conf.int = 0.95)) %>% 
  mutate(day_bin_vis = (block*50) - 25) %>% 
  left_join(bat_labels %>% filter(Day == "Night 1") %>% select(day_bin_vis, n_bats), by = c("day_bin_vis")) %>% 
  select(-Day)

p1.5 <- first_10_last_10 %>% 
  ggplot() +
  geom_line(aes(day_bin_vis, y, group = `Visit bin`)) +
  geom_point(data = first_10_last_10 %>% filter(`Visit bin` == "First 10 visits"),  aes(day_bin_vis, y), shape = "triangle", size = 2) + 
  geom_point(data = first_10_last_10 %>% filter(`Visit bin` == "Last 10 visits"), aes(day_bin_vis, y), shape = "square", size = 2) + 
  geom_ribbon(aes(day_bin_vis, y, ymin = ymin, ymax = ymax, group = `Visit bin`), alpha = 0.3) +
  xlim(50, 300) + 
  scale_x_continuous(breaks = seq(50, 300, by = 50)) +
  scale_y_continuous(breaks = seq(0, 1.1, by = 0.25)) +
  geom_hline(yintercept = c(0.25, 0.5, 0.75, 1), linetype = "dotted") +
  ylim(0, 1.05) + 
  geom_vline(xintercept = c(50, 100, 150, 200, 250), linetype = "dashed") + 
  # scale_colour_viridis_d(option = "plasma") + 
  # scale_fill_viridis_d(option = "plasma") + 
  theme_srl2() +
  geom_text(
    aes(x = day_bin_vis, y = 1.05, label = n_bats, group = n_bats), size = 5, family = "Times"
  ) +
  labs(x = "Visits", y = "Visits to the rewarding option") + 
  # theme(axis.title = element_text(size = 14)) + 
  # theme(axis.text = element_text(size = 12)) +  
  theme(legend.position = "none")

p1.5  

p1.75 <- rev_learning %>% 
  ungroup() %>% 
  group_by(Day, count_vis) %>% 
  filter(Day == "Day 1", 
         count_vis > 0) %>% 
  group_modify(~ mean_cl_boot(.x$reward_status, conf.int = 0.95))

p1.75 %>% 
  ggplot(aes(count_vis, y)) + 
  geom_line() + 
  geom_ribbon(aes(ymin = ymin, ymax = ymax), alpha = 0.3) + 
  geom_hline(aes(yintercept = 0.5), linetype = "dotted") + 
  geom_vline(xintercept = c(50, 100, 150, 200, 250), linetype = "dashed") + 
  ylab("Prop. of rewarded visits") + 
  xlab("Visits") + 
  theme_srl2()

ggarrange(p1, p1.5, labels = c("a)", "b)"))
```

## Bats switch to the rewarding option faster as they experience more reversals

The proportion of visits to the rewarding flower in the first half of each reversal block increased as the bats experience more reversals. This conclusion was visually evident in the raw data (Figure \@ref(fig:raw-data-first-half)), and was held up by the statistical analysis. 

(ref:raw-data-first-half) Proportion of visits to the rewarding option out of the first 25 visits after each reversal on the first night. Thin coloured lines are data from the individual bats; the thick red line is the average area under the curve of all the bats.

```{r raw-data-first-half, fig.cap = "(ref:raw-data-first-half)", fig.width = 6, fig.height = 4}

# calculating and saving the values for the proportion of visits to the rewarding option overall

bin_means <- rev_learning %>% 
  ungroup() %>% 
  filter(Day == "Day 1",
         block > 1) %>% 
  group_by(bin) %>% 
  group_modify(~ mean_cl_boot(.x$reward_status, conf.int = 0.95)) %>%
  mutate(
    y = round(y, digits = 3),
    ymin = round(ymin, digits = 3),
    ymax = round(ymax, digits = 3)
  )
  
# extracting the mean for the final block

final_mean <- bin_means %>% 
  ungroup() %>% 
  filter(bin == 5) %>% 
  select(y)

final_mean_90 <- (as.numeric(final_mean))*0.9
  
# setting a different binsize to group the data
binsize_five <- 5
breaks_five <- seq(0, 3000, binsize_five)

# creating a separate dataframe with the data from the first night
pers_visits <- rev_learning %>% 
  # filtering out the first night
  filter(Day == "Day 1") %>%
  # binning the data
  mutate(bin_five = as.numeric(cut(block_vis, breaks_five, include.lowest = TRUE))) %>% 
  ungroup() %>% 
  select(Bat, block, bin, reward_status, block_vis, bin_five) %>% 
  # grouping by block
  group_by(Bat, block) %>% 
  # calculating the average proportion of visits to rewarding flower for each bat and each block
  mutate(block_average = mean(reward_status)) %>% 
  ungroup() %>% 
  group_by(Bat, block, block_average, bin_five) 

pers_bin_number <- pers_visits %>%
  # calculating the average proportion of visits to the rewarding flower for each bat, block and bin
  summarise(bin_five_average = mean(reward_status)) %>%
  ungroup() %>% 
  group_by(Bat) %>% 
  # calculating the total number of visits per animal over the whole night
  mutate(total_vis = 1:n()) %>% 
  ungroup() %>% 
  filter(block > 1) %>% 
  group_by(block, bin_five) %>% 
  summarise(overall_avg = mean(bin_five_average)) %>%
  mutate(cutoff = final_mean_90, 
         include = ifelse(overall_avg < cutoff, 1, 0)) %>% 
  filter(include == 1) %>% 
  ungroup() %>% 
  summarise(mean = mean(bin_five))

pers_bin_number <- round((as.numeric(pers_bin_number))*5)

pers_visits <- pers_visits %>% 
  ungroup() %>% 
  filter(block > 1, 
         block_vis <= pers_bin_number) %>% 
  ungroup() %>%
  group_by(Bat, block, bin_five) %>% 
  mutate(bin_five_average = mean(reward_status)) %>% 
  # selecting the required columns
  select(Bat, block, bin_five, bin_five_average) %>% 
  ungroup() %>% 
  group_by(Bat, block) %>% 
  # calculating the proportion of rewarded visits per bat per block
  mutate(block_bat_mean = mean(bin_five_average)) %>% 
  ungroup() %>% 
  group_by(block) %>% 
  # calculating the proportion of rewarded visits per block averaged all bats 
  mutate(block_mean = mean(bin_five_average))

pers_visits_first_night <- rev_learning %>% 
  filter(Day == "Day 1", 
         bin == 1, 
         block > 1) %>% 
  ungroup() %>% 
  group_by (Bat, block) %>% 
  mutate(mean_per_bat = mean(reward_status)) %>% 
  ungroup() %>% 
  group_by(block) %>% 
  mutate(mean_overall = mean(reward_status))

pers_visits <- pers_visits %>% 
  ungroup() %>% 
  filter(block > 1, 
         block_vis <= pers_bin_number) %>% 
  ungroup() %>%
  group_by(Bat, block, bin_five) %>% 
  mutate(bin_five_average = mean(reward_status)) %>% 
  # selecting the required columns
  select(Bat, block, bin_five, bin_five_average) %>% 
  ungroup() %>% 
  group_by(Bat, block) %>% 
  # calculating the proportion of rewarded visits per bat per block
  mutate(block_bat_mean = mean(bin_five_average)) %>% 
  ungroup() %>% 
  group_by(block) %>% 
  # calculating the proportion of rewarded visits per block averaged all bats 
  mutate(block_mean = mean(bin_five_average))

# plotting it out
p2.5 <- pers_visits %>%
  ggplot() + 
  geom_line(aes(block, block_bat_mean, group = Bat, colour = Bat)) + 
  geom_line(aes(block, block_mean), colour = "red", size = 2) + 
  ylim(0, 1) + 
  ylab("Proportion of rewarded visits in \n the first 12 visits after a reversal") + 
  xlab("Reversal number") +
  scale_colour_viridis_d() + 
  theme_srl() + 
  theme(legend.position = "right")

p2 <- pers_visits_first_night %>%
  select(Bat, block, mean_per_bat, mean_overall) %>% 
  ungroup() %>% 
  distinct() %>% 
  ggplot() + 
  geom_point(aes(block, mean_per_bat, group = Bat, colour = Bat), alpha = 0.75) + 
  geom_line(aes(block, mean_overall), colour = "red", size = 2) + 
  ylim(0, 1) + 
  ylab("Prop. of rewards in \n the first 10 visits") + 
  xlab("Block") +
  scale_colour_viridis_d() + 
  theme_srl() + 
  # theme(axis.title = element_text(size = 14)) + 
  # theme(axis.text = element_text(size = 12)) +  
  theme(legend.position = "top", 
        legend.title = element_blank(),
        legend.text = element_text(size  = 8),
        legend.margin=margin(0,0,0,0)) +
    guides(colour = guide_legend(nrow = 2))

p2
```

```{r perseverative visits}

pers_visits <- rev_learning %>% 
  ungroup() %>% 
  filter(block_vis > 0, 
         Day == "Day 2" | Day == "Day 3") %>% 
  group_by(Day, block, block_vis, count_vis) %>% 
  group_modify(~ mean_cl_boot(.x$reward_status, conf.int = 0.95)) %>% 
  mutate(pers_visits = ifelse(ymin < 0.5, 0, 1)) %>% 
  ungroup() %>% 
  group_by(Day, block) %>% 
  filter(pers_visits == 0) %>%
  ungroup() %>% 
  group_by(Day, block) %>% 
  mutate(check = count_vis - lag(count_vis), 
         check = ifelse(is.na(check), 0, check)) %>% 
  filter(check < 3) %>% 
  mutate(check = count_vis - lag(count_vis), 
         check = ifelse(is.na(check), 0, check)) %>% 
  filter(check < 3) %>% 
  mutate(check = count_vis - lag(count_vis), 
         check = ifelse(is.na(check), 0, check)) %>% 
  filter(check < 3) %>% 
  ungroup() %>% 
  group_by(Day, block) %>% 
  summarise(pers_visits = max(block_vis)) %>% 
  ungroup() %>% 
  group_modify(~ mean_cl_boot(.x$pers_visits, conf.int = 0.95)) %>% 
  mutate(y = round(y, digits = 2), 
         ymin = round(ymin, digits = 2), 
         ymax = round(ymax, digits = 2))

pers_visits_first_night <- rev_learning %>% 
  ungroup() %>% 
  filter(block_vis > 0, 
         Day == "Day 1", 
         block == 6) %>% 
  group_by(Day, block, block_vis, count_vis) %>% 
  group_modify(~ mean_cl_boot(.x$reward_status, conf.int = 0.95)) %>% 
  mutate(pers_visits = ifelse(ymin < 0.5, 0, 1)) %>% 
  ungroup() %>% 
  group_by(Day, block) %>% 
  filter(pers_visits == 0) %>%
  ungroup() %>% 
  group_by(Day, block) %>% 
  mutate(check = count_vis - lag(count_vis), 
         check = ifelse(is.na(check), 0, check)) %>% 
  filter(check < 3) %>% 
  ungroup() %>% 
  group_by(Day, block) %>% 
  summarise(pers_visits = max(block_vis)) %>% 
  ungroup() %>% 
  group_modify(~ mean_cl_boot(.x$pers_visits, conf.int = 0.95)) %>% 
  mutate(y = round(y, digits = 2), 
         ymin = round(ymin, digits = 2), 
         ymax = round(ymax, digits = 2))

pers_visits <- rev_learning %>% 
  ungroup() %>% 
  filter(block_vis > 0, 
         Day == "Day 1" & block == 6 | Day == "Day 2" | Day == "Day 3") %>% 
  group_by(Day, block, block_vis, count_vis) %>% 
  group_modify(~ mean_cl_boot(.x$reward_status, conf.int = 0.95)) %>% 
  mutate(pers_visits = ifelse(ymin < 0.5, 0, 1)) %>% 
  ungroup() %>% 
  group_by(Day, block) %>% 
  filter(pers_visits == 0) %>%
  ungroup() %>% 
  group_by(Day, block) %>% 
  mutate(check = count_vis - lag(count_vis), 
         check = ifelse(is.na(check), 0, check)) %>% 
  filter(check < 3) %>% 
  mutate(check = count_vis - lag(count_vis),
         check = ifelse(is.na(check), 0, check)) %>%
  filter(check < 3) %>%
  mutate(check = count_vis - lag(count_vis),
         check = ifelse(is.na(check), 0, check)) %>%
  filter(check < 3) %>%
  ungroup() %>% 
  group_by(Day, block) %>% 
  summarise(pers_visits = max(block_vis)) %>% 
  ungroup() %>% 
  group_modify(~ mean_cl_boot(.x$pers_visits, conf.int = 0.95)) %>% 
  mutate(y = round(y, digits = 2), 
         ymin = round(ymin, digits = 2), 
         ymax = round(ymax, digits = 2))

pers_visits_t_test <- rev_learning %>% 
  ungroup() %>% 
  filter(block_vis > 0, 
         Day == "Day 1" & block == 6 | Day == "Day 2" | Day == "Day 3") %>% 
  group_by(Day, block, block_vis, count_vis) %>% 
  filter(block_vis <= 8)
  ungroup() %>% 
  group_by(Day, block, block_vis) %>% 
  summarise(mean = mean(reward_status)) %>% 
  arrange(Bat)

# pers_visits %>% 
#   ggplot(aes(count_vis, y)) + 
#   geom_line() + 
#   geom_ribbon(aes(ymin = ymin, ymax = ymax), alpha = 0.3) +
#   facet_grid(Day~.) + 
#   geom_vline(xintercept = c(50, 100, 150, 200, 250), linetype = "dashed", colour = "red") + 
#   geom_hline(yintercept = c(0.5), linetype = "dotted") + 
#   theme_srl2()
```

```{r change point}

######
# Helper functions 
######


#' Make a lagged copy of a vector
#' @param x Input vector
#' @return y A lagged copy of the input vector x, with the first entry repeated
#' @details Not normally called directly, but via the cp_wrapper function instead.

lag_v <- function(x) c(x[1], x[1:(length(x) - 1)])

#' Make a lead copy of a vector
#' @param x Input vector of cumulative response counts
#' @return y A lead copy of the input vector x, with the last entry repeated
#' @details Not normally called directly, but via the cp_wrapper function instead.
#'
lead_v <- function(x) c(x[2:(length(x))], x[length(x)])

######
# CP wrapper 
######
#' Find change points in a sequence of choices based on given test and decision criterion
#' @param input A vector of correct or incorrect decisions, coded as 1s and 0s
#' @param isDiscrete A boolean parameter, true if the data to be analyzed are discrete,
#' false if continuous, e.g. succesive intervals
#' @param test Name of the test to be performed. The following tests are implemented:
#' "binomial" (random rate), "chisquare", "ttest", "KS" (Komolgorov-Smirnov). The binomial
#' test is used for finding changes in the rate parameter of a random rate process, either
#' intermittently (isDiscrete = TRUE) or continuously (isDiscrete = FALSE) sampled.
#' The chi square test is used with data where there has been a frequency change, as in,
#' e.g. correct choices. The t test should be used for normally distributed data.
#' The Komolgorov-Smirnof test is used for data with nonnormal or unknown distribution.
#' @param Crit A real-valued decision criterion on logit. Values recommended by
#' Gallistel et al. (2004) are between 1.3 and 6, which correspond to p values of 0.05 and
#' 0.000001, respectively. The values are the logarithms of the odds against the null
#' (no-change) hypothesis. logit = log[(1-p)/p], where p is the desired significance level
#' @return A data frame with the number of Trials (Trial) for each change point detected,
#' the cumulative number of correct responses, or successes, (CumSs),
#' and the ratio of correct/total choices (Slopes) for the trials since the last change
#' point and the current change point
#' @references Gallistel CR, Fairhurst S, Balsam P (2004) The learning curve:
#' Implications of a quantitative analysis. PNAS 101:13124-13131.
#' doi: 10.1073/pnas.0404965101
#' @examples
#' # generate dummy data with a change point at trial 120
#' input <- c(rbinom(120, 1, 0.5), rbinom(200, 1, 0.8))
#' cp_wrapper(input, TRUE, "chisquare", 3)
#' cp_wrapper(input, TRUE, "binomial", 3)
#'
#' # use included eyeblink data set:
#' eyeblink[,] # inspect data set
#' cp_wrapper(eyeblink, TRUE, "chisquare", 3)
#' # using small criterion, e.g. 2, fails due to computational problems
#' # better use "binomial" instead
#' cp_wrapper(eyeblink, TRUE, "binomial", 2)
#'
#' # use included plusmaze data set:
#' plusmaze[,] # inspect data set
#' (cp.1 <- cp_wrapper(plusmaze, TRUE, "binomial", 1.3))
#' # decrease sensitivity and detect different change points
#' (cp.2 <- cp_wrapper(plusmaze, TRUE, "binomial", 2))
#' # the chisquare test detects more change points even with higher criterion
#' (cp.3 <- cp_wrapper(plusmaze, TRUE, "chisquare", 2))
#'
#' # plotting data with ggplot2
#' library(ggplot2)
#' # first generate data.frame with cumulative responses:
#' my.data <- data.frame(Trial = 1:length(plusmaze[,]),
#' CumRespMeasure = cumsum(plusmaze)[,])
#' # plot cumulative learning curve with change points
#' ggplot(my.data) + geom_line(aes(Trial,CumRespMeasure)) +
#'  geom_point(data = cp.1, aes(Trial, CumSs), shape = 1, size = 6, color = "blue") +
#'  geom_point(data = cp.2, aes(Trial, CumSs), shape = 2, size = 3, color = "green") +
#'  geom_point(data = cp.3, aes(Trial, CumSs), shape = 3, size = 3, color = "red")
#'
#' # plot average response rate per trial
#' ggplot() + geom_step(data = cp.1, aes(Trial, Slopes)) +
#'  ylab("Average Response Rate per Trial")
#'
#' @export

cp_wrapper <- function(input, isDiscrete, test, Crit)
{
  if (!is.logical(isDiscrete)) stop("Second input (isDiscrete) must be boolean")

  input <- unlist(input, use.names = FALSE)
  Cum <- unlist(cumsum(input), use.names = FALSE)


  if ((test == "binomial") & (!identical(input %% 1, mat.or.vec(length(input), nc = 1))) &
      (isDiscrete))
    stop("When the binomial test is used with discrete-trial data,
         the data must be integer valued")

  if (!isDiscrete & test == "chisquare")
    stop("Cannot use chi square test when data are successive intervals")

  if ((test == "chisquare") & (sum(input + !input) != length(input)))
    stop("When chi square test is used, data must be binary, i.e. 0 or 1")

  switch(test,
         binomial = {
           CritLength <- 1 # When binomial test is used, there must be at least two data
         },
         chisquare = {
           CritLength <- 7 # A test of differences of frequency cannot be significant when
           # the total number of observations is less than 8
         },
         KS = {
           CritLength <- 7 # K-S test is not valid when there are fewer than 4 data in
           # either of the two samples
         },
         ttest = {
           CritLength <- 2 # when t test is used there must be at least 3 data
         },
         stop("Test can only be 'binomial', 'chisquare', 'ttest', or 'KS' ")
  )

  outputlist <- c() # resetting the output

  if (test == "chisquare" | test == "binomial")
  {
    CP <- matrix(c(0, 0), ncol = 2)
    outputlist <- list(Cumt = Cum) # Initializiing for while loop. The Cumt vector will
    # be truncated as change points are found
    outputlist$r <- 1 # Initializing for while loop

    while (!is.null(outputlist$r) & (length(outputlist$Cumt) > CritLength))
    {
      if (!isDiscrete) { # data are continuous
        R <- cpc(outputlist$Cumt) # putative inflection points
        L <- rrc(outputlist$Cumt, R) # logit vector for continuous case
      } else {# data are discrete
        R <- cpd(outputlist$Cumt) # putative inflection points

        switch(test,
               binomial = {# if binomial test is to be used
                 L <- rrd(outputlist$Cumt, R) # logit vector
               },
               chisquare = {# if chisquare test is to be used
                 L <- chi2logit(outputlist$Cumt, R) # logit vector
               },
               stop("For discrete data test can only be 'binomial' or 'chisquare' ")
        )
      }
      outputlist <- trun(outputlist$Cumt, R, L, Crit) #Cumt is the truncated cumulative
      # record; Lt is the logit vector up to the point of
      # truncation (not used); r is the change point; r is empty if there is
      # no significant change point

      if (!is.null(outputlist$r)) { # if change point, update change-point array
        if (!isDiscrete) # In the continuous case, the row count goes in the
          # y-column of the output array (the event count); in all other cases, it goes
          # in the x column. In the continuous case, the x column
          # contains the successive event times
        {
          cumrCP <- CP[length(CP[, 1]), 2] + outputlist$r # Add Cumt row for latest change
          # point to last change point to get Cum row of latest change point
          CP <- rbind(CP,c(Cum[cumrCP], cumrCP)) # Value of cumulative record at the
          # change point
        }else{# In the discrete case, the row data go in the first column of CP
          cumrCP <- CP[length(CP[, 1]), 1] + outputlist$r # Add Cumt row for latest
          # change point to last change point to get Cum row of latest change point
          CP <- rbind(CP, c(cumrCP, Cum[cumrCP])) # Value of cumulative record at the
          # change point
        }

      } # end of updating change-point array

    } # end of while loop for finding successive change points with binomial test
  } # end of section that computes change-point array with binomial or chi square test

  if (test == "ttest" | test == "KS")
  {
    outputlist <- list(newinput = input) # Initializing for while loop. These vectors will
    # be truncated as CPs are found out
    CP <- matrix(c(0, 0), ncol = 2) # Initializing for while loop
    outputlist$r <- 1 # Initializing for while loop

    while (!is.null(outputlist$r) & (length(outputlist$newinput) > CritLength))
    {
      outputlist$newCum <- cumsum(outputlist$newinput)
      if (!isDiscrete) {# data are continuous
        R <- cpc(outputlist$newCum) # putative inflection points
      } else {# data are discrete
        R <- cpd(outputlist$newCum) # putative inflection points
      } #computing R vector

      switch(test,
             KS = {# if K-S test is to be used
               outputlist$r <- KS(outputlist$newinput, R, Crit) # logit vector
             },
             ttest = {# if t test is to be used
               outputlist$r <- cpt(outputlist$newinput, R, Crit) # logit vector
             }
      ) # end of computing new changepoint
      if (!is.null(outputlist$r)) {# if there is a change point, update change-point array
        # and truncate newinput
        cumrCP <- CP[length(CP[, 1]), 1] + outputlist$r # Add Cumt row for latest change
        # point to last change point to get Cum row of latest change point
        CP <- rbind(CP, c(cumrCP, Cum[cumrCP])) # Value of cumulative record at the change
        # point
        outputlist$newinput <-
          outputlist$newinput[(outputlist$r + 1):length(outputlist$newinput)]
        # Truncated data vector

      } # end of updating change-point array & truncating
    } # end of while loop for computing CP array when K-S or t test are used
  } # end of section that computes CP array when K-S or t test are used

  # Adding final point to output array
  if (isDiscrete) #
  {
    CP <- as.data.frame(rbind(CP, c(length(Cum), Cum[length(Cum)])))
    names(CP) <- c("Trial", "CumSs")
  } else {# in continuous case, row count goes in y column
    CP <- as.data.frame(rbind(CP, c(Cum[length(Cum)], length(Cum))))
    names(CP) <- c("Time", "Events")

  }
  # last row of CP array gives coordinates of final point in cumulative record
  CP$Slopes <- (lead_v(CP[, 2]) - CP[, 2]) / (lead_v(CP[, 1]) - CP[, 1])
  CP$Slopes <- ifelse(is.na(CP$Slopes), lag_v(CP$Slopes), CP$Slopes)
  CP
}

######
# CP detector 
######

#' Find putative change point in discrete-time cumulative records
#' @param Cum Input vector of cumulative response counts
#' @return R A vector with the same length as Cum, with putative change points for each
#' trial. These correspond to the preceding trial at which the deviation of the
#' observed count from the expected count is maximal
#' @details Not normally called directly, but via the cp_wrapper function instead.

cpd <- function(Cum)
{
  N <- 1:length(Cum) #Trial count vector
  Slopes <- Cum / N #Average count or measure per trial for trials 1 to N

  M <- diag(length(Cum))
  M[upper.tri(M)] <- 1 # Mask with ones on and above diagonal & zeros below

  Diag <- M * matrix(rep(Slopes, length(Slopes)), nrow = length(Slopes), byrow = TRUE)
  # Creates an array in which successive cols have successive slopes of the cumulative
  # record. The slope for a given col fills all the cells on and above the main diagonal

  Preds <- 1:length(Slopes) * Diag
  # Predicted (expected) cumulative values in a diagonal array

  Obs <- Cum * M
  # Diagonal array of observed cumulations

  Devs <- abs(Obs - Preds) # Diagonal array of deviations from expectations

  mx <- M * matrix(rep((apply(Devs, 2, max)), length(Slopes)), nrow = length(Slopes),
                   byrow = TRUE)

  # mx is a matrix listing the maxima of the deviations

  R <- merge(data.frame(col = 1:length(Cum)),
                 as.data.frame(which(Devs == mx & mx > 0, arr.ind = TRUE)), by = "col",
             all.x = TRUE)

  names(R)[names(R) == "row"] <- "R"
  names(R)[names(R) == "col"] <- "N"
  # R at this stage is a data.frame with columns N, and R. R has the trial numbers of the
  # putative change points and N - the trial numbers.

  stats::aggregate(R$R, by = R["N"], min)$x

  # return the minimum of the trial numbers of the putative change points for each trial
  # number
}

#' Find putative change point in continuous-time cumulative records
#' @param Cum Input vector of the cumulative interevent intervals
#' @return R A vector with the same length as Cum, with putative change points for each
#' event. The putative change point corresponding to the Nth
#' event is the preceding event at which the deviation of the observed event count
#' from the expected event count is maximal. The expected event count
#' at any earlier event, n, is Cum[n], the interval up to the nth event,
#' divided by the average interevent interval over the range from n = 0 to n = N
#' The deviation from expectation is n - this expectation. R is the value of n at
#' which this deviation is maximal
#' @details Not normally called directly, but via the cp_wrapper function instead

cpc <- function(Cum)
{
  N <- 1:length(Cum) # Event count vector
  Slopes <- N / Cum # Average slope up to given point in cumulative function

  M <- diag(length(Cum))
  M[upper.tri(M)] <- 1 # Mask with ones on and above diagonal & zeros below

  Diagonal <- M * matrix(rep(Slopes, length(Slopes)), nrow = length(Slopes), byrow = TRUE)
  # Creates an array in which successive cols have successive slopes of the cumulative
  # record. The slope for a given col fills all the cells on and above the main diagonal

  Preds <-  Cum * Diagonal
  # Creates diagonal array of the predicted numbers of events at each time in Cum

  Obs <- 1:length(Slopes) * M
  # Diagonal array with actual numbers of events

  Devs <- abs(Obs - Preds) # Diagonal array of deviations from expectations

  mx <- M * matrix(rep((apply(Devs, 2, max)), length(Slopes)), nrow = length(Slopes),
                   byrow = TRUE)

  # mx is a matrix listing the maxima of the deviations

  R <- merge(data.frame(col = 1:length(Cum)),
             as.data.frame(which(Devs == mx & mx > 0, arr.ind = TRUE)), by = "col",
             all.x = TRUE)

  names(R)[names(R) == "row"] <- "R"
  names(R)[names(R) == "col"] <- "N"
  # R at this stage is a data.frame with columns N, and R. R has the cumulative
  # inter-event intervals of the putative change points and N - the event numbers.

  stats::aggregate(R$R, by = R["N"], min)$x

  # return the minimum of the trial numbers of the putative change points for each trial
  # number
}

#' Truncate the cumulative record at significant change point
#' @param Cum Input vector of cumulative response counts
#' @param R A vector with trial numbers of putative change points
#' @param L A vector giving for each trial the pseudologit, approximately
#' the log of the odds that there has been a change point
#' @param Crit A real-valued decision criterion on logit
#' @return A list of Cumt, the truncated cumulative record,
#' Lt, the truncated L vector up to the row at which a change point was detected,
#' and r, the row at which L was truncated.
#' @details Not normally called directly, but via the cp_wrapper function instead.
#' Works for both discrete and continuous cumulative records. All input arguments are
#' obligatory.

trun <- function(Cum, R, L, Crit)
{
  # Cumt is truncated cumulative record,
  # the record as it would be if observation began at time CP+ or after trial CP
  # Lt is the L vector truncated at Alert, which is the row at which an CP was detected
  # r is row at which it was truncated.

  La <- abs(L)
  if (length(which(La > Crit)) > 0) {
    Alert <- min(which(La > Crit))# Finds first row where decision criterion is exceeded
  } else {# If there is no such row, then Alert will be NULL
    Alert <- NULL
  }

  if (is.null(Alert)) {
    list(Cumt = Cum, Lt = L, r = Alert)
  }
  else
  {
    r <- R[Alert] # The putative change point at the value of Cum that first yields
    # significant logit.This putative change point is always the number of an earlier
    # event or trial

    I <- c(Cum[1], diff(Cum)) # Interevent interval vector OR vector
    # of responses on successive trials

    Cumt <- cumsum(I[(r + 1):(length(I))]) # Truncated cumulative record

    Lt <- L[1:Alert] # Truncated logit vector

    list(Cumt = Cumt, Lt = Lt, r = r)
  }

}


######
# Logits 
######
#' Compute the pseudologit vector for random rate discrete data, using binomial test
#' @param Cum Input vector of cumulative response counts
#' @param R A vector with trial numbers of putative change points
#' @return L A vector giving for each trial the pseudologit, approximately
#' the log of the odds that there has been a change point
#' @details Not normally called directly, but via the cp_wrapper function instead

rrd <- function(Cum, R)
{
  # L is the vector giving for each trial the pseudologit--log[P / (1 - P + p)]--
  # for the probability of observing n_a or fewer post-CP responses if
  # lambda_a / lambda_b = 1
  # where lambda_a and lambda_b are the rates of responding before and after
  # the putative change point; P is the probability of observing Cum - Cum(R) or fewer
  # responses after the putative change point; and p is the probability of
  # observing exactly Cum - Cum[R] responses after the putative change point.
  # Note that the numerator and denominator of the pseudologit are not complementary
  # probabilities, as they are in a true logit; they both include the probability of
  # observing exactly Cum - Cum[R] post-CP responses, where Cum is the cumulative number
  # of responsess at the moment of calculation.
  # The putative change point is the row (R = trial number) at which the difference
  # between the observed and expected number of responses is maximal.
  # Cum / N is the slope of the cumulative record up to N (i.e., the average response rate
  # up to the trial of calculation
  # (Cum / N) * R is the expected number of responses up to trial R; Cum[R] is the
  # observed number. A negative pseudologit means that n_a is less than expected.
  Trial <- 1:length(Cum) # The trial count vector
  Ta <- Trial - R # the trials since the putative change point
  p <- Ta / Trial # probability of any one response occuring during the trials since the
  # putative CP
  Na <- Cum - Cum[R] # number of responses since putative CP

  Peqorl <- stats::pbinom(Na, Cum, p)[-1]
  # Probability of observing Na or fewer total responses on the trials since putative CP

  Peqorm <- 1 - Peqorl + stats::dbinom(Na, Cum, p)[-1] #Probability of observing Na or
  # more total responses on the trials since putative CP. Note that this probability
  # overlaps the "complementary" probability; both include the probability of observing
  # exactly Na events.

  c(0, log10(Peqorl / Peqorm)) # Vector of the pseudologits

}

#' Compute the pseudologit vector for continuous random rate case
#' @param Cum A cumulative interevent interval vector
#' @param R A vector with trial numbers of putative change points
#' @return L A vector giving for each trial the pseudologit, approximately
#' the log of the odds that there has been a change point
#' @details  For use when finding changes in the rate parameter of a random rate process.
#' Not normally called directly, but via the cp_wrapper function instead

rrc <- function(Cum, R)
{
  # The output is the vector giving for each event the pseudologit log[P / (1 - P + p)]
  # for the probability of observing n_a or fewer post-CP responses if
  # lambda_a / lambda_b = 1
  # where lambda_a and lambda_b are the rates of responding before and after
  # the putative change point; P is the probability of observing N - R or fewer
  # events after the putative change point; and p is the probability of
  # observing exactly N - R events after the putative change point.
  # Note that the numerator and denominator of the pseudologit are not complementary
  # probabilities, as they are in a true logit; they both include the probability of
  # observing exactly N - R events, where N is the total number of events at the moment of
  # calculation. The putative change point is the row (R = event number) at which
  # the difference between (N / Cum[N]) * (Cum[R]) and Cum[R] is maximal.
  # N / Cum[N] is the slope of the cumulative record up to the Nth event.
  # Cum[R] is the time up to the Rth event.
  # A negative pseudologit means that n_a is less than expected.

  Ta <- Cum - Cum[R] # the interval elapsed since the putative CP
  p <- Ta / Cum # probability of any one event falling after the putative CP
  N <- 1:length(Cum) # event count vector
  Na <- N - R # vector giving number of events since putative CP



  Peqorl <- stats::pbinom(Na, N, p)[-1]
  # Probability of observing Na or fewer events in the interval Ta

  Peqorm <- 1 - Peqorl + stats::dbinom(Na, N, p)[-1] # Probability of observing Na or more
  # events in the interval Ta. Note that this probability overlaps the "complementary"
  # probability; both include the probability of observing exactly Na events.

  c(0, log10(Peqorl / Peqorm)) # Vector of the pseudologits
}


#' Compute the pseudologit vector for random discrete data using Chi squared and Fisher
#' exact tests
#' @param Cum Input vector of cumulative response counts
#' @param R A vector with trial numbers of putative change points
#' @return Lgt A vector giving for each trial the pseudologit, approximately
#' the log of the odds that there has been a change point
#' @details Not normally called directly, but via the cp_wrapper function instead.
#' For cases, in which the chi square test is not valid (expected obersavations all
#' smaller than 5), the Fisher exact test is used instead. Occasionally, for noisy data
#' even this test will fail. In that case use the rrd function instead. Notice that the p
#' values delivered by this test are estimated from a 1000 Monte Carlo simulations.

chi2logit <- function(Cum, R)
{
  # Level is the point beyond which the
  # Chi square test is not valid (because no expectation < 5)
  # and NV gives the rows for which the chi square test cannot
  # validly be performed (because at least one cell has an expectation
  # less than 5).
  N <- 1:length(Cum) # The trial count vector

  Level1 <- min(which(N > 7)) # Finds the row
  # below which even the Fisher exact test should not be applied, because it
  # cannot yield a p value lower than .1 with fewer than 7 observations, and,
  # moreover, for fewer than 4 observations, fishexct returns p values
  # greater than 1.

  Ta <- N - R # the trials since the putative change point
  Onespre <- Cum[R] # number of (corect) responses up to the putative CP
  Onespre[which(is.na(Onespre))] <- 0
  Onespost <- Cum - Cum[R] # number of (correct) responses since the putative CP
  Onespost[which(is.na(Onespost))] <- 0
  Zeroespre <- R - Onespre # number of incorrect responses (or no responses) up to the
  # putative CP
  Zeroespre[which(is.na(Zeroespre))] <- 0
  Zeroespost <- Ta - Onespost # number of incorrect responses (or no responses) since the
  # putative CP
  Zeroespost[which(is.na(Zeroespost))] <- 0

  Smallest <- pmin(Cum, N - Cum) * pmin(R, Ta) / N # The smallest expectation is the
  # smallest row total times the smallest column total, divided by N

  NV <- which(Smallest < 5) # Critical value for cell expectations is 5. NV is the
  # vector of rows whose contingency tables have a cell with less than the
  # critical value

  Level <- max(NV) # The highest level at which the  smallest expectation is less than 5.
  # Chi square is not valid when smallest expectation is less than 5.

  p_chisq <- rep(1, length(N)) # initiate pvalue vector
  # mat <- matrix(rep(0, 4), nrow = 2, ncol = 2)

  for (i in 1:length(N)) # loop over the trial count vector
  {
    mat <- cbind(c(Onespre[i], Onespost[i]),
                 c(Zeroespre[i], Zeroespost[i]))

    p_chisq[i] <-
      ifelse(N[i] > Level,
             stats::chisq.test(mat, simulate.p.value = TRUE, B = 1000)$p.value,
             ifelse(N[i] <= Level & N[i] > Level1,
                    # For the cases in which chi square is invalid, calculate p values
                    # from Fisher's exact test.
                    stats::fisher.test(mat, simulate.p.value = TRUE, B = 1000)$p.value,
                    1
                    )
             )
  }

  Lgt <- ifelse(p_chisq == 1, 0, log10(p_chisq / (1 - p_chisq)))
  Lgt
}


#' Uses t test to find first significant change point
#' @param Data A vector of trial by trial measures or successive intervals
#' @param R A vector of putative change points
#' @param Crit Decision criterion, the value the logit must exceed
#' for the function to return a significant change point
#' @return CP The first significant change point
#' @details This test is appropriate if one is looking for a change in the expectation of
#' a renewal event-generating process, where the interevent intervals are normally (rather
#' than exponentially) distributed. Not normally called directly, but via the cp_wrapper
#' function instead.

cpt <- function(Data, R, Crit)
{
  Data <- unlist(Data, use.names = FALSE)
  L <- c(0, 0) # initialization of the logit vector up to and including
  # the row where the significance criterion (Crit) was exceeded
  r <- 3 # Initializing for while loop, with index r

  while (abs(L[length(L)]) < Crit)
  { # loop that ends when critical L found or end of data reached
    if (!is.na(R[r])) # if R[r] is NA skip to next r
    {
      if ((sum(stats::sd(Data[1:R[r]]), stats::sd(Data[(R[r] + 1):r]),
               na.rm = TRUE) > 0) &
          (length(Data[1:R[r]]) > 1) & (length(Data[(R[r] + 1):r]) > 1))# test cannot be
        # run when there is no variance on either side of putative CP, for example, in the
        # sequence 0 0 0 3 3 3 or from a single observation e.g. 0 vs 3 2 5
      {
        pb <- stats::t.test(Data[1:R[r]], Data[(R[r] + 1):r], "greater")$p.value
        # Probability that the mean after the putative change point is greater than the
        # mean up to and including the putative change point
        pl <- stats::t.test(Data[1:R[r]], Data[(R[r] + 1):r], "less")$p.value
        # Probability that the mean after the putative change point is less than the
        # mean up to and including the putative change point
        L[r] <- log10(pb / pl) # Latest logit
      } else {
        L[r] <- 0
      } # end of if that computes individual logit (L) values
    } # end of if that checks if R[r] is NA


    r <- r + 1 # Incrementing latest row for next iteration
    if (r > length(Data)) break # end of data reached

  } # end of while loop

  if (abs(L[length(L)]) > Crit) CP <- R[r - 1] else CP <- NULL # if no significant change
  # point, CP empty
  CP
}


#' Uses Komolgorov-Smirnov test to find first significant change point
#' @param Data A vector of trial by trial measures or successive intervals
#' @param R A vector of putative change points
#' @param Crit Decision criterion, the value the logit must exceed
#' for the function to return a significant change point
#' @return r1 the change point row when the decision criterion is exceeded
#' @details Not normally called directly, but via the cp_wrapper function instead.

KS <- function(Data, R, Crit)
{
  # L is the pseudologit vector for rows where the
  # approximation formula for the Kolmogorov-Smirnov p is valid.
  # Its final value is the first value to exceed the decision criterion
  # t is the col vector of rows for which L is defined
  # r1 is the change point row when the decision criterion is exceeded
  # r2 is the row at which the decision criterion is exceeded
  # If there are no testable rows or if the decision criterion is never
  # exceeded, the variables are returned empty

  N <- 1:length(Data) # Number of rows in Data vector
  L <- rep(0, length(N)) # initialization of the logit vector

  Na <- N - R # Col vector giving for each row in Data the number of rows
  # after the putative change point. So R gives the number of
  # rows before the change point and Na the number after

  Test <- which(Na * R / (Na + R) >= 4) # For the approximation to the KS
  # probability to be valid, the product of the two n's divided by
  # the sum must be greater than or equal to 4. Test is the col
  # vector of rows that satisfy this constraint--the row numbers(!),
  # not the entries themselves
  r1 <- c()
  r2 <- c()
  t <- rep(0, length(Test))

  if (length(Test) > 0) {# check if any rows satisfy the constraint and proceed
    for (T in 1:length(Test)) {
      pval <- suppressWarnings(stats::ks.test(Data[1:R[Test[T]]],
                                       Data[(R[Test[T]] + 1):Test[T]],
                                       exact = FALSE)$p.value)
      L[T] <- log10((1 - pval) / pval)
      t[T] <- Test[T] # The row to which the latest value of L[T] "belongs"

      if (L[T] > Crit) # Value of logit exceeds decision criterion
      {
        r2 <- Test[T] # the row (in Data) at which the criterion is exceeded
        r1 <- R[Test[T]] # the change point when the criterion is exceeded
        L <- L[1:T] # Drop rows of L after row in which decision criterion reached
        break # Break out of loop when decision criterion exceeded
      }
    }
  }
  r1
}

######
# CP finder
######
#' Find putative change point in discrete-time cumulative records
#' @param Cum Input vector of cumulative response counts
#' @return R A vector with the same length as Cum, with putative change points for each
#' trial. These correspond to the preceding trial at which the deviation of the
#' observed count from the expected count is maximal
#' @details Not normally called directly, but via the cp_wrapper function instead.

cpd <- function(Cum)
{
  N <- 1:length(Cum) #Trial count vector
  Slopes <- Cum / N #Average count or measure per trial for trials 1 to N

  M <- diag(length(Cum))
  M[upper.tri(M)] <- 1 # Mask with ones on and above diagonal & zeros below

  Diag <- M * matrix(rep(Slopes, length(Slopes)), nrow = length(Slopes), byrow = TRUE)
  # Creates an array in which successive cols have successive slopes of the cumulative
  # record. The slope for a given col fills all the cells on and above the main diagonal

  Preds <- 1:length(Slopes) * Diag
  # Predicted (expected) cumulative values in a diagonal array

  Obs <- Cum * M
  # Diagonal array of observed cumulations

  Devs <- abs(Obs - Preds) # Diagonal array of deviations from expectations

  mx <- M * matrix(rep((apply(Devs, 2, max)), length(Slopes)), nrow = length(Slopes),
                   byrow = TRUE)

  # mx is a matrix listing the maxima of the deviations

  R <- merge(data.frame(col = 1:length(Cum)),
                 as.data.frame(which(Devs == mx & mx > 0, arr.ind = TRUE)), by = "col",
             all.x = TRUE)

  names(R)[names(R) == "row"] <- "R"
  names(R)[names(R) == "col"] <- "N"
  # R at this stage is a data.frame with columns N, and R. R has the trial numbers of the
  # putative change points and N - the trial numbers.

  stats::aggregate(R$R, by = R["N"], min)$x

  # return the minimum of the trial numbers of the putative change points for each trial
  # number
}

#' Find putative change point in continuous-time cumulative records
#' @param Cum Input vector of the cumulative interevent intervals
#' @return R A vector with the same length as Cum, with putative change points for each
#' event. The putative change point corresponding to the Nth
#' event is the preceding event at which the deviation of the observed event count
#' from the expected event count is maximal. The expected event count
#' at any earlier event, n, is Cum[n], the interval up to the nth event,
#' divided by the average interevent interval over the range from n = 0 to n = N
#' The deviation from expectation is n - this expectation. R is the value of n at
#' which this deviation is maximal
#' @details Not normally called directly, but via the cp_wrapper function instead

cpc <- function(Cum)
{
  N <- 1:length(Cum) # Event count vector
  Slopes <- N / Cum # Average slope up to given point in cumulative function

  M <- diag(length(Cum))
  M[upper.tri(M)] <- 1 # Mask with ones on and above diagonal & zeros below

  Diagonal <- M * matrix(rep(Slopes, length(Slopes)), nrow = length(Slopes), byrow = TRUE)
  # Creates an array in which successive cols have successive slopes of the cumulative
  # record. The slope for a given col fills all the cells on and above the main diagonal

  Preds <-  Cum * Diagonal
  # Creates diagonal array of the predicted numbers of events at each time in Cum

  Obs <- 1:length(Slopes) * M
  # Diagonal array with actual numbers of events

  Devs <- abs(Obs - Preds) # Diagonal array of deviations from expectations

  mx <- M * matrix(rep((apply(Devs, 2, max)), length(Slopes)), nrow = length(Slopes),
                   byrow = TRUE)

  # mx is a matrix listing the maxima of the deviations

  R <- merge(data.frame(col = 1:length(Cum)),
             as.data.frame(which(Devs == mx & mx > 0, arr.ind = TRUE)), by = "col",
             all.x = TRUE)

  names(R)[names(R) == "row"] <- "R"
  names(R)[names(R) == "col"] <- "N"
  # R at this stage is a data.frame with columns N, and R. R has the cumulative
  # inter-event intervals of the putative change points and N - the event numbers.

  stats::aggregate(R$R, by = R["N"], min)$x

  # return the minimum of the trial numbers of the putative change points for each trial
  # number
}

#' Truncate the cumulative record at significant change point
#' @param Cum Input vector of cumulative response counts
#' @param R A vector with trial numbers of putative change points
#' @param L A vector giving for each trial the pseudologit, approximately
#' the log of the odds that there has been a change point
#' @param Crit A real-valued decision criterion on logit
#' @return A list of Cumt, the truncated cumulative record,
#' Lt, the truncated L vector up to the row at which a change point was detected,
#' and r, the row at which L was truncated.
#' @details Not normally called directly, but via the cp_wrapper function instead.
#' Works for both discrete and continuous cumulative records. All input arguments are
#' obligatory.

trun <- function(Cum, R, L, Crit)
{
  # Cumt is truncated cumulative record,
  # the record as it would be if observation began at time CP+ or after trial CP
  # Lt is the L vector truncated at Alert, which is the row at which an CP was detected
  # r is row at which it was truncated.

  La <- abs(L)
  if (length(which(La > Crit)) > 0) {
    Alert <- min(which(La > Crit))# Finds first row where decision criterion is exceeded
  } else {# If there is no such row, then Alert will be NULL
    Alert <- NULL
  }

  if (is.null(Alert)) {
    list(Cumt = Cum, Lt = L, r = Alert)
  }
  else
  {
    r <- R[Alert] # The putative change point at the value of Cum that first yields
    # significant logit.This putative change point is always the number of an earlier
    # event or trial

    I <- c(Cum[1], diff(Cum)) # Interevent interval vector OR vector
    # of responses on successive trials

    Cumt <- cumsum(I[(r + 1):(length(I))]) # Truncated cumulative record

    Lt <- L[1:Alert] # Truncated logit vector

    list(Cumt = Cumt, Lt = Lt, r = r)
  }

}

```

```{r}
cutoff <- 12
lookup <- tibble(block = c(6, rep(c(2, 3, 4, 5, 6), 2)), 
                 Day = c("Day 1", rep("Day 2", 5), rep("Day 3", 5)), 
                 overall_block = 1:11)

change_point <- rev_learning %>% 
  select(Day, Bat, block, bin, block_vis, reward_status) %>% 
  filter(Day == "Day 2" | Day == "Day 3" | Day == "Day 1" & block == 6, 
         block > 1, 
         block_vis <= cutoff & block_vis > 0) %>% 
  mutate(Block = paste0(Day, " ", "- Block ", block)) %>% 
  ungroup() %>% 
  group_by(Bat, Block) %>%
  do(cp_wrapper(.$reward_status, isDiscrete = TRUE, "ttest", 1.5))  

#generate a cumulative response vs trial plot:
change_point %>% 
  filter(str_detect(Block, "Day 1") | str_detect(Block, "Day 2")) %>%
  ggplot(aes(Trial, CumSs, colour = Block, group = Block
             )) +
  geom_jitter(size = 0.75) +
  geom_line(alpha = 0.2, size = 1.25) + 
  geom_vline(xintercept = c(5, 10), linetype = "dotted") +
  # scale_x_continuous(limits = c(0, 15), breaks = seq(0, 15, by = 1)) +
  # scale_y_continuous(limits = c(0, 15), breaks = seq(0, 15, by = 1)) +
  facet_wrap(.~Bat) +
  xlab("Number of trials for each change point") + 
  ylab("Cumulative number of correct responses") + 
  theme_bw()
  
change_point %>% 
  filter(str_detect(Block, "Day 3")) %>%
  # mutate(Block = as.factor(Block)) %>%
  ggplot(aes(Trial, CumSs, colour = Block, group = Block
             )) +
  geom_jitter(size = 0.75) +
  geom_line(alpha = 0.2, size = 1.25) + 
  geom_vline(xintercept = c(5, 10), linetype = "dotted") +
  # scale_x_continuous(limits = c(0, 15), breaks = seq(0, 15, by = 1)) +
  # scale_y_continuous(limits = c(0, 15), breaks = seq(0, 15, by = 1)) +
  facet_wrap(.~Bat) +
  xlab("Number of trials for each change point") + 
  ylab("Cumulative number of correct responses") + 
  theme_bw()
```

```{r plateau}

plateau <- rev_learning %>% 
  select(Bat, Day, block, bin, block_vis, count_vis, reward_status) %>% 
  filter(
         #Day == "Day 1" & block == 6 |
         Day == "Day 2" | Day == "Day 3",
         block > 1, 
         block_vis > 0 & block_vis < 11) %>% 
  mutate(Day = case_when(Day == "Day 1" ~ "Night 1", 
                         Day == "Day 2" ~ "Night 2", 
                         Day == "Day 3" ~ "Night 3"))

write.csv2(plateau, file = "/Users/shambhavi/Google Drive/Experiments & Data/Serial Reversal Learning - La Selva_2017 (backup)/Analysis/plateau_raw_data.csv", row.names = FALSE)

plateau_avg <- plateau %>% 
  ungroup() %>% 
  group_by(block_vis) %>% 
  group_modify(~ mean_cl_boot(.x$reward_status, conf.int = 0.95))

p11 <- plateau_avg %>% 
  ggplot(aes(block_vis, y)) + 
  geom_ribbon(aes(ymin = ymin, ymax = ymax), alpha = 0.3) +
  geom_hline(aes(yintercept = 0.5), linetype = "dotted") + 
  geom_line() + 
  geom_point() + 
  scale_x_continuous(breaks = seq(1,10, by = 1)) + 
  scale_y_continuous(breaks = seq(0, 1, by = 0.1), limits = c(0,1)) +  
  xlab("Number of visits after a reversal") + 
  ylab("Visits to the rewarding option") + 
  theme_srl2()

p12 <- plateau %>% 
  filter(Bat == "Bat 10") %>% 
  ggplot(aes(block_vis, reward_status)) + 
  #geom_ribbon(aes(ymin = ymin, ymax = ymax), alpha = 0.3) +
  geom_hline(aes(yintercept = 0.5), linetype = "dotted") + 
  geom_line(aes(colour = Bat, group = Bat)) + 
  #geom_point() + 
  scale_x_continuous(breaks = seq(1,10, by = 1)) + 
  scale_y_continuous(breaks = seq(0, 1.1, by = 0.1)) +  
  facet_grid(Day~block) + 
  #ylim(0,1) + 
  xlab("Visits after reversal") + 
  ylab("Prop. rewarded visits ± 95% CIs") + 
  theme_bw()
  

plateau <- rev_learning %>% 
  select(Bat, Day, block, bin, block_vis, count_vis, reward_status) %>% 
  filter(Day == "Day 1" & block == 6 |
         Day == "Day 2" | Day == "Day 3",
         block > 1, 
         block_vis > 0 & block_vis < 11) %>% 
  ungroup() %>% 
  group_by(Day, block, block_vis) %>% 
  group_modify(~ mean_cl_boot(.x$reward_status, conf.int = 0.95)) %>% 
  ungroup() %>% 
  mutate(trial_num = 1:n())

blocks <- plateau %>% 
  mutate(reversal = ifelse(block != lag(block), 1, 0)) %>% 
  filter(reversal == 1) %>% 
  mutate(trial_num = trial_num - 0.5)

plateau %>% 
  ggplot(aes(trial_num, y)) + 
  geom_line() + 
  geom_point() +
  geom_ribbon(aes(ymin = ymin, ymax = ymax, alpha = 0.3)) + 
  geom_vline(data = blocks, aes(xintercept = trial_num), linetype = "dashed") +
  geom_hline(aes(yintercept = 0.5), linetype = "dotted") + 
  scale_x_continuous(breaks = seq(0, 120, by = 10)) + 
  ylab("Prop. rewarded visits ± 95% CIs") + 
  xlab("Running trial number") + 
  theme_bw() + 
  theme(legend.position = "none") 
```

The Prop~rew~ in the first bin of 10 visits after a reversal increased significantly as the bats experienced more reversals. This effect was present in the second bin of 10 visits (visits 11 - 20) as well, but by the third bin there was no further change (Figure \@ref(fig:first-night-block-removed) b)). At the end of each block, i.e., just before the next reversal, the bats visited the rewarding flower almost exclusively, and there was no evidence of anticipatory visits. 

(ref:first-night-first-block-removed) a) Forest plot of the regression coeffients from the model of the effect of reversal and 10-visit bin on the visits to the rewarding flower. Circles represent the means of the posterior distributions of the slope coefficients, thick horizontal lines represent 50% credible intervals, and thin horizontal lines 89% credible intervals. The numbers in bold are the means of the posterior distributions and 89% credible intervals b) Conditional effects plot from the model of the effect of reversal and 10-visit bin on the visits to the rewarding flower showing the two-way interaction between reversal and bin, sampling from the posterior distribution.

```{r first-night-first-block-removed, fig.cap = "(ref:first-night-first-block-removed)", fig.width = 20, fig.height = 5}

# creating a table of the data from the first night with the first block removed
analysis_choices_firstnight_nofirstblock <- rev_learning %>% 
  ungroup() %>% 
  select(Day, block, bin, Bat, reward_status, block_vis, count_vis) %>% 
  filter(block_vis != 0) %>% 
  # removing the space temporarily and changing the Day back to numbers as this is how it was done in the model 
  mutate(Bat = str_remove_all(Bat, " "),
         Day = case_when(Day == "Day 1" ~ 1, 
                         Day == "Day 2" ~ 2, 
                         Day == "Day 3" ~ 3), 
         Day = as.integer(Day),
         block = as.integer(block),
         bin = as.integer(bin),
         reward_status = as.integer(reward_status),
         block_vis = as.integer(block_vis),
         count_vis = as.integer(count_vis)) %>% 
  filter(Day == 1,  
         block != 1)

# fitting the model
# m.firstnight.blockbin.nofirstblock <-
#   brm(data = analysis_choices_firstnight_nofirstblock, family = bernoulli,
#       reward_status ~ block + bin + block:bin + 
#         (1 + block:bin|Bat), # random slopes and intercepts
#       prior = c(prior(normal(0, 2.5), class = Intercept),
#                 prior(normal(0, 2.5), class = b), 
#                 prior(cauchy(0, 1), class = sd)
#                 ),
#       iter = 2000, warmup = 1000, chains = 4, cores = 5, thin = 3,
#       control = list(adapt_delta = 0.99, max_treedepth = 15),
#       seed = 12)

# saving the model
# save(m.firstnight.blockbin.nofirstblock, file = "data/processed_data/m.firstnight.blockbin.nofirstblock.rda")

# loading the model
load("data/processed_data/m.firstnight.blockbin.nofirstblock.rda")

# setting the colour scheme
color_scheme_set("darkgray")

# setting the names of the fixed effects 
fixed_effects = c("Intercept", "block", "bin", "block:bin")

# putting the model's estimates into a table
t1_estimates <- model_outputs(m.firstnight.blockbin.nofirstblock, fixed_effects)

# finding the maximum x value in the fixed effects of the model
max_xvalue <- max_xvalue_output(m.firstnight.blockbin.nofirstblock, fixed_effects)

# creating a plot of the slope coefficients
p3 <- mcmc_intervals(m.firstnight.blockbin.nofirstblock,
  point_size = 2.5,
  pars = vars(1:4),
  prob_outer = 0.89, 
  inner_size = 4, 
  outer_size = 2.5
) +
  xlim(-4.5, max_xvalue + 0.9) +
  ylim(c(2.5, 1)) + 
  geom_vline(xintercept = 0) +
  scale_y_discrete(
    labels = c(
      "b_Intercept" = "Intercept",
      "b_block" = "Reversal",
      "b_bin" = "Bin",
      "b_block:bin" = "Reversal-bin \n interaction"
    ),
    limits = c("b_block:bin", "b_bin", "b_block", "b_Intercept")
  ) +
  geom_text(
    data = t1_estimates,
    aes(x = max_xvalue + 0.1, y = c(4, 3, 2, 1), label = All, fontface = "bold", family = "Times"), size = 5, hjust = 0
  ) +
  scale_colour_viridis_d() + 
  theme_srl2() + 
  theme(axis.text = element_text(size = 12, family = "Times", colour = "black"), 
        axis.title = element_text(size = 14, family = "Times"))
  

# setting the conditions for the conditional effects plots 
int_conditions <- list(block = c(2,3,4,5,6), bin = c(1,2,3,4,5))

# calculating the conditional effects
m_firstnight_blockbin_nofirstblock <- conditional_effects(m.firstnight.blockbin.nofirstblock, int_conditions = int_conditions, prob = 0.89, nsamples = 150)

# plotting out the conditional effects
p4 <- plot(m_firstnight_blockbin_nofirstblock, plot = FALSE, line_args = c(alpha = 1/5)) [[3]] +
  scale_x_continuous(breaks = seq(2,6,by = 1)) +
  ylim(0,1) + 
  xlab("Block") + 
  ylab("Posterior estimates of the model") +
  guides(color = guide_legend(reverse=TRUE), 
         fill = guide_legend(reverse = TRUE)) + 
  scale_colour_viridis_d() + 
  scale_fill_viridis_d() + 
  theme_srl2() +
  theme(axis.text = element_text(size = 12, family = "Times", colour = "black"), 
        axis.title = element_text(size = 14, family = "Times"), 
        legend.position = "top") 
  

# plotting it out
ggarrange(p3, p4, nrow = 2, labels = c("a)","b)"), font.label = list(face = "plain", family = "Times New Roman", size = 12))
```

The block after the very first reversal of the night, which was also the first reversal of the whole experiment had the lowest proportion of rewarded visits in the first twenty visits of the block. The effect of reversal on the Prop~rew~ persisted even when the data from this block were removed from the analysis (see **Supplementary Information**).
Thus, the bats switched to the rewarding flower with increasing speed, i.e., within a smaller number of visits, as they experienced successive reversals. 

# Discussion 

In our experiment wild nectar-feeding bats participated in a spatial serial reversal learning task with two potentially rewarding options that repeatedly alternated their rewarding properties. With this study we examined whether nectar-feeding bats were capable of second-order learning, an ability that would enhance their behavioural flexibility in a dynamically changing foraging environment. We found that the bats switched to the newly-rewarding option from a previously-rewarding one with increasing swiftness with each successive experience of a reversal: strong evidence of second-order learning. This 'speed of switching' increased on the first night of the experiment with five experiences of a reversal until it reached a plateau, and no further increase was seen as an effect of reversals.  

On the first night of our three-night experiment there were significant changes in the bats' decision-making behaviour. In order to quantify the swiftness of the change of the bats' choices from one option to another we analyzed the area under the curve marked by the choice data from the first 25 visits out of 50 visits of each block. The area under the curve following each of the five reversals increased significantly. The first reversal on this night was also the very first experience of a reversal in the main experiment, experienced after a long series of trials with fixed reward contingencies (the bats experienced an alternation of reward contingencies during the training phase of the experiment, but this occurred with every single rewarded visit they made). Thus, in the first ten visits after the first reversal, the proportion of visits to the rewarding flower dropped to the lowest value observed in the entire experiment (figure \@ref(fig:overall-summary)a). Even when this block with its especially low number of rewarded visits was excluded from the analysis however, the area under the curve increased as an effect of the third, fourth and fifth reversals on the first night (figure \@ref(fig:area-under-the-curve-all-but-first-reversal)). In other words, the effect of reversal on the area under the curve of the first 25 visits of a block was not driven solely by the very first experience of a reversal.

The overall proportion of visits to the rewarding option increased with each block, excluding the very first block when reversals had not been experienced. In order to ascertain whether the increase in the area under the curve was during to an overall increase in the proportion of rewarded visits, and not swifter choice reversal, we analyzed how the proportion of rewarded visits changed both across blocks and within each block. To do this we calculated the effect of block, bins of 10 visits within each block, and their interaction on the proportion of rewarded visits (figure \@ref(fig:first-night-first-block-removed)). This analysis revealed that the proportion of rewarded visits in the last 30 visits of each block did not change as an effect of block; rather, the increase in the proportion of rewarded visits with each block was driven by the first 20 visits in the block. This was true even when the second block, which occurred after the first reversal, was excluded from the analysis, although the effect of block was somewhat weaker (figure \@ref(fig:first-night-first-two-blocks-removed)). This is consistent with the interpretation that the bats alter their choice behaviour faster immediately after a reversal of reward contingencies. 

An important methodological point that affects the interpretation of our results is that the bats in this experiment received a rather large magnitude of reward each trial: 40 $\mu$L. As the experiment went on, and the bats received hundreds of these large rewards, it is possible that they both became physically satiated, and learned that the environment was a rich one where food was easily obtained. One might expect therefore that motivation to find food decreased over the course of each night due to these reasons, with the animals relatively hungry at the beginning of their nightly foraging bout. On the first experimental night there was an increase in the number of rewarded visits made, but a potential decrease in motivation to find food may have contributed to the choice behaviour seen on the second and third nights. On these later nights the successive experiences of reversals did not increase the proportion of rewarded visits; rather, there was a small increase in the variation of the proportion of rewarded visits. 

During the first 50 visits of each night, the bats had no experience of a reversal of reward contingencies that night. This is when the proportion of rewarded visits was the highest every night. After the bats experienced no reward at an option that had been rewarding until then, the proportion of rewarded visits decreased, and never again became as high as it was in the first block. Bats are known to adjust their choice behaviour between different available options according to their history of reinforcement at those options [@tolch_psychometric_2007, @nachev_psychophysics_2012]. If it is solely reinforcement history that dictates choice behaviour, then as the experience of reinforcement accumulates at both flowers over the course of the night, it is more difficult to discriminate which flower has a richer history. One would then expect that the bats' behaviour approaches random choice as a night goes on, i.e., the Prop~rew~ would approach 0.5. Even if the animals do not rely on their entire history of reinforcement at an option for their decision-making but merely a part of it, one would expect to see a slower switch to the rewarding option following each reversal, and then a steady increase in rewarded visits. This is the exact opposite of what was seen on the first experimental night: the bats switched to the rewarding option *faster*. On the second and third nights, while the switch to the rewarding option did not become faster, the bats also did not show a steady increase in rewarded visits, even after experiencing a few reversals. Instead, a consistent pattern was seen: the proportion of rewarded visits dropped to about 0.5 immediately after the reversal, and then came back up to approximately 0.9, steadily maintained until the next reversal. The immediate post-reversal drop in rewarded visits was never as low as it was at the start of the first night, but was consistently approximately 0.5, which was the proportion of rewarded visits immediately after the reversals at the end of the first night. 

While it is clear, therefore, that the bats' choice behaviour was not dictated by the reinforcement history at the two options, it is also evident that the swifter switch to the rewarding option ceases by the end of the first night. The bats' choice behaviour was consistent with second-order learning, but though the optimum behaviour of one error per reversal is approached, it is never reached. 

The performance on the serial reversal task of animals that share similarities with bats in their foraging ecology is illuminating. In an experiment similar to ours with a large trial number bumblebees showed a reduction in their perseverative errors and an increase in the errors made in the last trials, though there was an overall decrease in the errors [@strang_serial_2014]. The authors of this paper interpreted these findings as indicative of proactive interference, which occurs when previously-learned information interferes with the learning or remembering new information [@tello-ramos_spatial_2019]. 
Several animals that rely strongly on spatial memory have also been studied in reversal learning tasks, specifically birds that cache food at various locations that they must remember and return to. Birds that are known to have better or more long-lasting spatial memory such as black-capped chickadees [@hampton_proactive_1998], Clark’s nutcrackers [@lewis_interference_2006] and high elevation mountain chickadees [@croston_predictably_2017] were worse at adapting to the new contingency after a reversal than the initial learning (reviewed in @tello-ramos_spatial_2019). These data are consistent with the idea that there is a trade-off between acquiring new memories and retaining old ones, i.e., that proactive interference may be occurring in spatial reversal tasks, just like in bumblebees. It is known that Glossophagine bats have excellent spatial memory, potentially lasting up to several weeks [@rose_learning_2016], but there no evidence of proactive intereference in the bats' performance on the serial reversal task. At best there is a little increased variation in the choice behaviour after many reversals have been experienced, for which there may be other explanations such as physical satiety.  

Our results are consistent with previous work of the same species of bat under natural conditions in the same environment (La Selva Biological Field Station, Costa Rica) [@thiele_nahrungssuchstrategien_2006]. This study, using the serial reversal task, evaluated the behavioural flexibility of nectar-feeding bats to fluctuations in food resource availability. Free-flying, ID-tagged wild bats interacted with 50 ID-sensor equipped artificial flowers placed over a 100 x 100 m area in the open forest that varied in their rate of nectar production. The allocation of flower types to spatial locations changed with the same pattern every night. During each night, bats adapted to the changes in resource availability. However, the bats needed four nights before they had adapted to the underlying recurring, predictable pattern of resource variability. 

In most cases under natural foraging conditions, flowers are emptied in a single visit. There are however certain plants such as species of *Agave* or *Vriesea*, that hold large amounts of nectar, which if undetected for a long time may require multiple hovering visits to deplete – “jackpot” rewards in other words [@ohashi_efficient_2005]. Thus the ability to swiftly inhibit visiting a flower that had been rewarding for multiple visits is likely part of the bats' natural foraging ecology as nectar-feeding animals. 

What performance on the serial reversal task says about the cognitive mechanisms at work is not completely settled. Cognitive flexibility describes the processes in the brain that underlie adaptive change in behaviour in response to changes in the internal or external environment, whereas behavioural flexibility is the modifiability of learned behaviour [@dhawan_more_2019]. Cognitive flexibility cannot be directly observed; it is inferred to have occurred through behavioural flexibility [@tait_assessment_2018], and the reversal learning task is a test of behavioural flexibility, not cognitive flexibility [@dhawan_more_2019]. Our study with nectar-feeding bats yielded strong evidence of second-order learning, indicative of a high capacity for behavioural flexibility evolved in the bats through a foraging ecology dominated by the search for nectar-rich flowers. 

# Electronic Supplementary Material {-}

\beginsupplement

## Visits and approaches to the unassigned flowers

```{r Preparing-data-and-checking-distribution-to-nonassigned-flowers}

#------------------------------------------------
# Preparing the table with the information needed
#------------------------------------------------

# setting binsize and breaks for cutting up the data into block and bin
binsize <- 10
breaks <- seq(0, 3000, binsize)

# creating a data-table with the visits to the unassigned flowers 
samp_all_nonrw <- alldata_pumps %>%
  arrange(DateTime) %>%
  filter(
    Condition == "SerialReversalCounter",
    Day %in% main_days,
    !IdLabel %in% bats_beta,
    !IdLabel %in% bats_incomp,
    # selecting the required information in the proper columns
    str_detect(MsgValue1, "start pump") | str_detect(MsgValue1, "end pump") | str_detect(MsgValue1, "switch") | str_detect(unitLabel, "CondMod | Reader") | str_detect(IdLabel, "Bat")
  ) %>%
  mutate(
    Day = case_when(
      Day == "Day 1" ~ "Night 1",
      Day == "Day 2" ~ "Night 2",
      Day == "Day 3" ~ "Night 3"
    ),
    Loc = as.integer(str_extract(unitLabel, "[0-9]+"))
  ) %>%
  rename(Bat = IdLabel) %>%
  ungroup() %>%
  group_by(Day, Bat) %>%
  # creating a column with the block number, marking the reversals
  mutate(block = ifelse(MsgValue1 == "switch", 1, 0)) %>%
  group_by(Day, Bat) %>%
  mutate(block = cumsum(block)) %>%
  ungroup() %>%
  group_by(Day, Bat, block) %>%
  # creating a column with the number of visits within each block
  mutate(
    block_vis = ifelse(MsgValue1 == "switch", 0, 1),
    block_vis = cumsum(block_vis),
    # creating a new column for visits in each block to be binned
    bin = ""
  ) %>%
  ungroup() %>%
  group_by(Day, Bat, block) %>%
  # cutting the visits inside each block into bin of the size set earlier
  mutate(bin = as.numeric(cut(block_vis, breaks, include.lowest = TRUE))) %>%
  filter(Bat != " Test")

# making a look-up table to mark the assigned flowers
rewarding <- samp_all_nonrw %>%
  # marking the assigned flowers
  filter(outLabel == "positive") %>%
  # pulling out the CondMod events
  mutate(assigned = ifelse(str_detect(unitLabel, "CondMod"), 1, 0)) %>%
  arrange(Bat) %>%
  ungroup() %>%
  select(Day, Bat, unitLabel, assigned) %>%
  distinct() %>%
  # making a column with the flower numbers
  mutate(Loc = as.integer(str_extract(unitLabel, "[0-9]+"))) %>%
  select(-unitLabel)

# making the table with the flower numbers marked
assignment <- samp_all_nonrw %>%
  ungroup() %>%
  select(Day, Bat, unitLabel) %>%
  distinct() %>%
  mutate(Loc = as.integer(str_extract(unitLabel, "[0-9]+")))

# joining the tables to create the assignment look-up table
assignment <- left_join(assignment, rewarding, by = c("Day", "Bat", "Loc")) %>%
  mutate(assigned = replace_na(assigned, 0)) %>%
  select(-unitLabel)

# removing the now unnecessary look-up table
rm(rewarding)

# marking the visits in the data set from the bats as assigned or not assigned
samp_all_nonrw <- left_join(samp_all_nonrw, assignment, by = c("Day", "Bat", "Loc"))

# labels to extract
labels <- paste(c("CondMod", "Reader"), collapse = "|")

# making a look-up table to find the last visit of the experiment
last_visit <- samp_all_nonrw %>%
  # selecting the visits to the assigned flowers and the CondMods
  filter(
    assigned == 1,
    outLabel == "positive"
  ) %>%
  group_by(Day, Bat) %>%
  # counting these visits
  mutate(count_vis = 1:n()) %>%
  # filter the last one of these visits
  filter(count_vis == max(count_vis)) %>%
  # selecting the required columns
  select(DateTime, Day, Bat) %>%
  distinct() %>%
  # noting the last experimental visit
  mutate(final_vis = 1)

# adding the information about the last visit to the main table
samp_all_nonrw <- left_join(samp_all_nonrw, last_visit, by = c("DateTime", "Day", "Bat"))

samp_all_nonrw <- samp_all_nonrw %>%
  mutate(
    final_vis = replace_na(final_vis, 0),
    # flipping the 1s and 0s for the assigned so that the visits to the unassigned flowers can be calculated for the Y axis
    assigned = ifelse(assigned == 0, 1, 0)
  )

# taking only the experimental times
samp_exp_nonrw <- samp_all_nonrw %>%
  ungroup() %>%
  group_by(Day, Bat) %>%
  mutate(
    final_vis = cumsum(final_vis),
    final_vis = cumsum(final_vis)
  ) %>%
  filter(final_vis <= 1) %>%
  group_by(Day, Bat)

# making a look-up table with the reversals
reversals <- samp_exp_nonrw %>%
  ungroup() %>%
  group_by(Bat, Day) %>%
  mutate(day_bin = ifelse(bin == lag(bin), 0, 1)) %>%
  filter(!is.na(day_bin)) %>%
  mutate(
    day_bin = cumsum(day_bin),
    day_bin = day_bin + 1,
    day_bin_vis = day_bin * 10
  ) %>%
  ungroup() %>%
  mutate(day_bin_vis = ifelse(MsgValue1 == "start pump" | MsgValue1 == "end pump", lag(day_bin_vis), day_bin_vis)) %>%
  filter(MsgValue1 == "switch")

#----------------------------------------------
# Counting the events at the unassigned flowers
#----------------------------------------------

# calculating the visits to the unassigned flowers over the night
samp_avg_nonrw <- samp_exp_nonrw %>%
  # grouping the data to see what happened before and after the experiment
  group_by(Day, Bat, block, bin) %>%
  group_modify(~ mean_cl_boot(.x$assigned, conf.int = 0.89)) %>%
  ungroup() %>%
  group_by(Bat, Day) %>%
  mutate(
    day_bin = 1:n(),
    day_bin_vis = day_bin * 10,
    ymin = replace_na(ymin, 0),
    ymax = replace_na(ymax, 0)
  ) %>%
  filter(str_detect(Bat, "Bat"))

# plotting the proportion of visits to the unassigned flowers
# samp_avg_nonrw %>%
#   # filtering only the first three main days of the experiment:
#   # one group had the experiment extended a further three days
#   ggplot(aes(day_bin_vis, y)) +
#   geom_point(size = 0.3) +
#   geom_line() +
#   geom_ribbon(aes(ymin = ymin, ymax = ymax), alpha = 0.3) +
#   facet_grid(Bat ~ Day) +
#   #scale_x_continuous(breaks = seq(50, 300, by = 50)) +
#   ylim(0, 1.1) +
#   geom_hline(yintercept = c(0.25, 0.5, 0.75, 1), linetype = "dotted") +
#   geom_vline(data = reversals, aes(xintercept = day_bin_vis), color = "blue") +
#   theme_classic() +
#   labs(x = "Visits", y = "Proportion of visits to the non-assigned flowers") +
#   theme(legend.position = "none")


# creating a table with the individual counts of visits to the different flowers

samp_bar_nonrw <- samp_exp_nonrw %>%
  # removing the NAs
  filter(
    !is.na(Bat),
    !is.na(Loc)
  ) %>%
  ungroup() %>%
  group_by(Day, Cage, Bat, unitLabel, assigned, Loc) %>%
  summarise(visits = n()) %>%
  arrange(Loc) %>%
  mutate(
    Type = str_extract(unitLabel, labels),
    # marking the CondMod and Reader events
    Type = as.factor(ifelse(Type == "CondMod", "Nose-poke", "Fly-by")),
    Loc = as.character(Loc),
    assigned = ifelse(assigned == 0, "", "(non-assigned)")
  ) %>%
  ungroup() %>%
  group_by(Day, Bat, Loc, Type) %>%
  mutate(
    max = sum(visits),
    Event = paste(Type, assigned, sep = " ")
  ) %>%
  # taking only the bat visits 
  filter(unitLabel != "exp")

# calculating the proportion of events at the unassigned flowers
samp_prop_nonrw <- samp_exp_nonrw %>%
  group_by(Day, Bat, assigned) %>%
  summarise(sum = n()) %>%
  pivot_wider(names_from = assigned, values_from = sum) %>%
  rename(
    non_assigned = `1`,
    assigned = `0`
  ) %>%
  filter(!is.na(assigned)) %>%
  mutate(
    non_assigned = replace_na(non_assigned, 0),
    prop_assigned = non_assigned / (assigned + non_assigned)
  )

# calculating the mean and 95% CIs
samp_prop_mean <- samp_prop_nonrw %>%
  ungroup() %>%
  group_by(Day) %>%
  group_modify(~ mean_cl_boot(.x$prop_assigned, conf.int = 0.89))
```

Only two out of the array of eight flowers were assigned uniquely to each bat but all the flowers were accessible to all the animals. The number of approaches to and attempts to get a reward from all the flowers, both assigned and not assigned, is shown in figure \@ref(fig:unassigned-flowers).

(ref:unassigned-flowers) Visits made by the bats to all the flowers, including the ones that were not assigned to them. Yellow bars are nose-pokes at the assigned flowers, where the bats attempted to get a reward by breaking the light-barrier. Purple bars are 'fly-by' events near the assigned flowers where the bat flew near the flower but did not attempt to get a reward. Orange bars are nose-pokes at the non-assigned flowers and black bars are fly-bys at the non-assigned flowers.

```{r, unassigned-flowers, fig.cap="(ref:unassigned-flowers)", fig.width = 10, fig.height = 7}

samp_bar_nonrw <- samp_bar_nonrw %>% 
  ungroup() %>% 
    add_row(Day = "Night 1", Cage = 1, Bat = "Bat 20", unitLabel = "Reader7", assigned = "", Loc = as.character(7), visits = 0, Type = "Fly-by", max = 0, Event = "Fly-by ")

p5 <- samp_bar_nonrw %>%
  # adding a row for the fly-by visits to an assigned flower for Bat 20 so the bars in the following plot are of even width
  filter(Cage == 1) %>%
  ggplot(aes(x = Loc, y = visits, fill = Event)) +
  geom_col(position = "dodge", color = "black") +
  # geom_text(aes(x = Loc, y = max + 15, label = assigned), size = 2) +
  facet_grid(Day ~ Bat) +
  xlab("Flower number") +
  ylab("Number of approaches/visits \n to non-assigned flowers") +
  theme_srl() +
  scale_fill_viridis_d(option = "inferno") 

p6 <- samp_bar_nonrw %>%
  filter(Cage == 2) %>%
  ggplot(aes(x = Loc, y = visits, fill = Event)) +
  geom_col(position = "dodge", color = "black") +
  # geom_text(aes(x = Loc, y = max + 15, label = assigned), size = 2) +
  facet_grid(Day ~ Bat) +
  xlab("Flower number") +
  ylab("Number of approaches/visits \n to non-assigned flowers") +
  scale_fill_viridis_d(option = "inferno") +
  theme_srl() +
  theme(legend.position = "bottom")

ggarrange(p5, p6, nrow = 2, ncol = 1, common.legend = TRUE)
```

The number of approaches or attempts to get a reward at the non-assigned flowers was a small proportion of the overall number of approaches and reward-attempts at the flowers, less than 10% every night on average as Figure \@ref(fig:proportion-unassigned) shows.

(ref:proportion-unassigned) Proportion of visits or approaches to the un-assigned flowers out of the total number of visits or approaches to flowers. Coloured points are data from individual bats. Black points are the mean proportion per night and the error bars are 89% CIs. 

```{r, proportion-unassigned, fig.cap = "(ref:proportion-unassigned)", fig.width=5, fig.height= 4}

dodge <- position_dodge(width = 0.1)

p7 <- samp_prop_nonrw %>%
  mutate(Day = as.factor(Day)) %>%
  ggplot() +
  geom_jitter(aes(Day, prop_assigned, color = Bat)) +
  geom_point(data = samp_prop_mean, aes(Day, y), alpha = 0.7) +
  geom_errorbar(data = samp_prop_mean, aes(x = Day, ymax = ymax, ymin = ymin), alpha = 0.7, position = dodge, width = 0.1) +
  ylim(0, 1) +
  xlab("Night") +
  ylab("Proportion of approaches or visits \n to the unassigned flowers") +
  geom_hline(yintercept = 0.5, linetype = 2) +
  theme_srl() +
  scale_color_viridis_d(option = "inferno") +
  theme(legend.position = "top", 
        legend.title = element_blank(),
        legend.text = element_text(size  = 8),
        legend.margin=margin(0,0,0,0)) +
    guides(colour = guide_legend(nrow = 2))

p7
```

## Details of the statistical analyses

Weakly informative priors were used for the generalized linear mixed-models in `brms`.
All the models were estimated using 4 chains with a thinning interval of 3, with 1500 warm-up samples and 3000 post-warm-up samples for all the models except the one fitted to the data from the second and third nights, which had 1000 warm-up samples and 3000 post-warm-up samples. 

For the models of the area under the curve a normal likelihood function was used, with reversal number as a fixed effect. The intercepts and slopes were allowed to vary for each animal. For the models of the proportion of visits to the rewarding option a bernoulli likelihood function was used. For the model of the first night, the reversal number, 10-visit bin within each block, and their interaction were the fixed effects. Slopes and intercepts were allowed to vary for each animal.  

Visual inspection of the trace plots, the effective sample size, the Gelman-Rubin convergence diagnostic ($\hat R$) and the calculation of posterior predictions for the same clusters were all used to assess the fit of the models. In all the models the $\hat R$ was equal to 1 for all the chains.


## The effect of reversal is not driven solely by the effect of the first reversal on the first night 

The effect of reversal on the visits to the rewarding flower persisted even when the data from this block were removed from the analysis. 

(ref:first-night-first-two-blocks-removed) a) Forest plot of the regression coeffients from the model of the effect of reversal and 10-visit bin on the visits to the rewarding flower, excluding the first reversal. Circles represent the means of the posterior distributions of the slope coefficients, thick horizontal lines represent 50% credible intervals, and thin horizontal lines 89% credible intervals. The numbers in bold are the means of the posterior distributions and 89% credible intervals b) Conditional effects plot from the model of the effect of reversal and 10-visit bin on the visits to the rewarding flower - excluding the first reversal - showing the two-way interaction between reversal and bin, sampling from the posterior distribution.

```{r first-night-first-two-blocks-removed, fig.cap = "(ref:first-night-first-two-blocks-removed)", fig.width = 18, fig.height = 5}
# creating a table of the data from the first night with the first two blocks removed
analysis_choices_firstnight_lastthreeblocks <- analysis_choices_firstnight_nofirstblock %>% 
  filter(block > 2)

# fitting the model
# m.firstnight.blockbin.lastthreeblocks <-
#   brm(data = analysis_choices_firstnight_lastthreeblocks, family = bernoulli,
#       reward_status ~ block + bin + block:bin + 
#         (1 + block:bin|Bat), # random slopes and intercepts
#       prior = c(prior(normal(0, 2.5), class = Intercept),
#                 prior(normal(0, 2.5), class = b), 
#                 prior(cauchy(0, 1), class = sd)
#                 ),
#       iter = 2000, warmup = 1000, chains = 4, cores = 5, thin = 3,
#       control = list(adapt_delta = 0.99, max_treedepth = 15),
#       seed = 12)

# saving the model
# save(m.firstnight.blockbin.lastthreeblocks, file = "data/processed_data/m.firstnight.blockbin.lastthreeblocks.rda")

# loading the model
load("data/processed_data/m.firstnight.blockbin.lastthreeblocks.rda")

# setting the names of the fixed effects
fixed_effects = c("Intercept", "block", "bin", "block:bin")

# putting the model's estimates into a table
t1_estimates <- model_outputs(m.firstnight.blockbin.lastthreeblocks, fixed_effects)

# finding the maximum x value in the fixed effects of the model
max_xvalue <- max_xvalue_output(m.firstnight.blockbin.lastthreeblocks, fixed_effects)

# creating a plot of the slope coefficients
p8 <- mcmc_intervals(m.firstnight.blockbin.lastthreeblocks,
  point_size = 2.5,
  pars = vars(1:4),
  prob_outer = 0.89, 
  inner_size = 4, 
  outer_size = 2.5
) +
  xlim(-4.6, max_xvalue + 0.9) +
  geom_vline(xintercept = 0) +
  scale_y_discrete(
    labels = c(
      "b_Intercept" = "Intercept",
      "b_block" = "Reversal",
      "b_bin" = "Bin",
      "b_block:bin" = "Reversal-bin \n interaction"
    ),
    limits = c("b_block:bin", "b_bin", "b_block", "b_Intercept")
  ) +
  geom_text(
    data = t1_estimates,
    aes(x = max_xvalue + 0.1, y = c(4, 3, 2, 1), label = All, fontface = "bold", family = "Times"), size = 5, hjust = 0
  ) +
  scale_colour_viridis_d() + 
  theme_srl2() + 
  theme(axis.text = element_text(size = 12, family = "Times", colour = "black"), 
        axis.title = element_text(size = 14, family = "Times"))

# setting the conditions for the conditional effects plots 
int_conditions <- list(block = c(3,4,5,6), bin = c(1,2,3,4,5))

# calculating the conditional effects
m_firstnight_blockbin_lastthreeblocks <- conditional_effects(m.firstnight.blockbin.lastthreeblocks, int_conditions = int_conditions, prob = 0.89, nsamples = 150)

# creating the plots of the conditional effects
p9 <- plot(m_firstnight_blockbin_lastthreeblocks, plot = FALSE, line_args = c(alpha = 1/5)) [[3]] +
  scale_x_continuous(breaks = seq(3,6,by = 1)) +
  ylim(0,1) + 
  xlab("Block") + 
  ylab("Posterior estimates of the model") +
  scale_colour_viridis_d() + 
  scale_fill_viridis_d() + 
  guides(color = guide_legend(reverse=TRUE), 
         fill = guide_legend(reverse = TRUE)) + 
  theme_srl2() + 
  theme(legend.position = "top") +
  theme(axis.text = element_text(size = 12, family = "Times", colour = "black"), 
        axis.title = element_text(size = 14, family = "Times"))

# plotting it out
ggarrange(p8, p9, ncol = 2, labels = c("a)","b)"), font.label = list(face = "plain", family = "Times New Roman", size = 8))
```

## The proportion of rewarded visits does not increase due to reversal experience in the later stages of the experiment

On the second and third experimental nights the highest Prop~rew~ was in the first block of the night, before any reversals had been experienced: `r report_m_ci_perc(day2and3block1, par = "y", brackets = "square")`. Excluding this first block, there was no effect of reversal on the Prop~rew~, although there was a strong effect of 10-visit bin within each block. That is, the proportion of visits to the rewarded flower only increased within each block as the block progressed (Figures 
\@ref(fig:overall-summary-last-two-nights) and \@ref(fig:second-and-third-nights-analysis)).  

(ref:overall-summary-last-two-nights) Visits to the rewarding one of two options over second and third experimental nights. Data are average proportions for bins of ten visits averaged over all the individuals that made visits in each bin. Data are indicated by white points in the first block before the bats had experienced any reversals; the bin averages of the other blocks are indicated by black points. Numbers indicate the bats that participated in a block. Shading shows 95% confidence intervals. Dashed lines show reversals

```{r, overall-summary-last-two-nights, fig.cap = "(ref:overall-summary-last-two-nights)", fig.width = 6, fig.height = 3}

p10 <- rev_learning_avg %>%
  # filtering only the first three main Days of the experiment:
  # one group had the experiment extended a further three Days
  filter(Day != "Day 1") %>%
  mutate(
    Day = case_when(
      Day == "Day 2" ~ "Night 2", 
      Day == "Day 3" ~ "Night 3"
    ),
    firstpoint = as.factor(ifelse(block == 1 & Day == "Night 1", 1, 0)), 
    day_bin_vis = day_bin_vis - 5
  ) %>%
  ggplot(aes(day_bin_vis, y)) +
  geom_point(aes(color = firstpoint, fill = firstpoint), shape = 21) +
  scale_color_manual(values = c("0" = "black", "1" = "black")) +
  scale_fill_manual(values = c("0" = "black", "1" = "white")) +
  geom_line() +
  geom_ribbon(aes(ymin = ymin, ymax = ymax), alpha = 0.3) +
  facet_grid(. ~ Day) +
  scale_x_continuous(breaks = seq(50, 300, by = 50)) +
  geom_vline(aes(xintercept = day_bin_vis), data = rev_main_avg %>% filter(Day != "Night 1"), linetype = "dashed") +
  geom_hline(yintercept = c(0.25, 0.5, 0.75, 1), linetype = "dotted") +
  ylim(0,1.05) + 
  #scale_y_continuous(breaks = seq(-0.1, 1.1, by = 0.25)) +
  theme_srl2() +
  geom_text(
    data = bat_labels  %>% filter(Day != "Night 1"),
    aes(x = day_bin_vis, y = 1.05, label = n_bats, group = n_bats), family = "Times"
  ) +
  labs(x = "Visits", y = "Visits to the rewarding option") +
  theme(legend.position = "none")

p10
```

(ref:second-and-third-nights-analysis) a) Forest plot of the regression coeffients from a model of the effect of experimental night, reversal and 10-visit bin on the visits to the rewarding flower, excluding the first night. Circles represent the means of the posterior distributions of the slope coefficients, thick horizontal lines represent 50% credible intervals, and thin horizontal lines 89% credible intervals. The numbers in bold are the means of the posterior distributions and 89% credible intervals b) Conditional effects plot from the model of the effect of experimental night, reversal and 10-visit bin on the visits to the rewarding flower - excluding the first night - showing the two-way interaction between reversal and bin, sampling from the posterior distribution.

```{r second-and-third-nights-analysis, fig.cap = "(ref:second-and-third-nights-analysis)", fig.width = 18, fig.height = 5}

# creating a data table with the data from the second and third nights
analysis_choices_laternights <- rev_learning %>% 
  ungroup() %>% 
  select(Day, block, bin, Bat, reward_status, block_vis, count_vis) %>% 
  filter(block_vis != 0) %>% 
  # removing the space temporarily and changing the Day back to numbers as this is how it was done in the model 
  mutate(Bat = str_remove_all(Bat, " "),
         Day = case_when(Day == "Day 1" ~ 1, 
                         Day == "Day 2" ~ 2, 
                         Day == "Day 3" ~ 3), 
         Day = as.integer(Day),
         block = as.integer(block),
         bin = as.integer(bin),
         reward_status = as.integer(reward_status),
         block_vis = as.integer(block_vis),
         count_vis = as.integer(count_vis)) %>% 
  filter(Day > 1, 
         block > 1)

# fitting the model
# m.dayblockbin.laternights <-
  # brm(data = analysis_choices_laternights, family = bernoulli,
  #     reward_status ~ Day + block + bin + block:bin + Day:block + 
  #       (1 + block:bin + Day:block|Bat), # random slopes and intercepts
  #     prior = c(prior(normal(0, 2.5), class = Intercept),
  #               prior(normal(0, 2.5), class = b), 
  #               prior(cauchy(0, 1), class = sd)
  #               ),
  #     iter = 2000, warmup = 1000, chains = 4, cores = 5, thin = 3,
  #     control = list(adapt_delta = 0.99, max_treedepth = 15),
  #     seed = 12)

# saving the model
# save(m.dayblockbin.laternights, file = "data/processed_data/m.dayblockbin.laternights.rda")

# loading the model
load("data/processed_data/m.dayblockbin.laternights.rda")

# setting the names of the fixed effects
fixed_effects = c("Intercept", "Day", "block", "bin", "block:bin", "Day:block")

# putting the model's estimates into a table
t1_estimates <- model_outputs(m.dayblockbin.laternights, fixed_effects)

# finding the maximum x value in the fixed effects of the model
max_xvalue <- max_xvalue_output(m.dayblockbin.laternights, fixed_effects)

# creating a plot of the slope coefficients
p11 <- mcmc_intervals(m.dayblockbin.laternights,
  point_size = 2.5,
  pars = vars(1:6),
  prob_outer = 0.89, 
  inner_size = 4, 
  outer_size = 2.5
) +
  xlim(-2.5, max_xvalue + 0.8) +
  geom_vline(xintercept = 0) +
  scale_y_discrete(
    labels = c(
      "b_Intercept" = "Intercept",
      "b_Day" = "Experimental \n night", 
      "b_block" = "Block",
      "b_bin" = "Bin",
      "b_block:bin" = "Block-bin \n interaction", 
      "b_Day:block" = "Night-block \n interaction"
    ),
    limits = c("b_Day:block", "b_block:bin", "b_bin", "b_block", "b_Day", "b_Intercept")
  ) +
  geom_text(
    data = t1_estimates,
    aes(x = max_xvalue + 0.1, y = c(6, 5, 4, 3, 2, 1), label = All, fontface = "bold", family = "Times"), size = 5, hjust = 0
  ) +
  theme_srl2() + 
    theme(axis.text = element_text(size = 12, family = "Times", colour = "black"), 
        axis.title = element_text(size = 14, family = "Times"))

# setting the conditions for the conditional effects plots 
int_conditions <- list(Day = c(1, 2, 3), block = c(2,3,4,5,6), bin = c(1,2,3,4,5))

# calculating the conditional effects
m_dayblockbin_laternights <- conditional_effects(m.dayblockbin.laternights, int_conditions = int_conditions, prob = 0.89, nsamples = 150)

# creating the plots of the conditional effects
p12 <- plot(m_dayblockbin_laternights, plot = FALSE, line_args = c(alpha = 1/5)) [[4]] +
  ylim(0,1) + 
  xlab("Block") + 
  ylab("Posterior estimates of the model") +
  scale_colour_viridis_d(option = "plasma") +
  scale_fill_viridis_d(option = "plasma") + 
  guides(color = guide_legend(reverse=TRUE), 
         fill = guide_legend(reverse = TRUE)) + 
  theme_srl2() + 
  theme(legend.position = "top") + 
  theme(axis.text = element_text(size = 12, family = "Times", colour = "black"), 
        axis.title = element_text(size = 14, family = "Times"))

# plotting it out
ggarrange(p11, p12, ncol = 2, labels = c("a)","b)"), font.label = list(face = "plain", family = "Times New Roman", size = 8))
```

# References
